---
layout: post
title:  "人工智能及未来畅想-AI and Future"
date:   2019-06-04 23:41:00
categories: 人工智能
tags: 人工智能 AI 人类简史 人文 哲学 康德 汉字屋 清华大学 天机 自行车 AGI 类脑 类机 waitbutwhy 脑机接口 张首晟 姚期智 冯·诺依曼 天道 沈向洋 戴海琼
excerpt: 深度思考
mathjax: true
---

* content
{:toc}

# AI之路

- 【2021-2-28】[Bengio、Hinton的不懈追求——深度学习算法揭示大脑如何学习](https://mp.weixin.qq.com/s/2-mTVY_pyHcYyaoJtR1Hsg)，[原文链接](https://www.quantamagazine.org/artificial-neural-nets-finally-yield-clues-to-how-brains-learn-20210218/)
  - [Hinton：我终于想明白大脑怎么工作了！神经学家花三十年，寻找反向传播的生物机制](https://mp.weixin.qq.com/s/nKPde5Hv4YoZCMOFvBXM1w)，更详细的解释，英文原文：[Artificial Neural Nets Finally Yield Clues to How Brains Learn](https://www.quantamagazine.org/artificial-neural-nets-finally-yield-clues-to-how-brains-learn-20210218/)
    - <video width="658" height="444" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/02/Neuron_2880_Lede.mp4" poster="https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/02/Simulating-a-Neuron.svg" autoplay="autoplay" preload="none"></video>
  - 时至今日，深度学习网络统治了人工智能领域，是当之无愧的新时代的弄潮儿，其背后最大的功臣之一，便是大名鼎鼎的反向传播算法Backpropagation。
  - 深度学习算法虽然启发自人脑的结构单元和学习机制，但这种简单的“模拟”其实并不是人脑真正运行的方式。
  - 生物大脑不太可能使用反向传播机制来进行学习。来自Montreal大学的计算机科学家、魁北克人工智能研究所科学主任、也是2007年那场“非法”的研讨会的组织者之一Yoshua Bengio说，“相对于深度学习算法，人脑更加强大，它拥有更好的泛化和学习的能力”。而且各种证据都显示，在大脑的解剖和生理构造上，特别是在皮质层，人脑是几乎不可能利用反向传播机制进行学习的。相对于简单的深度学习算法来说，人脑是一个更趋于完美的有机主体，如果我们能对它的学习机制有所了解，肯定能够促进深度学习的发展。
  - 反向传播算法在生物学上是不可信的。
    - 首先，虽然计算机可以很容易地实现该算法的两个传播阶段，但是对于生物神经网络来说，这样做难上加难。
    - 第二个问题是，计算神经科学家所说的权重传递问题: backprop 算法复制或传递关于推理所涉及的所有突触权重的信息，并更新这些权重以获得更高的准确性。但是在生物网络中，神经元只能看到其他神经元的输出，而不能看到影响输出的突触权重或内部过程。从神经元的角度来看，「知道自己的突触权重是可以的，」Yamins 说。「你无法知道其他神经元的突触权重。」
    - 任何生物学上可行的学习规则都需要遵守一个限制，即神经元只能从相邻神经元获取信息，而反向传播算法可能需要从更远的神经元处获取信息。因此，「如果你非常严格地来分析反向传播算法的话，大脑是不可能这样计算的，」Bengio 曾表示。
  - 研究人员一直在苦苦求索这个人脑中的与“反向传播”学习算法相匹配的生物机制。近年来，人们已经取得了一些相关的进展，其中最有前景的三个发现包括——**反馈对齐**（FeedBack Alignment）、**均衡传播**（Equilibrium Propagation）和**预测编码**（Predictive Coding）。还有一些研究人员甚至将生物学中某些类型的皮质层神经元的特性和注意力机制等过程具体化到他们的算法之中，力求揭示人脑神经元学习背后的奥秘。
    - **反馈对齐**
      - 2016年，伦敦谷歌 DeepMind 的 Timothy Lillirap 和他的同事提出了一个解决权重传递问题的方法。他们的算法，并非依赖从前向路径记录的权重矩阵，而是在反向传播过程中随机初始化矩阵。一旦指定权重，这些值永远不会改变，因此不需要为每个反向路径传输权重。对于大规模的问题和具有更多隐藏层的更深层次的网络，反馈比对不如反向传播好: 因为前向权重的更新在每次通过时都不如真正的反向传播信息准确，所以训练网络需要更多的数据。
      - 按照经典的赫布学习法，神经元只对邻近神经元做出反应，研究人员探索了在保持这条经典规则不变的情况下，如何达到反向传播神经元的性能。可以将反向传播看成两组神经元，其中一组神经元进行推理，另一组神经元进行更新突触权重的计算。Hinton的想法是研究出一种算法，使得其中的每个神经元都可以同时进行两组计算。「这基本上就是Hinton 在2007年想实现的目标，」Bengio表示。
      - 在 Hinton 研究的基础上，Bengio 团队在2017年提出了一个学习规则，要求神经网络具有循环连接(也就是说，如果神经元 A 激活神经元 B，那么神经元 B 反过来激活神经元 A)。如果给这样一个网络一些输入，它设置网络的反馈，如同每个神经元在推拉其邻近的神经元。
    - **均衡传播**
      - 待补充
    - **预测编码**
      - 传统观点认为，大脑不断地接收新的感知信息，并在越来越复杂的信息中寻找规律，然后构建起大脑对环境的认知，这是一种以「由下对上」的控制为主的感知结构。而预测编码理论恰恰与此相反，是以「由上对下」的控制为主的：我们的大脑用已有的模型制造出丰富的感官数据，形成一个预测性的内在世界，去匹配即将发生的真实世界。
      - 在大脑感知理论方面，爱丁堡大学博士生Beren Millidge，和他的同事们一直在研究叫做「预测性编码」的大脑感知观点，并和反向传播做对比。「预测性编码，如果以某种方式设置，将给你一个在生物学上合理的学习规则，」Millidge表示。
      - 预测性编码假定大脑不断地对感觉输入的原因进行预测。这个过程包括神经处理的层次结构。为了产生特定的输出，每一层都必须预测下一层的神经活动。如果最高层期望看到一张脸，它就可以对下面层的活动进行预测，可以证明这种感知。下一层对再下面的层做出类似的预测，以此类推。最低层能够预测实际的感觉输入，比如说，光子落在视网膜上。通过这种方式，预测从较高的层流向到较低的层。
      - 但问题是，错误可能会发生在层次结构的每个级别: 每一层对它所期望的输入和实际输入的预测之间存在差异。最底层根据接收到的感觉信息调整突触的权重，以最大限度地减少错误。这种调整导致了最新更新的最低层和上面一层之间会产生误差，因此较高层必须重新调整它的突触权重，以尽量减少它的预测错误。这些错误信号向上传递。如此循环往复，直到每一层的预测误差都实现最小化。
   - **锥体神经元**
     - 一些科学家已经开始着手基于单个神经元的已知特性建立类似反向传播的模型。标准神经元有树突，它们从其他神经元的轴突中收集信息。树突传递信号到神经元的细胞体，在那里信号被整合。这可能会导致神经元放电，从神经元的轴突到突触后神经元的树突上。但并非所有的神经元都有这种结构。特别是皮层中最丰富的神经元类型——锥体神经元有着明显的不同。锥体神经元具有树状结构，有两套不同的树突。树干向上伸展，分杈形成所谓的顶端树突。根向下延伸，分杈形成基部树突。
     - 2001年由德国神经科学家Kording 独立开发的模型，以及近期由麦吉尔大学和蒙特利尔神经研究所的 Blake Richards 及其同事开发的模型，已经表明，锥体神经元可以通过同时进行前向和反向计算，而形成深度学习网络的基本单元。
  - **注意力机制**
    - 对于使用反向传播的深度网络，一个隐含的要求就是要有「老师」的存在: 某种能够计算神经元网络误差的东西。荷兰阿姆斯特丹神经科学研究所(Netherlands Institute for Neuroscience)的Pieter Roelfsema表示，「但是，大脑中没有一个『老师』会告诉运动皮层的每一个神经元，『你应该被打开，还是应该被关闭。』」
    - Roelfsema提出大脑解决问题的方法是通过注意力。20世纪90年代后期，他和他的同事发现，当猴子盯着一个物体时，在大脑皮层内代表该物体的神经元会变得更加活跃。猴子集中注意力的这一行为会针对相应的神经元产生反馈信号。「这是一个高度选择性的反馈信号，」Roelfsema 表示。「这不是一个误差信号。它只是在告诉所有这些神经元: 你要为(一个行为)负责。」Roelfsema 的观点是，当这种反馈信号与某些其他神经科学发现所揭示的过程结合起来时，可以实现类似反向传播的学习过程。例如，剑桥大学的 Wolfram Schultz 和其他研究人员已经证明，当动物执行一个行动，产生比预期更好的结果时，大脑的多巴胺系统就会被激活。「它让整个大脑充满了神经调节器，」Roelfsema 说。多巴胺水平就好比一个全局强化信号。
    - 该团队在去年12月的NIPS 2020 在线会议上展示了这项工作。团队提出的Attention-Gated Brain Propagation (BrainProp) 机制，在数学上等效于误差反向传播，相比于反向传播算法要慢2到3倍。Roelfsema表示，「它打败了所有其他在生物学上合理的算法。」尽管如此，仍然无法证明人类大脑真地在使用这些似是而非的机制。斯坦福的Yamins 和他的同事提出了一些方法，来判断哪些学习规则是正确的。通过分析1,056个实现不同学习模型的人工神经网络，他们发现，通过在一段时间内识别一组神经元的活动，可以鉴别出该神经网络的学习规则类型。这些神经元的活动可以从猴子的大脑记录中得到。
  - ![](https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F0228%2F03d557fep00qp8evu0029d200fk00klg00fk00kl.png&thumbnail=650x2147483647&quality=80&type=jpg)
  - ![](https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F0228%2F98f17815p00qp8evu001kd200fk00cng00fk00cn.png&thumbnail=650x2147483647&quality=80&type=jpg)
  - ![](https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F0228%2F83ce12e7p00qp8evu002nd200fk00pgg00fk00pg.png&thumbnail=650x2147483647&quality=80&type=jpg)
- 【2020-7-28】实现AI一般有三条路径：
   - 1）**神经**科学：自底向上，模仿生物；
   - 2）**认知**科学：自顶向下，构建认知框架；
   - 3）**计算**科学：模拟神经活动（例如DNN）。
![](https://p26-tt.byteimg.com/img/pgc-image/8c84b15be9c54b76acb45b5396b0242a~tplv-obj:523:291.image)
- 最为理想的研究状态是：
  - 首先由神经科学发现大脑的一些信息加工的机制；
  - 然后用认知科学的方法对这种机制进行建模；
  - 在此模型之上，计算科学抽象出算法，从而获得一套解决问题的方案。
- 简单来说，即将认知神经科学与人工智能结合，分别从生物视觉的硬件层、模型层、算法层进行研究。

- 【2019-11-13】[综述：全面介绍脑连接研究的方法学](https://mp.weixin.qq.com/s?__biz=MzI2ODEyOTE3OQ==&mid=2649569369&idx=1&sn=210bb5d90c308ff5072fabb6645c85b9&chksm=f2eddeadc59a57bb7192738d35d5d4f8a078f7c20038c9bcce3183ce308fa3be74d10476ad5a&mpshare=1&scene=23&srcid&sharer_sharetime=1573616516238&sharer_shareid=b8d409494a5439418f4a89712efcd92a%23rd)

- 【2020-7-12】[天道](https://www.ixigua.com/6805386709845410318)：透视社会有三个层面：`技术`、`制度`和`文化`，小到一个人，大到一个国家、民族，任何一种命运，都是一种文化属性的产物，强势文化造就强者，弱势文化造就弱者。这是规律，也可以理解为天道，不以人的意志为转移。强势文化在武学里称之为秘笈，弱势文化因为易学、易懂和易用，就成了流行品种。文学影视是扒拉灵魂的艺术，如果文学影视能够破解更高思维空间的文化密码，那它的功效就在于启迪人的觉悟，震撼人的灵魂，这就是众生所需。就是功德、名利和市场。精神拯救的暴利，和毒品麻醉的暴利，完全等值


- 【2020-7-30】[沈向洋：从深度学习到深度理解](https://www.toutiao.com/i6854955754193945096/?tt_from=mobile_qq&utm_campaign=client_share&timestamp=1596065543&app=news_article&utm_source=mobile_qq&utm_medium=toutiao_android&use_new_style=1&req_id=2020073007322301014412006713A3E050&group_id=6854955754193945096)
   - 现状：NLP需要更多参数，视觉需要更多层网络
   - ![](http://p1-tt.byteimg.com/large/pgc-image/S69UvxE2u3vZ2C?from=pc)
   - 这三个方面在实现robust AI时大有可为：
      - 其一，构建大规模的强机器学习仿真器。不仅是游戏，还有自动驾驶等复杂系统。
      - 其二，对于机器学习本质的深度理解。从优化功能开始，思考我们从里面真正学到的是什么。
      - 其三，基于神经与符号的混合模型（Hybrid Neural/Symbolic Model for Robust AI）。——今天演讲的重点
   - 雷蒙德微软研究院写了一篇论文，题目为《SOLOIST: Few-shot Task-Oriented Dialog with A Single Pre-trainedAuto-regressive Model》，文章中提出了一种新的方法，能够利用迁移学习进行高效地大规模构建面向任务的对话系统。
   - 文章有两个亮点
      - 其一是有个预训练模型GTG（Grounded Text generator）
      - 其二是该方法实现了真正的会话学习。下面我主要讲讲GTG。
   - ![](http://p1-tt.byteimg.com/large/pgc-image/S69UvxiDrKbqBH?from=pc)
   - GTG模型与GPT模型对比也有比较大的优势：GPT是学习如何理解和生成自然语言，而GTG是学习预测对话状态，产生grounded responses（真实响应）来完成任务。

- 【2020-9-5】[戴琼海：深度学习遭遇瓶颈，全脑观测启发下一代AI算法](https://www.toutiao.com/i6867958040830837256/)
![](https://p6-tt.byteimg.com/origin/pgc-image/S9SNAiKA50i3tG?from=pc)
![](https://p6-tt.byteimg.com/origin/pgc-image/S9SNAioHQBerMW?from=pc)
![](https://p1-tt.byteimg.com/origin/pgc-image/S9SNAjF8XOMAe3?from=pc)
- 利用脑观测成果启发人工智能理论应该还大有可为。
![](https://p6-tt.byteimg.com/origin/pgc-image/S9SNAjdEmZVr3j?from=pc)
![](https://p6-tt.byteimg.com/origin/pgc-image/S9SNAkC7SXcarK?from=pc)
- 近年来，脑科学和人工智能是两条平行线，互不相交。在未来，我们需要在两者之间构建一个桥梁，即认知计算。认知计算是通过先进神经技术揭示脑结构、脑功能与智能产生的多层次关联与多模态映射机制，从而建立认知模型与类脑智能体系的科学。
![](https://p6-tt.byteimg.com/origin/pgc-image/S9SNDpiDatW4iK?from=pc)
- 对1906年来脑科学和人工智能的重要成果进行了调研，这些研究分别探索了人类的思考模式以及机器的思考模式
![](https://p1-tt.byteimg.com/origin/pgc-image/S9SNDqG1c4SWtO?from=pc)
![](https://p6-tt.byteimg.com/origin/pgc-image/S9SNDrB5fGyDbI?from=pc)
![](https://p1-tt.byteimg.com/origin/pgc-image/S9SNGvP81HYn4c?from=pc)

- 【2020-9-19】[颜水成&刘嘉：机器学习与认知神经的火花碰撞](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247508222&idx=1&sn=fedb8b7883838c037f36b25f108541df&chksm=ec1c4d07db6bc4119a1c7c3e4523cb36ec826e7a9f7cc2fbb350d83144e7dff0c7057a4ca01b&mpshare=1&scene=23&srcid=0919C6RPLiswXQvHXKhCl0hB&sharer_sharetime=1600528849801&sharer_shareid=b8d409494a5439418f4a89712efcd92a#rd)
   - 刘嘉认为，通过对人脑的类比或仿真，科学家更易在创造智能体的工作上取得成功。科研领域的重大突破往往产生于**交叉领域**。因为在交叉地带，一个未知的领域，最可能产生新的东西。
   - 知识图谱+深度学习，或许能够解决人工智能所面临的困境，但显然不是唯一解。将常识与深度学习进行融合，来创造一个在他们看来有认知的智能体。这种“认知”与神经科学家们所理解的“认知”不是同一个概念
- （1）一、GPT-3剖析
   - GPT-3非常了不起,可能是深度学习巅峰式的成果，但GTP-3和人的思维，在本质上是不一样的，它的推理方式更多的是一种**概率上的连接**，可能在训练的数据中出现了“脚”与“眼睛”的某种关联，它就学习出两者之间一种概率链接，在这个过程中，它并没理解“脚”和“眼睛”是什么。而人类则是先理解后推理。
   - GPT与非常庞大的知识图谱进行融合，这与我们大脑的运行机制越来越像，如果摔倒了，知识图谱推理出要受伤，但人的第一反应则是自己感到疼，这是一种共情能力，是基于我们对他人心理的一个推理，猜测他现在的感受
- （2）二、System 1 & System 2
   - Bengio等人提出人工智能将从System 1（潜意识，反应比较快，但不需要做推理） 转向 System 2（显意识，需要一个推理、判断的过程）。
      - 人类有两套系统，一套是皮层下系统，对应脑干等中枢系统；一套是皮层系统，对应大脑皮层。这种结构归因于人类的大脑是从低等动物一点点积累起来的。前者比较古老，主要掌管呼吸、心跳等比较初等但与我们生存有密切关系的活动，所以反应比较快，例如我们看到一个老虎出现，它会立刻加强肾上腺素，做出应激反应；而后者，更多的是去理解到底发生了什么事，然后做出推理和判断，例如我们发现原来这个老虎是人扮的，这时皮层系统就会告诉皮层下系统，从而调节原来的紧张。
      - 这两套系统物理上完全独立，但有交互
   - 人脑学习机制，将System 1和System 1类比开车，熟悉的道路直接操作，不用过多思考，而陌生的路就开始调动推理能力
      - 学习的过程中，最开始我们不知道怎么去表征外部的世界，在这种情况下，大脑神经的反应模式基本上就是，让与它相关区域的所有神经元全都活动；但第二次可能就只有40%的神经元活动，因为其他的神经元活动已经没有任何意义了；经过反复的学习之后，最终可能只有4、5个神经元去反应，这就是所谓的Sparse Coding。经过Sparse Coding之后，系统会集中在一个特定的任务上，变得非常精准且高效。在这个过程中，开始时需要更多的意识参与，然后逐渐减少而变得自动化。
      - 还需要一个警觉系统。学会走路后，我们根本不去关心应该先迈哪只脚，以及应该迈多远，完全可以一边走路一边脑袋里想着自己的事情。直到我们突然踩了一个坑，这时候我们的警觉系统就开始起作用了，它会快速启动System 2，对 System 1进行干涉，让你保持平衡而不会摔倒。然后你的视觉注意到原来前面是个大坑，于是马上反应过来改变路径。这个警觉系统就在我们大脑内侧，叫“前扣带回”。
- （3）三、大脑如何处理视觉信息
   - 早在1968年，两个诺贝尔奖获得者Hubel和Wiesel他们对猫做实验，将细小的探针插入到神经元上去，然后给猫一个刺激，例如点、线以及其他复杂的图形，然后看不同的刺激会引起哪个脑区的兴奋。他们发现V1、V2、V3、V4等脑区，越往后面敏感的图形越复杂。这个研究说明，我们的大脑在处理视觉信息时，是将复杂的图像还原成局部元素，然后再进行合成的。这种方法事实上到现在仍然在用。
   - 图见原文
- （4）四、关于记忆
   - 人会经常忘记一些事情，特别是老年人。那么我们的记忆是真的从脑子里完全消失了，还是被打包存储在记忆深处某个地方了？
   - 两种情况都有
      - 不可能记得所有的事情，我们的大部分经历都会被忘掉
      - 记忆还在，但没有找到合适的途径把它提取出来
   - 目前普遍认为人类记忆有**三级加工模型**，分别为**感觉记忆**、**短时记忆**和**长时记忆**。如果一个信息不能转化为长时记忆，即引起神经元突出的持久改变（例如相邻神经元突出结构的变化、神经元胶质细胞数量的增加和神经元之间突出连接数量的增加），那么它就会被我们彻底地遗忘掉。
- （5）五、神经元数目
   - ① 脑神经元的数量从出生之后就不会再增长
      - 变化的是神经突触的数目以及神经元之间的连接。出生时，婴儿大脑皮层突触密度远低于成人；但出生后的几个月内，大脑皮层突触迅速增加，4岁左右，大脑皮层突触的密度会达到顶峰，约为成年人的150%。类比人工神经网络的话，你可以理解为一个全连接系统。随后，随着年龄和经验的增长，突触数目会慢慢减少，一些连接就会剪断。但也正是这样，我们反而变得更加聪明。（新生儿神经连接逐渐完善，见原文）
   - ② 神经元数目可能不一样。会因为神经元数量的多少，影响我们的智力水平吗？
      - 不同的人神经元数目不同，但人类的智商似乎不受神经元数目的影响，或者至少可以说神经元数目不是决定智商的本质因素。
      - 男性的大脑平均而言要比女性重100克左右。但从来没有任何证据表明男性会比女性更聪明。从IQ上来讲，两者是一样的。图见原文
      - 一个大致的估计认为，人类的神经元数量在800亿到1000亿之间，也即是说，不同的人之间相差100亿个神经元是一件很正常的事情
      - 猜测：真正决定人类智能的，不是神经元的数量，而是它们之间的连接。这些连接很大程度上取决于后天的学习。
- （6）六、通用智能与神经元数目
   - 人工智能超越人类智能，只是一个时间问题，因为它有无限的算力、无限的存储能力，能够无限地扩展下去。而人不行，出生后就不会增长。
   - 通用智能其实不是人类所特有的，是所有生物体都有的。
      - 例如斑马鱼只有80万~100万个神经元；小鼠有1亿量级的神经元；狨猴神经元量级在10亿左右；恒河猴在百亿；而人类在千亿量级。但无论是斑马鱼也好，还是老鼠、狨猴、恒河猴，或者人类，它们都具有通用智能。图见原文
   - 生物智能应该有一套规则，这套规则本身与神经元数量无关，而正是这套规则使得我们生物具有了通用智能。也正是这样的规则使得斑马鱼与GPT-3有明显的区别。一旦把这种通用智能的规则搞清楚了，加上人工智能的无限可扩展能力，未来的人工智能发展，将不可限量。
- （7）七、Baby Learning 有无生理基础？
   - 人类的学习过程，大多情况下是一种无监督学习，通过在物理世界中，跟环境接触/观察，从而引起突触的变化。这根GPT-3有很大差别
   - “Baby Learning”的概念，核心就是要摆脱现在依赖标签数据的现状，给一些数据，能够从数据中自动学习出一些知识来。现在人工智能里面也有两个方向
      - 一个叫自训练，也即从数据中预测标签，然后用预测标签作为新的标签，来帮助训练模型；
      - 另一个叫自监督学习，也即通过pre-text tasks来训练。
   - 从发育的角度来看人类智能的发展，现在还处于一个比较分离的状态。
   - 大家目前的研究更多地集中在认知功能的变化上，但这些却缺少神经学上的证据。
   - 另一方面，我们对神经元突触之间的连接怎么搭建有了很好的研究，但却忽略了它功能上的变化，即为什么会这么搭，搭建之后发生了什么改变等，却不清楚。这是目前研究的一个空白点，背后的主要原因是**伦理的约束**。
- （8）八、大脑噪声的模式
   - 什么因素让突触从原来连接状态变成不连接，或者反过来？
   - 上世纪50年代，一位神经生理学家唐纳德·赫布曾提出一个理论“`赫布理论`”，描述了突触可塑性的基本原理。简单来说就是“Cells that fire together, wire together”，即当两个神经元同时发放时，它们就会产生连接。
   - 大脑里有很多噪音，神经元一些自主地放电活动，即使处于静息状态也会有，这些噪音事实上消耗了大脑95%的能量。过去认为噪声就只是噪声。但大约在10年前，神经科学家们发现，其实这些噪音是有模式的，正是这种模式试图把不同的神经元进行沟通。图见原文
   - 两个神经元以同样的频率同步发放信号，那么他们就会保持一种连接状态；而如果它们是异步发放噪音，那么即使它们现在处于连接状态，这种连接也会慢慢衰退。
- （9）九、认知的两套模型：规则+推理
   - 如果某个样本只出现少数几次的话，最好的策略就是直接把这个样本存储下来，而非再用它去训练模型；需要的时候直接查询匹配即可；而对那些经常出现的样本，则需要训练模型，通过模型来查找。
   - 大脑就是采用的这种机制，我们称它为“混合模型”
- （10）十、大脑中的跨感觉影响
   - 大脑对视觉和听觉的处理有显式分区，图见原文
   - 不同的感知信息处理模块之间，并不是完全独立的，而是随时在发生相互影响。
- （11）十一、大脑中，常识是怎么存在的？
   - 最开始我们认为常识完全与后天经验有关，是一种知识。但现在逐渐意识到，常识可能不是一种知识，而是一套规则。
   - 有大量证据表明，许多常识来自于先天的基因。
- （12）十二、记忆提取的野火模型
   - 看到一位非常熟的人，但怎么也想不起他的名字，然后当有一个极小的线索出现的时候，一下子就想起来了。这个过程，在大脑中到底发生了什么？
   - 这种现象叫做“野火模型”（注：在心理学中常叫做“激活扩散模型”），从一点把火点起来，它就会往四周燃烧；一个线索的出现就会把相邻的东西给激活。
   - 智能的目的是什么。从认知神经科学角度的一个理解认为，智能的目的就是对变化环境的适应。从这个角度来评价重要性问题。
- （13）十三、学习不是孤立的过程
- （14）十四、精确测量每个神经元
   - 当前的技术可以精确地测量每一个神经元的Action吗？
   - 以前不可以，现在已经可以通过双光子显微成像技术等精确记录一个神经元及它的发放过程了。现在准确记录大脑所有神经元的每一刻活动只是一个时间和技术问题。
- （15）十五、不同生物，神经元一样吗？
   - 基本上是类似的。神经元本身有很多种类型，但在动物中，大家的神经元类型基本上是差不多的
- （16）十六、大脑可以复制吗？
   - 记忆是否能够下载到一台计算机中？如果可以，那就意味着永生，因为记忆是我们最核心的东西。
   - 把大脑切片，切得足够精细，重现所有连接。但它会产生同样的功能吗？不会。
- （17）十七、梦的解析
   - 睡觉的时候，其实大脑仍然在工作，会清洗掉一些信息，以便第二天继续工作。关于梦，从神经科学的角度怎么解释？
   - 人可能是动物中唯一一种有深度睡眠的动物。像鸟、马等，它们在睡觉的时候，其实不是两个半球同时沉睡，而是交替入睡。
   - 人类的这种睡眠模式，对人类智力的提升可能起到一个非常关键的作用。为什么呢？我们人类在睡觉的时候，其实大脑并没有完全休息，他在重放我们白天所经历的一些事情，把其中关键的信息提取出来，并遗忘掉哪些不重要的东西。我们白天所感知到的信息都是具象的，但经过我们大脑这种睡眠时的重放，就能够变成一种抽象的东西。这个过程，我们现在知道它发生在海马体，海马体与我们的记忆和学习有关。
   - 梦的定义就是一种学习；其次它也在不断地做不同的假设。人的学习是一种主动学习，学习之后会做一些预测，当然这些推测很多时候是不靠谱的，所以你会觉得梦稀奇古怪的，没有任何逻辑目的。
   - 有些时候人在梦境中是知道自己在做梦，这是因为我们的意识在随时在监视大脑，这个时候，会感知到自己在做梦。
- （18）十八、神经元的复杂度
   - 神经元的胞体和突触都在进行信息处理，它们的复杂度在量级上哪个为主？胞体复杂度更高
   - Threshold是神经元的一个功能，但这里强调的是，目前的DNN是没有神经元胞体的成分的。
- 现在人工智能的研究有两种方式
   - 一种是不管人脑怎么干，我们凭经验设计一套规则来做；
   - 另一种是看人的智能是怎么产生的，然后进行类比或仿真。
   - 我觉得后者成功的概率会更大一些。


## 恐怖谷定律

- 【2020-11-12】恐怖谷（Uncanny Valley）最早是在机器人、3D电脑动画和计算机图形学（Computer Graphics,简称CG）领域存在着一个的假设。这个假设是由日本现代仿真机器人教父级人物**森政弘**（Masahiro Mori）于1970年提出：当仿真机器人的外表和动作像真实人类，但又不是完美拟合时，作为观察者的人类会产生厌恶反应。
- 我们对于机器人的情感反应是随机器人和人类相似程度的增加而增加的，然而当相似度达到一定比例，我们的情感会突然逆转，产生厌恶感，而随着相似度的继续增加，我们的情感反应才会再次爬升起来。
- 恐怖谷不是人类所独有的，很可能是进化的产物。2011年，加州大学圣地亚哥分校的认知科学家艾谢•瑟金（Ayse Saygin）和同事们从认知神经科学的角度研究了在观看机器人、仿真机器人和人类运动时，大脑皮层中到底发生了什么不同的活动。结果发现在运动感知系统（Action Perception System，APS，自身实施动作和观看他人动作时均会有所反应）中，的确会随刺激类型的不同而有不同的激活。相较于机器人和人类，在观看仿真机器人的活动影像时，大脑与运动感知系统相关的区域活动更加活跃（如上图）。这一结果恰恰可以运用认知失调的逻辑来解释，即当我们看机器人和人类活动时，他们就如我们预期的一样，而仿真机器人却不同，他们外观酷似人类，而动作却和机器人相同，这在我们头脑中造成了与预期不符的矛盾，从而要调动更多的大脑区域来调整这些矛盾。
- ![](https://2-im.guokr.com/gkimage/xl/jn/zb/xljnzb.png)
- 参考
   - [恐怖谷：娃娃为什么很可怕？](https://www.guokr.com/article/146004). 
   - [恐怖谷现象如何产生](https://www.zhihu.com/question/25865403) 
   - ![](https://pic1.zhimg.com/80/v2-07c5d951387f2454d7ab9023e391227b_720w.jpg?source=1940ef5c)
   - [可爱与可怕仅一步之遥](https://www.bilibili.com/video/BV1Vk4y127bM)
   - <iframe src="//player.bilibili.com/player.html?aid=754321911&bvid=BV1Vk4y127bM&cid=224994851&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"  height="600" width="100%"> </iframe>
   - [恐怖谷理论的六种解释](https://www.bilibili.com/video/BV1Bk4y167nq)
   - <iframe src="//player.bilibili.com/player.html?aid=753265971&bvid=BV1Bk4y167nq&cid=195539386&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

# 人工智能十大里程碑

- 【2019-10-17】摘自：[人工智能十大里程碑](https://www.toutiao.com/a6748617986803761668/?timestamp=1571413762&app=news_article_lite&group_id=6748617986803761668&req_id=201910182349220100260772071E2002D3)
 
从AI换脸到AI试穿，再到AI助“数字永生”……如今，人工智能正全方位渗透到我们的生活中，重要且不可忽视。
 
## 艾萨克·阿西莫夫提出“机器人三大定律”（1942）

1942年，艾萨克·阿西莫夫（IsaacAsimov）发表了短篇小说《转圈圈》(Runaround，又译作《环舞》)。这位著名的科幻作家首次完整地阐述了他的“`机器人三大定律`”：
- 第一定律：机器人不得伤害人类，或因不作为而让人类受到伤害。
- 第二定律：机器人必须服从人类的命令，除非这些命令违背了第一定律。
- 第三定律：在不违背第一与第二定律的前提下，机器人必须保护自己。
 
《转圈圈》讲述的是一个名叫速必敌（Speedy）的机器人，它接受了人类的命令，去危险的硒溶池执行采集任务。当它越来越靠近目的地，危险的程度越来越高，第三定律让它不得不离开以保护自己；但当它开始远离目的地，第二定律又让它必须服从命令前进。因此，它被置于一个前后两难的矛盾境地，围绕着硒溶池不停地转圈圈。
 
![人工智能十大里程碑](http://p3-tt.byteimg.com/large/pgc-image/c64f87a4e1f44f0382b6079be3eee6d1?from=pc)
 
水星上，两名宇航员寻找不停转圈圈的速必敌
 
阿西莫夫的“机器人”系列故事吸引了很多科幻迷，其中的一些科学家开始思考机器拥有思考能力的可能性。直到现在，仍有许多人使用阿西莫夫的三大定律，进行人工智能的智力练习。
 
## 艾伦·图灵提出模仿游戏（1950）
 
1950年，艾伦·图灵（Alan Turing）写道：“我提议考虑一个问题——‘机器能思考吗？’”这句话是其开创性的研究论文《计算机器与智能》的开头。该论文提出了一个思考机器智能的模型。他反问道，如果一台机器能够模仿人类有意识的行为，难道它不会有意识吗？
 
![人工智能十大里程碑](http://p3-tt.byteimg.com/large/pgc-image/862a335697d44df58ec67e868a3ccf8d?from=pc)
 
艾伦·图灵在1950年首次提出了判断机器意识的基准
 
受到理论性问题的启发，图灵经典的“模仿游戏”诞生了。游戏设置了三个角色，人、机器和人类“询问者”。“询问者”需要与其余二者在物理空间上分隔开。“询问者”发起提问，且根据二者的纯文本回应（避免声音回答产生干扰），区分机器和人。如果一台机器能够与人类沟通（注：图灵认为理想情况是使用Teleprinter，即“电传打字机”），且让“询问者”难以分辨人与机器的分别，那么这台机器就被认为具有智能。
 
在图灵时代，没有一台机器能够通过这样的测试，直到今天也没有。但他的测试为区分机器是否具有智能提供了一个简单的标准。它帮助塑造了人工智能的哲学。
 
## 达特茅斯举办人工智能大会（1956）
 
到1955年，世界各地的科学家已经开始思考一些概念问题，比如神经网络和自然语言，但还没有统一的概念来概括这些与机器智能有关的领域。

达特茅斯学院（Dartmouth College）数学教授约翰·麦卡锡（John McCarthy）创造了“人工智能”这个术语来囊括这一切。
 
由麦卡锡领导的一个小组申请了拨款，在第二年举办了一场人工智能大会。1956年夏天，他们邀请了许多顶尖科研人员到特茅斯礼堂参加会议。科学家们讨论了人工智能研究诸多的潜在发展领域，包括学习和搜索、视觉、推理、语言和认知、游戏（尤其是国际象棋），以及人机交互（比如个人机器人）。
 
![人工智能十大里程碑](http://p3-tt.byteimg.com/large/pgc-image/9763ef28e9af41d79d4b5ca29d30a856?from=pc)
 
这场讨论达成的普遍共识是，人工智能具有造福人类的巨大潜力。他们得出了一个“机器智能可能产生影响的研究领域”的总体框架。这次会议规范并促进了作为一门研究学科的人工智能在此后多年的发展。
 
## 弗兰克·罗森布拉特创造了感知机 （1957）
 
神经网络的基本结构被称为“感知机”（Perceptron），相当于节点（node），接收一系列输入并进行计算，对其进行分类和置信水平分析。举例而言，“输入”可能会分析一张图片的不同部分，并对图像中是否有人脸进行“投票”。节点将会对投票行为和置信水平进行计算，并得出结论。今天，在强大的计算机上运行的人工神经网络，连接了数十亿计这样的结构。
 
但在强大的计算机出现前，感知机就已经存在了。20世纪50年代末，一位年轻的心理学家，弗兰克·罗森布拉特（Frank Rosenblatt），为一台名为Mark I的感知机建立了一个机械模型。
 
![人工智能十大里程碑](http://p3-tt.byteimg.com/large/pgc-image/289c6bd534724ab9a02ce2d5c2e4a963?from=pc)

弗兰克·罗森布拉特在康奈尔航空实验室建立了一个“神经网络”

这台机器是为图像识别而设计的。它是一个模拟神经网络，其中的感光单元矩阵通过导线与节点相连。罗森布拉特开发了一种“感知机算法”，引导网络逐渐调整其输入强度，直到它们始终正确地识别图像，从而有效地让它进行学习。
 
当时，罗森布拉特受到美国海军的经费资助，召开了新闻发布会。《纽约时报》抓住了发布会的要点：“海军透露了一种电子计算机的雏形，希望未来它能够走、说、写、看、自我复制并意识到自己的存在。”如今，这台最早的感知器存放在美国的史密森尼博物院（Smithsonian）中。直到20世纪80年代，科学家们还在激烈地讨论感知机的相关问题。这对于创建神经网络的物理实体非常重要，而在此之前，神经网络主要是一个学术概念。
 
## 人工智能的第一个冬天（20世纪70年代）
 
人工智能已经将其大部分的历史投入到研究领域中。在20世纪60年代的大部分时间里，美国国防部高级研究计划局（DARPA）等政府机构为研究投入大量资金，但对于最终的回报要求不多。与此同时，为了保证经费充足，人工智能的学者经常夸大他们的研究前景。这一切在60年代末70年代初发生了改变。
 
1966年，语言自动处理咨询委员会（ALPAC）向美国政府提交了一份报告；1973年，英国科学研究委员会（SRC）向英国政府提交了一份由知名应用数学家James Lighthill爵士带头起草的报告。两份报告都对人工智能研究各个领域的实际进展提出了质疑，它们看待技术前景的态度也非常悲观。Lighthill报告认为，用于语音识别等任务的人工智能很难扩展到对政府或军方有用的规模。
 
![人工智能十大里程碑](http://p3-tt.byteimg.com/large/pgc-image/541493f23e384bed9e3a7418a866caf2?from=pc)
 
1973年BBC录制的AI拥护者与反对者James Lighthill的辩论。因此，美国政府和英国政府都开始削减大学人工智能研究的资金。在上世纪60年代的大部分时间里，DARPA一直慷慨地提供人工智能研究经费。如今，DARPA要求研究计划必须有明确的时间表，并且详细描述项目成果。当时的人工智能似乎是让人失望的，它的能力可能永远达不到人类的水平。人工智能第一个“冬天”一直持续到70年代，并且继续蔓延到80年代。
 
## 人工智能迎来第二个冬天（1987）
 
20世纪80年代的人工智能发展，是随着“专家系统”（Expert Systems）的发展与大获成功开始的。专家系统是一种模拟人类专家解决领域问题的计算机程序系统。系统内存储了大量领域知识，并模仿人类专家来做出决策。这一系统最初是由卡内基梅隆大学为数字设备公司（Digital Equipment Corporation）开发的，后者迅速采用了这项技术。但是专家系统需要昂贵的专用硬件支持，这就出现了一个问题：当时，Sun Microsystems的工作站、Apple和IBM的个人电脑都拥有近似的能力，但价格却更低。1987年，专家系统计算机的市场崩溃了，主要供应商黯然离场。上世纪80年代初，专家系统的繁荣让DARPA增加了对人工智能研究的资金投入。但后来情况再次发生了改变，除了少数人为挑选的项目以外，DAPRA再次切断对于其他人工智能项目的大部分资助。
 
“人工智能”一词再次成为研究领域的禁忌。为了避免被视为不切实际、渴求资助的“梦想家”，科研人员开始为人工智能相关的研究冠上不同的名称——比如“信息学”、“机器学习”和“分析学”。
 
第二个“人工智能冬天”延续到了2000年代。
 
## IBM的深蓝击败卡斯帕罗夫（1997）
 
1997年，当IBM的深蓝国际象棋（Deep Blue chess）电脑在国际象棋比赛中击败了当时的世界冠军加里•卡斯帕罗夫（Garry Kasparov）时，人工智能的公众形象大幅提升。在电视直播的六场比赛中，深蓝赢了两场，卡斯帕罗夫赢了一场，其中三场以平局告终。在前一年，卡斯帕罗夫击败了早期版本的“深蓝”。
 
![人工智能十大里程碑](http://p6-tt.byteimg.com/large/pgc-image/3529dd71cd7e42c387abb7b6fdf124d3?from=pc)
 
1997年，IBM的深蓝击败了世界上最好的人类棋手加里·卡斯帕罗夫
 
深蓝拥有强大的计算能力，它使用了一种“蛮力”的方法，每秒评估2亿种可能的走法，从而找到最佳走法。而人类每回合只能检查大约50步。深蓝达到的效果就像人工智能一样，但是计算机此时还并没有真正地在下棋中思考策略、自主学习。尽管如此，深蓝的胜利还是将人工智能非常高调地带回了公众视野。有人很着迷，也有人则对机器打败顶尖的人类棋手这件事感到很不自在。令投资者难以忘怀的是：深蓝的胜利推动IBM股价上涨了10美元，创下了历史新高。
 
## 神经网络看到猫（2011）
 
到2011年，世界各地的科学家都在讨论并创造神经网络。那一年，谷歌工程师杰夫·迪恩（Jeff Dean）遇到了斯坦福大学计算机科学教授吴恩达（Andrew Ng）。两人萌生了建立一个大型神经网络的想法，利用谷歌的服务器资源为其提供强大的计算能力，并向它输送海量的图像数据集。他们建立的神经网络在16000个服务处理器上运行。他们随机上传了1000万张没有标签的来自YouTube的截图。杰夫和吴恩达并没有要求神经网络提供任何特定信息，或标记图像。当神经网络在“无监督”的状态下运行时，它们自然会试图在数据找到模式，并形成分类。
 
神经网络对图像数据进行了为期三天的处理。然后，它返回了一个输出，该输出包含了三个模糊图像，这些图像描述了它在测试图像中一次又一次看到的“图案”——人脸、人体和猫。
 
![人工智能十大里程碑](http://p6-tt.byteimg.com/large/pgc-image/5747c02ee4bf456bbddf0bb48ab1ede2?from=pc)
 
神经网络对图像数据的处理

在计算机视觉任务中使用神经网络和无监督学习，该研究是一个重大突破。这个事件也标志着“谷歌大脑项目”（Google Brain Project）的开始。
 
## 杰弗里·辛顿解放了深层神经网络（2012）
 
在杰夫和吴恩达取得突破性进展之后的一年，多伦多大学教授杰弗里·辛顿（Geoffrey Hinton）和他的两个学生建立了名为AlexNet的计算机视觉神经网络模型。2012年，在著名的ImageNet的图像识别大赛当中，AlexNet一举夺冠。参赛者必须使用自己的系统来处理数百万的测试图像，并且以尽可能高的准确率进行识别。AlexNet赢得了比赛，错误率不到亚军的一半。AlexNet的Top-5错误率是15.3%；而在2012年以前，最好成绩是26%的错误率。
 
注：Top-5错误率是ImageNet大赛的评价标准之一。简而言之，大赛给图片类别设置了近千项“分类”，而模型识别图片时，会给出其预测的“分类”概率排名。对于某个图片，如果该模型预测结果中，预测概率最大的前5项都不吻合实际结果，则算“错误”。这一成功有力地证明，深度神经网络在对图像进行准确识别和分类方面远远优于其他系统。这次夺冠影响极其深远，使深度神经网络得以复兴，也为辛顿赢得了“深度学习教父”的绰号。辛顿和他的同事约舒亚·本乔（Yoshua Bengio）、扬·勒昆（Yann LeCun）一起获得了2018年图灵奖。
 
## AlphaGo打败人类围棋冠军（2016）
 
早在2013年，一家名为DeepMind的英国初创公司的研究人员发表了一篇论文，展示了他们如何使用神经网络来赢得50种老式的雅达利游戏（Atari）。令人印象深刻的是，谷歌以4亿美元的价格收购了这家公司。不过，DeepMind的光辉岁月还未到来。
 
几年后，DeepMind的科学家们（现属于谷歌）从雅达利游戏转向人工智能的长期挑战之一——围棋。他们开发了一个名为AlphaGo的神经网络模型用于玩围棋，并通过玩来学习。该模型与其他版本的AlphaGo进行了数千场比赛，学习AlphaGo的输赢策略。
 
它居然成功了。2016年3月，AlphaGo在一系列比赛中以4比1击败了世界上最伟大的韩国棋手李世石（Lee Sedol）。整个事件被拍成了纪录片。
 
![人工智能十大里程碑](http://p1-tt.byteimg.com/large/pgc-image/554a72d41bb04a659f00891192aae90a?from=pc)
 
 
人类顶尖棋手与AlphaGo的交战
 
观看这部片子的时候，我们很难忘记李世石被击败时的悲伤。看起来就好像人类——而不仅仅是一个人——被打败了。在深度学习产生了广泛影响的同时，人工智能的故事只是刚刚开始。
 
我们已经进入一个崭新的时代。人工智能仍将充满希望，裹挟着炒作与浮躁。它所带来的，也许将远远超过个人计算和互联网在过去30年对世界造成的改变。带着对未来的期许，让我们回到图灵一开始提的问题：“机器能思考吗？”可能不需要再次历经70年的求索，答案也许就在这个十年。




# 人类唯一的出路：变成人工智能

- ![](https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2015/03/Logo-sometimes-Pixelmator-577.png)

- Tim Urban，之前火热的文章《为什么有很多名人让人们警惕人工智能》也是出自他手，英文原文刊载于waitbutwhy.com，点击文末的阅读原文可以跳转到原文链接。
>Wait but Why的作者Tim Urban 是埃隆马斯克（特斯拉/SpaceX创始人）强烈推荐的科技博主。他写的AI文章是全世界转发量最高的。他的粉丝还包括：Facebook创始人马克扎克伯格，Facebook COO谢丽桑伯格等。Tim也是TED演讲平台上有史以来最受欢迎的演讲者之一

在一个由人工智能和“其他所有生物”组成的未来， 人类只有一条出路：“变成人工智能。

本翻译版本由谢熊猫君提供，全文共六万字。两百余张图片，分成六个章节，将分成五篇推送完成。
- 第一章：人类巨灵 （约7000字）简述人类语言、智能和人类巨灵的崛起
- 第二章：大脑 （约8000字）简述大脑结构，为了解脑机接口提供基础知识
- 第三章：脑机接口（约12000字）讲述脑机接口的基本原理和目前的技术水平
- 第四章：挑战（约8000字）讲述目前脑机接口跨越到全脑接口所要面临的挑战
- 第五章：魔法纪元（约13000字）全脑接口实现后未来的人类会是怎样
- 第六章：大融合（约10000字）人类唯一的出路：变成人工智能

注：
- 原文请看:[人类唯一的出路：变成人工智能](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649768466&idx=1&sn=b6b1720b7a2243ab3907c58d2b22a602&chksm=bec3df0f89b456198c4960da99e46075f2bef121320f52a805b19f9143f5c083f6bac9430e97&token=832591528&lang=zh_CN#rd)，篇幅所限，不含第四章和第六章
- [微云完整版](https://docs.qq.com/doc/DZlN3ZlBJS3pnSVBN)
- 60页的打印版下载，[链接](https://share.weiyun.com/5rFS3oT) 密码：tvr5sa

> * 全文地址：[【完整版】人类唯一的出路：变成人工智能](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649768466&idx=1&sn=b6b1720b7a2243ab3907c58d2b22a602&chksm=bec3df0f89b456198c4960da99e46075f2bef121320f52a805b19f9143f5c083f6bac9430e97&token=832591528&lang=zh_CN#rd)
> * 原文地址：[英文版-
Neuralink and the Brain’s Magical Future](https://waitbutwhy.com/2017/04/neuralink.html)
> * Word文档版：[腾讯文档](https://share.weiyun.com/5y4D89d)
 
# 实际案例

![](https://mmbiz.qpic.cn/mmbiz_jpg/V1OJoKudbibamvvRKM6jYFt5Gf2wz9BHR92gRojGfZMFMR6ocnDNSicGKCfncAjtWClicU2rHDicmSt0OjibUFTLpjA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 【2020-1-16】浙江大学：[国内首例植入式脑机接口让“意念”控制机器臂](https://mp.weixin.qq.com/s/X58bAYMPGDtw-IC7aOcAZg)
   - 1月16日，浙江大学对外宣布“双脑计划”重要科研成果，求是高等研究院“脑机接口”团队与浙江大学医学院附属第二医院神经外科合作完成国内第一例植入式脑机接口临床研究，患者可以完全利用大脑运动皮层信号精准控制外部机械臂与机械手实现三维空间的运动，同时首次证明高龄患者利用植入式脑机接口进行复杂而有效的运动控制是可行的。
   - 除了吃喝、社交、娱乐外，这项最新成果将有助于肢体瘫痪患者进行运动功能重建，从而提高生活质量，未来也将对辅助运动功能、失能者功能重建、老年机能增强等更多领域产生积极影响。

- 视频：

<iframe src="//player.bilibili.com/player.html?aid=83746758&cid=143264316&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height="600" width="100%"> </iframe>


# [语言的对决：乔姆斯基攻防战](https://www.guokr.com/article/156457/)

## 乔姆斯基

![](https://bkimg.cdn.bcebos.com/pic/e850352ac65c10388ad37ce8b3119313b07e896f)

- 艾弗拉姆·诺姆·乔姆斯基（Avram Noam Chomsky，1928年12月7日—），美国哲学家。是麻省理工学院语言学的荣誉退休教授。乔姆斯基的《句法结构》被认为是20世纪理论语言学研究上最伟大的贡献。


## 攻防战

- [愤怒的语言](https://www.guokr.com/article/156367/)：语言学家丹尼尔·埃弗雷特（Daniel Everett），前往偏远的亚马逊部落毗拉哈（Pirahã），去传播基督教。他原想把《圣经》翻译成当地语言，教毗拉哈人信仰上帝，结果反倒是自己放弃了信仰，不再笃信上帝，也开始质疑自己尊为圣人的语言学前辈，乔姆斯基。
- 诺姆·乔姆斯基（Noam Chomsky）（右图），现代语言学学界领袖，20 世纪最富盛名、最具影响力的学者之一。乔氏及其 “普遍语法论” 执掌现代语言学长达半世纪之久。乔姆斯基认为，语言是人类特有的一种先天机制。2002 年，乔姆斯基在一篇与人合著的论文中提出（或者看似可以理解为），递归性是人类语言唯一至关重要的特性 。
- 而埃弗雷特（左图）发现，毗拉哈语中不存在这种所谓的 “递归性”——毗拉哈人并不将语言单位互相套嵌，而是只讲简单的短句。也就是说，这种语言不符合现代语言学的一项基本原理。这一发现似乎足以颠覆整个语言学体系，事实也的确如此：2005 年，当埃弗雷特的论文发表时，引起巨大轰动，而他跟乔姆斯基的决斗，也就此开始。

![](https://1-im.guokr.com/gkimage/z4/o7/fv/z4o7fv.png)

## 资料

- [20世纪最著名的100位心理学家](https://www.psychspace.com/psych/category-192)：[38 乔姆斯基 Noam Chomsky](https://www.psychspace.com/psych/category-124)
- [【纪录片】乔姆斯基：manufacture consent](https://www.bilibili.com/video/BV1i7411J7qZ)
- [福柯、乔姆斯基的一场世纪辩论——关于人性、公正与权力](https://www.bilibili.com/video/BV1Ht411Y7Nd)
- [诺姆·乔姆斯基访谈——语言与知识【中英文字幕】](https://www.bilibili.com/video/BV1ht411c79j)

<iframe src="//player.bilibili.com/player.html?aid=61449523&bvid=BV1ht411c79j&cid=106886489&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"  height="600" width="100%"> </iframe>

# [语文是一切科学之母](https://zhuanlan.zhihu.com/p/151675013)


## 艺术是最高境界

人类的智慧分为几种境界，其中艺术是最高境界。
- 第一重境界叫`技术`（techniques）。对于一个问题，能给出一个解法的人就算达到这个境界了。这样的人叫 technician（`技术工人`）。大部分程序员是这个级别的。
- 第二重境界叫`科学`（science）。
   - 经历了很多问题，提出了很多解法之后，技工可能会总结出一些规律，称之为`理论`（theory）。
   - 每个 theory 的出发点是一些抽象描述物理世界的`公理`（axioms）。比如欧式几何这个理论有五个公理，就是记录在欧几里得老师的《`几何原本`》（Elements）里的。
   - 从`公理`出发，大家可以按照逻辑可以导出很多`推论`（theorems）。很多推论恰好也符合对物理世界的描述。比如沿着欧式几何的公理，大家推导了两千多年，一些推理帮着人类把阿波罗发射到月亮上还能活着回来
-  *数学真是tmd一个巧合啊* —— 没事没事，**语文才是科学之母**。
- 严正声明，这不是玩笑 —— 20 世纪人类最伟大的科学发现是`哥德尔定理`。
   - 用俗话说，就是沿着逻辑推导，推着推着一定会发现一个推论和之前的某个推论是相悖的，比如一个说老王家的鸡是公的，另一个说老王家的鸡是母的。
   - 所以，真的，用数学计算出来的阿波罗轨迹能把人安全的带回来，真是一个奇迹 —— 说它是公的，它恰好就是公的。
   - 什么样的程序员可以算是 scientist 呢？给定一个问题，能分析设计出**最优解法**的，而不是随便给一个解法了事的。
- 第三重境界叫`哲学`（philosophy）。
   - 小学思想品德课制造的一个误区是让人以为哲学是文科，其实哲学是理科。理工科的硕士研究生毕业之后的学位是 Master of Science。而博士研究生毕业之后就是 Ph.D. 了 —— Philosophy Doctor（哲学博士），也有人说是 permanent head damage，也有道理，不是悖论。
   - 哲学是归纳了很多 theory 的人归纳出来的`原则`（principles），说的是怎么思考问题，可以归纳出好的 theories —— 别从公理出发刚推了没几步就出现悖论 —— 这tm多尴尬）。因为哲学是指导人们归纳 theory 的，所以我们说哲学原理（principles）是帮助我们拓展人类知识边界的工具。
   - 什么样的程序员可以称为哲学家呢？有一套哲学思想叫 [Unix Philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)。看进去就明白了。
- 第四重境界叫`艺术`（art）。
   - Paul Graham 有一本书叫《Hackers & Painters》，说的就是最高境界的程序员和画家一样。徐悲鸿画的马，大家都说好！而且每个人都能说出一些好的理由 —— 比如简练却生动、比如线条刚柔相济、比如动感十足。既然人人都能说出来的评价标准，恐怕算不上 theories，估计可以算 techniques。徐老师无疑是大家！他也明白自己不同寻常，可以他却没法把自己的高才总结成一些 theories 或者 techniques，让徒弟照着弄就能画出一样好看的马。
   - 艺术家的直觉（英语叫 gut feeling，直译为猪肚和肥肠的感受）只可意会，不可言传。汉语里的“道可道非常道”，这个道不是 principles 而是 arts。老子不是哲学家，而是艺术家啊。
   - 有些程序员，每次碰到一个难题，其猪肚和肥肠的都会有一些感受，照着这灵感做，总是没错，基本就是最优选择。如果他不是蒙的，那么他就算一个艺术家了。


# 人工智能哲学笔记

- 【2019-10-24】[人工智能哲学笔记](https://yam.gift/2018/04/07/2018-04-07-AI-Philosophy-Note/)

## 背景
- 来源：[复旦大学公开课：人工智能哲学_全 7 集_网易公开课](http://open.163.com/special/cuvocw/rengongzhinengzhexue.html)
- 讲师：徐英瑾教授
- 课程介绍：本课程从人工智能科学发展的科学史概要出发，讨论了哲学思辨和人工智能研究之间的密切关系，并从人工智能的角度，重新审视了近代欧洲哲学对于 “机器是否能够思维” 这个问题的思辨结论。尔后，讨论了如何从当代计算机科学的角度来解读康德哲学，并从中得到一个关于类比推理的计算模型。本课程也讨论了当代美国哲学家塞尔对于 “计算模型如何获得关于符号的语义知识” 的忧虑，并进一步探讨了这一忧虑在计算机科学内部的表达形式：框架问题。

## 为何人工智能科学需要哲学的参与
哲学研究的特点：
- 思考大问题，澄清基本概念。
- 在不同学科的研究成果之间寻找汇通点，而不受某一具体学科视野之局限。
- 重视论证和辩护，相对轻视证据的约束。

就对哲学文化的宽容度而言，AI 就是自然科学界的一个艺术。AI 是头脑风暴的产物。
- 先导者：阿兰·图灵
   - 1950 年 Mind 杂志发表的《计算机器和智能》提出了著名的 “图灵测验”。
   - 行为主义的哲学思想，对外在心灵的判断仅仅是通过外部表现行为来判断，而不是内在活动。
- 美国达特茅斯学院关于计算机实现人类智能的会议
   - 1956 年，会议筹备期间，麦卡锡发明了 Artificial Intelligence 这个词，人工智能学科诞生。还有明斯基、纽厄尔、西蒙等大牛。
   - 会议讨论的子课题：自然语言处理、人工神经元网络、计算理论以及机器的创造性等。

为什么 AI 有哲学维度？
- AI 必须对 “何为智能” 这个问题做出解答。然而，不同的解答往往会导致不同的技术路径。
   - 未雨绸缪，知道的足够多，有很多解决方案：专家系统
   - 人工大脑，对于人工大脑的模拟中，出现了人工神经元这门技术，就是对于人类的神经元网络进行数字模拟，然后在此基础上，希望被模拟出来的系统能够具有人类神经元系统的特点。
   - 行为主义，智能是黑箱，只要找到输入和输出的映射关系就是智能。
- AI 科学研究与一般科学研究相比，缺乏删除不同理论假设的决定性的判定例。AI 科学家一般不做实验，而只做试验，就这一点而言，这么学科似乎更像是工科，而不是理科。
- 关于智能、人类的思维是什么哲学思考的最多。另外，AI 所关注的思维结构某种意义上必须具有抽象性，因为它横跨人和机器，哲学家所提供的那种抽象思维方式也许更有用。
- 不成熟学科，哲学容易参与。

历史层面证明哲学强的国家对 AI 也有反哺作用
- 美欧对比
   - 美国进行 AI 研究的优点：资金充裕，科研机制有活力，哲学和科学互动频繁。
   - 欧洲：财力、体制（如德国的哲学研究偏向人文经典的解读，使得哲学研究难以对当下的热点问题作出及时回应；文理分科问题比较严重；跨学科研究支持力度相对小）等。
- 日本
   - 日本 AI 研究的特点：日本的经济结构不是一个纯粹的西式的自由主义的体系。重大科研项目由政府牵头，集中力量攻关。和我们的思维很像。
   - 日本研究第五代计算机（自然语言处理，听懂 90%+ 的日语）失败的主要原因：看到了 AI 建构的工程学面相，却没有看到其背后的哲学难题（如什么是智能）。
- 前苏联
   - 苏联 AI 研究落后的原因：第一，苏联官方缺乏 AI 研究方面的远见；第二，苏联官方意识形态对于马克思主义的曲解（“人工智能是独立人脑，能够独立产生智慧和生产力” 违背了 “机器只能转移价值不能生产价值” 的观点）。我们的今天的科研体制很大程度上仍然受苏联的影响。
   - 对维纳控制论的反对和赞成也都是站在政治图解的思维里。
   - 归根结底，是对马克思主义做了教条主义的理解，哲学仅仅是意识形态的工具，而不会对实际的工程学研究产生任何积极的思想。
- 中国 AI 研究存在的问题：
   - 长期跟风研究，缺乏真正系统的原创性思维。
   - 注重模仿，轻视原理；缺乏哲学兴趣。
   - 跨学科研究缺乏体制保障。

AI 是科学和工程学的一种奇妙结合，它并不以描述自然为终极目的，而以制造出合乎人类需要的智能机器为工作目标。所以对于如何实现这种目标，如何理解这种目标，AI 本身就具有一个比较大的宽容度，而这种宽容度是使得它能够和哲学相互交流的一个契机。

## 近代欧洲哲学与人工智能

### 希腊文明对 AI 的滋养

- 德谟克利特
   - 受 “机械唯物主义” 影响。
   - “灵魂原子” 只是比别的原子更为精微和灵活而已，并非在本体论上自成一类的对象。
- 毕达哥拉斯
   - 明确把 “数” 视为世界的本原，这就为后世科学对数学语言（以及一般意义上的形式语言）的推崇下了大调子。
- 苏格拉底和柏拉图
   - 对自然语义的歧义进行澄清，然后通过找定义的方式对我们所说的很多概念加以清楚厘定。
   - 自然语言直觉中以为掌握的概念经过哲学反思后发现都不正确，所以要找到精确的泛型，什么东西都要形式化（对问题形式定义）。比如应用题，从 “自然语言” 的描述中得出一个 形式的数学的模型。
- 为什么机器智能的想法没有在古希腊出现
   - 在古希腊人那里，机械唯物主义和形式主义传统基本上还是两个路子，而没有机会在同一个思想体系中得到整合。
   - 心智理论的构建还不是古希腊哲学家的核心关涉，而只是其形而上学理论的一个运用领域。
   - 奴隶制的社会条件下，人工机械的发展水平有限。

### 近代哲学

- 条件发生了变化
   - 知识、人性、理解问题，促进对人类的心智进行思考。
   - 伽利略导致的物理学革命，形式和物理结合。
   - 各种机械日益精进，对机械系统潜力的乐观估计
- 笛卡尔和莱布尼茨
   - 表象（唯理派，传统像符号 AI 重视数理和一般意义上的科学研究）看他们是支持人工智能，其实不是。
      - 理性派认为直觉、经验只不过是改头换面的推理，归根结底一切都是推理。
      - 唯理派认为任何心智活动的实质是符号表征层面上的推理活动；符号 AI 认为任何符号表征层面上的推理活动就是心智活动。
      - 计算机先驱不一定支持人工智能，计算机技术和人工智能是两个不同的东西。
   - 笛卡尔是二元论者，即认为人是占据广延的物质实体和不占据广延的灵魂实体的复合体。智能和灵魂有关，灵魂不能还原为物质，智能是灵魂的一部分，智能不能还原成物质，所以物质的配置形式不可能构造出灵魂的配置形式。
   - 笛卡尔《方法谈》对人工智能正面的讨论（机器智能不可能）：它们不会使用语言和记号，或者不会像我们那样组织。它们在特定领域工作，不会学习。
      - 从 “机器能够表达词语” 出发，我们推不出 “机器能够根据环境的变化而调整语义输出策略”。（反驳：现在的 AI 已经很聪明了）
      - 如果我们真的要做出一台 “智能” 机器的话，我们就需要把所有的问题解决策略预存在其内置方法库中，但在实践上这是不可能的。
   - 莱布尼茨《单子论》
   - 磨坊论证：知觉以及依赖知觉的东西不能用机械的理由来解释，不能用形状和运动来解释，不能用广延的东西来解释。
   - 一个智能体放大，发现零件推动，找不到知觉。机器不能有知觉，所以没有机器智能。（反驳：看不到不等于就没有，比如放大大脑，大脑在知觉时，我们是看不到知觉的，只能看到神经元和电脉冲。再比如灰尘看电视机的画面也是看不到的。）
   - 空间中就不存在单子。
- 霍布斯《利维坦》
   - 所有人类的理智活动归根结底都是一种形式符号的运算。
   - 我们都是理性动物，可以做各种计算。
   - 与物理系统假设想和：对于展现一个一般的智能行动来说，一个物理符号系统具有必要的和充分的手段。物理系统不聪明，只是没有找到好的编程方法。
- 休谟
   - 理性没有什么原则，仅仅是一种习惯。
   - 习惯的根基在于感官经验，而不是在于一些理性的讨论。
   - 核心术语
      - 印象：接近于感官
      - 观念：接近于符号
      - 感觉：中间的东西
   - 习惯实际上是一种统计学机制
   - 联结主义：输入层是印象，中间层是感觉，输出层是观念。每一个神经元都不知道自己在干嘛，是整个 network 在处理，没有很清楚的规则来让它进行推理。
> 习惯是统计学机制，根据维特根斯坦的结论，是否应该将 “习惯” 作为逻辑命题（从习惯、数据中提取规则），而将例外情况作为经验命题？

## 康德、类比推理和 “照猫画虎”

### 康德

- 认为唯理派和经验派对人类认知的看法都有所偏颇，经验派比较重视怎么样从感觉的经验材料出发一步步把符号表征加工出来；唯理派认为感知经验不重要，我们在先天观念的帮助下构成知识。康的认为：概念的能力+直观的能力 = 知识
- 侯世达（美国计算机科学家 Douglas Richard Hofstadter）和他的学生查尔莫斯（澳大利亚哲学家 David John Chalmeres）的 “照猫画虎”
   - 1992 High-level perception representation and analogy: A critique of artificial intelligence
   - 这篇文章是受到康德的影响写出来的：很早人们就知道直觉活动是在不同层面上进行的。康德将心智的直觉活动划分为两个板块：其一是感性能力，其任务是拣选出那些感官信息的原始输入，其二是知性能力，其任务是致力于把这些输入材料整理成一个融贯的、富有意义的世界经验。
- 康德：自下而上的感性能力和自上而下的知性能力的综合。
- Why 康德：
   - if 休谟：人类知识从感官来，那很难说感官经验里得到的信息最后是怎么具有知识的普遍性必然性的。永远面临对知识的普遍性和合法性进行辩护的难题。
   - if 莱布尼茨、沃尔夫：认为知识只和先天观念和先天范畴相关，和经验不相关，就会面临：怎么说明知识和经验世界之间的关系，怎么保证知识不是从书斋里幻想出来的。
   - “自下而上” 与 “自上而下” 两条道路在康德那里整合的根本原因：他既要保证知识在经验中有它的用途，又要保证知识有它的普遍必然性，他就觉得要把两者的优点结合在一起。
   
### 类比推理

人工智能专家不考虑上面哲学家说的问题，他们作为工程师的思维：
   - 尝试不同方法，能搞定的就是好方法。
   - 要拿一件足够有说服力的事情，就是做类比思维的计算机模拟，看哪种方法好。
   - 类比思维在人类日常思维中非常有用的一种思维。即以旧推新。类比思维有时候有效，有时候无效；因为人类碰到的很多新情况和旧情况相比完全不同。

哲学家用语言描述有歧义，计算机模拟要写成程序，是确定的。人工智能使得哲学家变得诚实。——丹尼尔·丹尼特

例子：孔明之于（），可类比与管仲之于（）。A.张飞；B.刘备；C.董卓；D.貂蝉；E.齐桓公。
- if 休谟：看习惯，即已有数据中的共现关系（统计学方法）。
- 统计学的策略有两个根本缺陷：
   - 很多对问题求解有用的新类比关系，往往是缺乏统计数据支持的。没有主动修正过去实际的能力。比如搜狗的热词。
   - 对于系统输入历史的这种高度依赖性，将大大削弱系统对于输入信息的主动鉴别能力。
- if 霍布斯主义者：预先要求我们把所有概念说成很清楚的含义（各种属性和关系），系统就找里面的类比物。孔明-刘备 与 管仲-齐桓公 之间有共同模板。
- 如何在关系中找到共同模板？
   - 计算量太大（如果每个概念的属性很多时）
   - 从康德那里得到启发，建立从高到低和从低到高两种检索，有了 “照猫画虎”

### 照猫画虎

在大量数据（如字符串 abc iijjkk）中找到类比关系
   - abc：两个后继性标签
   - iijjkk：三个同一性标签，两个后继性标签
   - abc 与 iijjkk 都有两个后继性标签，abc 可以类比于 iijjkk

![](http://qnimg.lovevivian.cn/course-pyilosophy-ai2.jpeg)

为了做成这个事情，系统需要的配置：
   - 人工的感性能力：对短码的解读能力。在例子中就是表征 abc iijjkk。
   - 人工想象力：在康德的心智理论中，“想象力” 是介于 “感性” 和 “知性” 之间的一种能力，其任务是对感官输入进行初步处理，以便为知性的高级操作做准备。在例子中就是给 iijjkk 贴标签这个事情，知性就是对这些标签进行一个评估。

例子：看立方体，一次只能看到三个面，但我们知道有六个面，是个立方体。把握立方体的过程就是感性和知性相互协调工作的一个过程，感觉的最基本的能力会在我们看到三个面时抓到一些碎片的特征（如顶点的形状），然后慢慢整合出全面的情况，知性告诉我们这是一个立方体。但是我们不知道哪里是分界。
- 人工范畴表：康德心目中的知性范畴表，大致对应于 “照猫画虎” 程序中的 “滑移网（slipnet）”。基本的思维框架，比如刚刚的：同一性、后继性。再比如：因果性。
- 感性（康德：时间和空间的把控能力，前后就是一种时间关系）会唤醒想象力，想象力会产生很多图形，它告诉你整个认知构架因果范畴的一个感性图形就是时间上的前后相续。在想象力这个中介的帮助下，信息传到了 ”范畴“ 这个更上面的网络了，时间先后关系被唤醒了，所以因果关系也就出来了，它出来后会把更多的注意力注意到前后相续这件事情上，按照因果范畴这样的眼光来看待前后两件事情，其他范畴暂不工作。

例子：斥候相当于感性，司令部相当于知性范畴（佯攻、主攻、投降等等），参谋整合和情报分析相当于想象力。
- 信息的传播是双向的：从底层往上、从上层往下。上面听到下面有个整合的过程，整合完才传到下面。休谟的哲学就是只听下面的，莱布尼茨的哲学就是下面的是机器人。康德的哲学就是上下有灵活的互动。

![](http://qnimg.lovevivian.cn/course-philosophy-ai-3.jpeg)

康德：概念无直观则空，直观无概念则盲。 VS 照猫画虎：滑移网无短码算子则空，短码算子无滑移网则盲。

局限性：
   - 只是在高度模拟（对基本的字母代码进行类比运算），应该在各个感官上全面复制康德对于时间、空间或知性范畴的所有想法。

总结：康德的哲学描述平移到可以操作的、可以编程的工程学层面指导具体工作。不是哲学的问题，而是搞哲学的人的问题，不具备跨学科的能力。

>这块内容和深度神经网络非常类似，从底层传递到高层，再从高层反馈至底层。
有一点需要特别注意，在高层，注意力应该根据任务不同而放到不同的抽象关系上，而不是所有的。
是不是可以把无监督的抽象信息（或者其他方式获取的抽象的关系，比如词性）替换为现有的 Attention（现有的 Attention 其实并不是注意力，而更像是 Memory）呢？

## 汉字屋论证

汉字屋是用来反对人工智能的可能性的一个非常重要的哲学论证。
《心灵大脑与程序》中提出，该论证的重要的一个概念前提就是对强 AI 和弱 AI 的区分。

### 塞尔
塞尔对于强 AI 和弱 AI 的区分：
   - “强人工智能” 这种观点认为 “计算机不仅仅是人们用来研究心灵的一种工具，而且，被恰当编程的计算机本身就是一个心灵。”
   - 直观非常不靠谱，经常引导我们走入思想的泥潭。
   - “弱人工智能” 认为计算机至多只能够成为人们研究心灵的一种工具，或是对心智活动的一种抽象模拟。

塞尔论证的框架：
   - 大前提：每一种真正的心灵或智能都必须有能力在符号与对象之间建立起一种语义关系。
   - 小前提：这种语义关系无法仅仅通过任何一台被恰当编程的计算机所获取。
   - 结论：计算机本身不可能具有真正的心灵，因此强 AI 无法实现。
   
塞尔的汉字屋实验是用来证明小前提的。实际上是一种 ”思想实验“。
- 思想实验：指的是使用想象力去进行的实验，所做的都是在现实中无法做到或现实未做到的实验。

### 汉字屋实验

[中文房间 - Wikiwand](https://www.wikiwand.com/zh-hans/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4)

条件：
   - 初始条件：说英语的被试被关在密闭房间通过传递字条和屋外的懂汉语的人交流；屋外的人判断屋里的人是否真懂汉语，屋里的人要想方设法欺骗屋外的人自己懂汉语。
   - 其他条件：字条本身只能够用汉语写成。
   - 被试的资源条件：不能有英汉或汉英字典；很多写着汉字的卡片，规则书（在面对由哪些汉字所构成的问题时，应当如何从盒子中取出相应的汉字而构成合适的应答）。
   - 行动速度非常快

结论：屋外的人无法判断屋里的人是否真的懂汉语。但是就算计算机真的达到这种程度了，它也不可能真正具有智能，因为它并没有真正的理解语言。塞尔认为它只是机械地搬运各种符号，而不理解符号的真正含义。

汉字屋实验是图灵测验（计算机和人类交谈时，人类是否能够发现对方是计算机）的衍生版本，反过来用：即使通过了图灵测验，仍然没有智能。

### 反驳

- 他心应答：子非鱼安知鱼之乐。汉字屋的论证让我们可以怀疑任何一个人是否懂任何一种语言，这和初衷（人和机器不一样，人比机器高明，按照这个标准，人都是不懂任何语言的）不一样。因为没有人认为人本身都是不懂任何语言的，所以我们用来捍卫人的标准也可以用来捍卫机器，一视同仁。
- 系统论证（以偏概全）：承认一句话是对的：”被试不懂语言“。但是计算机不仅仅是被试，还包括规则书，规则书+被试=系统，系统懂汉语。

- 计算机没有办法在语言符号和所代表的外界事物之间所建立的联系，但是我们可以把这种联系加上去。但是塞尔反驳，即使建立联系，那种信息仍然是数码化的。他认为这种转换是有问题的，整个计算系统和原始世界的原始关系已经被破坏了。再反驳：人类也是进行一些转换。

- 从根本上反驳（课程老师的反驳）：
   - 塞尔的三个预设：
      - 汉字屋系统和计算机系统之间是同构的。
      - 即使整个汉字屋系统能够通过汉语测试，汉字屋中的被试也不懂汉语。
      - 行为主义是错的，也就是说，从系统的外部行为特征中，我们无法确保其内部状态是否具有智能。
   - 这三点放在一起有逻辑矛盾。反证法（12 步）：
      - 第一步：汉字屋系统和计算机系统存在着实质性的可类比关系。（塞尔说的，假设是对的）
      - 第二步：汉字屋论证的有效性，必须以（1）为必要前提（这一点是自明的）。
      - 第三步：汉字屋论证的一个核心目标，就是指出：一个系统在外部行为上具有语言智能，并不能够代表其真的有智能。（塞尔预设的一部分）
      - 第四步：由于（1），汉字屋中的规则书对应于计算机系统中的程序，或者是万能图灵机的机表（根据塞尔自己的叙述）。
      - 第五步：在假设系统的硬件条件不变的情况下，一个 AI 系统的智能程度的高下，关键在于如何编制程序。不执行任何程序的纯硬件没有任何智能。（计算机聪明不聪明看程序）
      - 第六步：由于（4）和（5）整个汉字屋系统通过汉语测试的能力的高下，取决于规则书的编制水平，而被试本身是谈不上智能的，它必须要执行某种程序，才能体现出这种程序的智能。
      - 第七步：即使整个汉字屋系统能够通过汉语测试，汉字屋中的被试也不懂汉语。（塞尔的话）
      - 第八步：塞尔如何确定第七步是真的呢？在逻辑上只有两种可能性（反省和行为）：
         - 8A：我们可以确定被试具有某种内部反思能力，以确定自己依然不懂汉语
         - 8B：我们可以从被试的外部行为中确定他不懂汉语。
      - 第九步：（8A）若是真的，则和（6）矛盾，因为被试的内部反思能力的存在就等于说他可以执行一个独立于汉语规则书的程序。为了维护汉字屋系统和计算机系统之间的可类比性，我们就必须得删除（8A）。
      - 第十步：（8B）若是真的，则和（3）矛盾，因为根据（3），从汉字屋系统的外部行为中我们无法判断出被试是否真懂汉语。为了不和汉字屋论证的最终目标相抵触，我们就必须得删除（8B）。
      - 第十一步：塞尔没有理由说清，为何即使整个汉字屋系统能够通过汉语测试，汉字屋中的被试也不懂汉语。这自然会造成整个汉字屋论证的崩溃。
      - 第十二步：之所以可以得出（11），乃是因为我们发现（8A）归根结底会和（1）不相容，而（8B）归根结底会和（3）不相容。也就是说，为了维护 “汉字屋中的被试也不懂汉语” 这个步骤的有效性，我们要么就去否定汉字屋系统和计算机系统之间的类比的有效性，要么就去放弃整个论证的反行为主义目标。但无论如何选择，我们都将再次导致整个汉字屋论证的崩溃。

小结：
- 塞尔的哲学风格比较清明，避免使用过于难的哲学词汇，过于技术性的表达。所以他觉得计算机太难，汉字屋比较直观，所以他用类比来做，但这个类比有些地方不太成功，他过多把直觉牵扯进来，没有看清楚这种类比可能有缺陷。和莱布尼茨的磨坊论证有点类似，都是诉诸于某一种直观，但直观在很大程度上没有普遍的合法性。再次说明，直观要慎用。
- 也让我们怀疑现象学的研究方法，因为对现象学直观的界定都非常主观。

前面三个是预设塞尔所说的计算机系统和汉字屋系统的同构性是没问题的。在此基础上进行反驳。老师的认为同构性就可能有问题。

### 衍生性问题讨论

- 塞尔脑子里：语义关系和意向性关系是有关的。
   - 塞尔的哲学观点：人类所有的言语行为归根结底是一种心智活动。
   - 塞尔对意向性实质的看法：实际是指心灵的内部状态朝向外的一种能力。也就是说，它能够被用来指涉它以外的事物。
   - 塞尔对语义关系的看法：语义关系也应该是朝向心灵以外的某种东西。
- 对上述观点有两个问题：
   - 意义真的奠基在意向性当中吗？
   - 意向性真的如塞尔所说，指的是一种心灵的内部状态和外部事物的一种奠基能力吗？
- 对上述问题的争论：
   - 角度一：恒温计在一定程度上也可以看作是按照语义（程序的语句）的规则来行事，但恒温计没有意向性；而且又与客观世界有关（客观世界温度变化，它也变化）。所以，恒温计与语义有关，与外部世界有关，但好像与意向性无关。所以，塞尔所说的语义关系一定要奠基在意向性里面，并且通过意向性才能获得它和外部世界的关联。这个观点似乎有些问题。
   - 角度二：意向性本身的一个界说。如果说意向的对象是你与外部的一个关系，那完全可以意向指向一个不存在的东西。所以，意向性是可以存在，但它所指涉的核心对象是不存在的，也就不能说意向性就指和外部世界的一种关系，除非这个外部世界包括柏拉图所说的理念世界（理念中的东西），如此一来，整个理论应该以柏拉图的理论作为预设。
   
### 其他讨论

- 什么是意向性对象
   - 意向性的根源是在一定的语言游戏，在一定的社会共同体里面。比如画出来的麒麟、方的圆之类。

总结：塞尔的实验和对塞尔的反驳让我们真正感受到了哲学的魅力。

在哲学上，如果真的有这样的中文屋，我们可以判断它是智能的。
其实这也取决于我们对于智能是怎么看待的，因为人类语言的灵活多变和复杂性，规则书要做的事其实和人要做的事一模一样。

更进一步，就按塞尔规则书的模式进行这样的转换（不知道具体意思，只是知道一些关系），但因为词的组合造成句子根本无法穷尽，所以其实规则书能做到这一步（就是知道进来问题的分词及其语义关系），它已经能够理解意思了，而不仅仅只是抽纸条。所以塞尔所要求的本身就是不可能的。

## 维特根斯坦、“颜色不相容”、框架问题和拆弹机器人

### 早期《逻辑哲学论》

- 《逻辑哲学论》三件事情：
   - 世界本身的形而上学的构建应当是怎样的
   - 对于这个形而上学的世界怎样在话语中和言语中加以符号表征
   - 哪些事情是不能够用言语表征的
- 《逻辑哲学论》与人工智能科学的 “知识表征” 任务的三个环节：
   - 对于被表征对象的形而上学理论
   - 对于知识表征的技术手段，特别是逻辑技术手段的选择问题
   - 在选定一个特定的表征手段的前提下，对于知识表征范围的可能性边界的划定问题
- 《逻辑哲学论》与海耶斯的 “朴素物理学宣言”：
   - 一个基本想法是用弗雷格和罗素所发明的谓词演算的技术手段把人类的日常物理学知识整编成公理集，物理世界中的所有行动和活动都是公理集的推论。
   
### 晚期《哲学研究》

- 本书关心的大问题：agent（智能体）应该在怎样的规范性条件的约束下，在历史的动态环境中，利用相关的表征工具，特别是日常语言完成某些特定任务。
- 为何后期维氏超越了早期维氏？
   - 从 AI 的角度看，《哲学研究》超越《逻辑哲学论》的最大地方，就在于它不再把静态的知识体系规整视为哲学理论的聚焦点，而是把焦点转移到了智能体的行动，转移到了对于信息的实时处理。
   - “实时” 意味着任务有时间限制。所以著述形式的散漫，因为问题太复杂，要考虑不同的智能体在不同的语境中面对不同的实时问题求解语境所给出的不同的问题求解策略，以至于他不可能以某种规整的、统一的、一劳永逸的方式（早期）对这些问题进行解决。
   - 其实现在的人工智能教材在处理各种技术问题时也基本是一种散漫的形式，最典型的例子就是每个章节讨论一个技术问题，如：经典逻辑、贝叶斯、神经网络、遗传算法等等，章节之间基本没有技术联系。不过底层还是数学、统计学。
- 工程学相关语录
   - 想一想工具箱里的工具，那里有锤子、钳子、锯子、螺丝刀、尺子、胶锅、胶水、钉子和螺丝钉。正如这些工具的功能各不相同一样，词的功能也是各不相同的。（不过，两者都有一些相似之处。）
   - 好比机器有两个界面，一个界面是用户友好的界面，另一个界面是机器内部操作的界面。第一个界面可能分不清不同语词之间的用法，但也许在第二个更深层次的界面上，也许它们之间有不同的输入输出对应关系。
   - 相似理论还可见西蒙的《人工科学》
   
## 维特根斯坦和框架问题

### 心灵模块论

福多（美国的哲学家和认知心理学家），认为人类的心智构架可以分为两大部分：
- 中央推理系统
   - 类似于司令部
   - 统一任务是在全局性的实践推理中，把所有的信息整合在一起，能够看看有什么一般性的东西。
   - 中央推理系统没法程序化（计算机模拟），因为两个特点：
      - 各向同性：在全局性的智能推理中，各个领域的信息都必须被智能体放在一个平面上予以考量。
      - 蒯因式的特点：
         - 蒯因的一个观点：如果有一个观察命题要对某个假设命题进行支持的话，要考虑到整个假说体系的一个支持力度。一个证据和假设之间不是孤立地建立一个正式的关系，还要看背景知识，看整个信念体系的支持力度。（有点贝叶斯的感觉）
         - 引入该观点：如果有一个信念，该信念要对其他一个信念的真值提出修正，会牵扯到对于和被修正的那个信念相关的一大堆其他信念的真值修正，导致一种牵一发而动全身的局面，而这种局面在计算上是不可控的，计算机无法模拟这种全局性问题。
- 边缘性模块
   - 类似于司令部下辖不同组织机关
   - 模块的信息处理：速度快、封装性
   - 边缘性模块可以利用计算机理论计算（可以写成程序）
   
由此得出福多的结论：针对心智架构的计算机模型，只能够适用于该架构中的模块部分，却不能够施加于中央语义系统。

### 拆弹机器人

- 任务：假设有一个能量快耗完的机器人，备用电池放在一辆拖车上，拖车锁在某个房间里，拖车上还有一个定时炸弹。计算机事先已经知道所有的事件。
怎么办？进房间拖出拖车，但同时也会将炸弹拖出来。
   - 所以需要对程序进行修正：程序需要预先知道哪些事件会引起哪些事件，或者说哪些事件类型彼此之间是相关的。但这其实很难，因为：在经典逻辑的技术支持下，在一个庞大的信念库中对于某些信念之间 “相关性” 的语义标注，将不会自动导致对于诸信念之间 “非相关性” 的语义标注。
   - 这和人类不一样，当你告诉计算机哪些相关的时候，它不会自动排除掉那些不相关的。比如，程序让机器人知道拉出拖车和拉出炸弹是相关的，但是还得告诉机器人其他信息（机器不知道），如拉出拖车和改变拖车的形状是不相关的、拉出拖车不会改变拖车下面轮子的数量、拉出拖车不会改变那个房间的颜色……因为人类具有朴素的物理先验知识，但机器人没有。所以，结果就是机器人不能在短时间内搞定这个任务，虽然看起来很容易。上面的故事来自丹尼尔·丹尼特，他讨论拆弹机器人例子的经典论文：《认知之轮：人工智能的框架问题》。
- 印证了福多对于中央语义推理系统可计算性的悲观态度（他认为框架问题在很大程度上就体现了这个问题），我们没有办法对全局性的语义相关性和非相关性进行一种快速的直觉的把握。
- 回到维特根斯坦：如果维特根斯坦看到框架问题，他会说：“我在批评逻辑哲学论的时候已经说过，你们要用经典逻辑来刻画信念系统当中的诸信念之间相关性和不相关性就会导致问题。”这个问题在很大程度上和 “颜色不相容” 问题相关。

### 颜色不相容

- 背景：维特根斯坦对于 “命题” 的分类
   - 经验命题：可真可假，如 “中石油宣布明天降价”，需要验证。
   - 逻辑命题：永真的，如 “明天要么下雨，要么不下雨”，总是对的。
- 颜色不相容
   - 这是红的。——经验命题
   - 这是红的，所以它不是绿的。——逻辑命题
      - 应该符合逻辑运算的规则
      - 但维特根斯坦发现并不是。比如命题逻辑中的合取规则：“这是红的，所以它不是绿的 & 这是绿的，所以它不是红的”，应该是真的，（真&真），但实际却是假的。
   - 这就意味着 “命题” 二分法的有效性遭到怀疑。这个问题为什么和框架问题有些像：
      - 因为对于框架问题来说，拖出被拖出这个命题对于拖车的颜色没有被改变这个命题应该有一种蕴含关系，但因为从逻辑里面没有办法表征出这种蕴含关系，所以只能写很多否定性命题，A 发生不会引起 B 发生。颜色不相容问题也类似，得事先告诉系统红色和绿色彼此不同，否则系统不会自动进行颜色不相容推演。
      - 于是，日常生活中最简单的语义推理逻辑就变成逻辑搞不定的东西，也就是说，我们的先验知识让我们 “自动” 地知道了某些事情之间的关系，但这种关系却不被机器知晓。
- 解决方案
   - 方案一：康德式
     - 颜色不相容问题是特殊命题，既不是先天分析判断，也不是后天综合判断，而是先天综合判断。
     - 这种独立的划分实际并未解决问题。
   - 方案二：蒯因式
     - 所有判断都看成经验的。
     - 对解决问题也没帮助，因为即使是纯粹的分析判断，也要想办法付出很多的表征资源进行表征，这实际是扩大了困难。
   - 方案三：维特有关的
     - 放弃真值函项理论或经典逻辑的主导地位，用更宽松的理论标准界定逻辑命题和经验命题的界限。
     - 维特根斯坦的建议可以归纳为两点：
        - 经典逻辑考虑的基本单位是句子，没有能力考虑概念。
           - 弗雷格的逻辑在形式化方面取得了大规模进步，但他的逻辑是为数学语言准备的，在应付日常语言时捉襟见肘。
           - 回到亚里士多德的道路，从语词的角度而非句子，制造很多概念层级。但很难形式化。
        - 《论确定性》中谈到的信念网的分布问题。
           - 把人类的信念系统看成非公理化却具有动力学特征的一种网络连接，网络连接中有不同的概念的节点。人在想起一件事时，当中的关键词就可以作为一个概念的节点。比如：“饿”，旁边有：面包等。一个网被激活后，其他邻近的网也可能会被激活。而且激活的次序看两点：第一，它和这个被激活的最早的那个节点之间的毗邻关系；第二，两者之间的信息通道的通畅程度。
           - 河渠的比喻：因为 “历史原因” 而形成的高权重信息通道就会构成网内信息流动的 “自然河渠”，并因为这种 “自然性” 而成为系统的 “缄默预设”，而不再成为系统自主知识表征的目标。（_正如人类自然而然的常识_）只有新问题（没有旧有的道路可以依赖）需要中央语义系统开拓新的道路。例子：兔鸭头图（既可以看成兔子也可以看成鸭子），假如看到的就是兔子或鸭子，就不会有在兔子和鸭子之间进行来回比较的心智过程。而现在两个概念节点被激活，它们都在争取对你感官印象的解释权，你的推理通道不知道该往哪边走，这时候的心智损耗就会很大。这种判断是经验判断。如果是非常容易的（兔子或鸭子），就可以快速推理，逻辑判断。
           - 按照上面的标准，维特根斯坦对分析判断和经验判断的标准变成一个心理学和语境论的标准：在当下语境下心理消耗的资源，而康德和休谟时代很大程度上是看一个知识论的标准。按照这个思路，框架问题也可以解决：为什么由某个行动不会引起的效果不需要在一个知识推理过程中得到系统的表征呢？因为这个系统的信息流向已经由这个信念系统自然的河渠流向来规定，对河渠外的事情不需要考虑。
      - 补充：
        - 传统的知识论的思路是指这个命题本身的性质是和它经验外部的那个关系，如果是先天命题就不需要通过经验来证实。是否需要经验验证 VS 是否需要付出心智的努力来思考。
        - 举例：很复杂的重言式，它的真不受任何经验的牵导或者牵制，和花多少时间计算无关，但计算的过程是真实的损耗。维特根斯坦考虑问题是在人的立场上，付出多少损耗的立场上。所以这种我们认为是分析判断的命题在维特根斯坦看来是经验判断，他认为证明很复杂的重言式在日常生活中是没用的，可能只有在应付逻辑考试时才用，而且做这件事需要大量的心智损耗。相反一些很简单的命题，因为它们和我们的日常生活非常相关（如 “我有两只手”）所以像分析判断，尽管按照传统知识论是经验判断。
        - 维特把传统看做知识、经验的东西看做逻辑，去分析；就是那些很简单的逻辑推理，但它们非常重要。传统的逻辑判断以逻辑体系为基础的。这是根本不同。

## 结论
- 维特根斯坦的思想宝库里有大量的金矿等着 AI 专家挖掘。
- 哲学家必须更多关心工程学实践，工程师也必须更多地熟悉哲学，能够在两者之间搭建互相熟悉的桥梁。


# [清华“天机”芯片登上Nature封面：全球首款异构融合类脑芯片](https://www.tmtpost.com/4099136.html)

2019-08-01 16:25

摘要： 
>这也是中国的人工智能芯片，首次登上Nature。

![](https://images.tmtpost.com/uploads/images/2019/08/20190801162443828.jpg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x649/gravity/center/crop/!1400x649&ext=.jpg)
   
近日，权威科技杂志《自然》(Nature)封面报道了来自清华大学团队的“天机”类脑芯片，论文标题为“Towards artificial general intelligence with hybrid Tianjic chip architecture”(面向通用人工智能的异构融合“天机”芯片架构)。
![](https://img1.mydrivers.com/img/20190801/f583e6ba-4539-4b0c-9ffe-8e85758f1451.jpg)

传统芯片均基于冯诺依曼架构，清华天机则是一种类似人类大脑机制的非传统结构，类似Intel正在研究的神经拟态芯片Loihi。

其实早在2015年，清华团队就完成了第一代“天机”芯片，2017年进化为第二代，速度更快，性能更高，功耗更低，相比于当前世界先进的IBM TrueNorth，也具备功能更全、灵活性、扩展更好的优点，密度高出20%，速度高出至少10倍，带宽高出至少100倍。

最新一代天机芯片采用28nm工艺制造，核心面积仅仅3.8×3.8毫米，包含156个FCores核心，拥有大约40000个神经元和1000万个神经突触，可以同时支持机器学习算法和类脑电路。

它不仅算力高、功耗低、支持多种不同AI算法，而且采用了存算一体技术，不需要外挂DDR缓存，可大大节省空间、功耗和成本。

![](https://img1.mydrivers.com/img/20190801/S7d431361-7176-4c6e-aee6-8ed3e6360faf.jpg)

## 自行车

今天，一辆来自清华的无人驾驶自行车登上了Nature的封面。

在论文中，研究团队描述了天机芯片如何帮助机器响应语音命令，识别周围世界，避开障碍，并保持平衡，展示了搭载该芯片的自动驾驶自行车如何自动控制平衡，并在操场上对目标人物进行识别、跟随、自动避障。

这个无人智能自行车系统包括激光测速、陀螺仪、摄像头等传感器，刹车电机、转向电机、驱动电机等制动器，以及控制平台、计算平台、天机板级系统等处理平台等。

据介绍，天机芯片目前还是非常初步的研究，但是团队已经启动了下一代芯片的研发，预期明年初完成。

![](https://img1.mydrivers.com/img/20190801/c4ded3bb9e914162a8c3aba36747d54e.gif)

S型路线跟踪

![](https://img1.mydrivers.com/img/20190801/3d029837c4b042e0ac978e153ae819e6.gif)

语音控制“左转”

![](https://img1.mydrivers.com/img/20190801/23e7680d94764435bd4f6a3b7283d064.gif)

语音控制“直行和加速”
这辆自行车不仅可以平衡自身，还可以绕过障碍物，甚至可以响应简单的声音命令。
      
![](https://images.tmtpost.com/uploads/images/2019/08/1dd7f2fdf7a3a4de36bf7bba1e17aff3_1564647942.gif?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x786/gravity/center/crop/!1400x786&ext=.gif)

自行车能够按照声音命令改变方向或调整速度
 
自行车检测并跟踪移动的人，并在必要时避开障碍物

这辆自行车能够如此平衡、顺利的自主运行，靠的是自行车背后的大脑。它采用了一种名为“天机（Tianjic）”的新型计算机芯片，用于实时物体检测，跟踪，语音识别，避障和平衡控制。

邓磊介绍，无人自行车系统的语音识别、自主决策、视觉追踪功能运用了模拟大脑的模型，而目标探测、运动控制和躲避障碍功能运用了机器学习算法模型。

研究团队还指出：“通过随机将新变量实时引入环境中可以产生高时空复杂性，例如不同的道路条件、噪声、天气因素、多种语言、更多人等等。通过探索允许适应这些环境变化的解决方案，可以检查对AGI至关重要的问题，比如概括、稳健性和自主学习。”

这只来自清华的团队也凭借Tianjic芯片，登上了8月1日发布的最新一期Nature封面。

这也是中国的人工智能芯片，首次登上Nature。

![](https://images.tmtpost.com/uploads/images/2019/08/1ed34cccf47ff53e8c057e5d5493dbea_1564647942.png?imageMogr2/strip/interlace/1/quality/85/format/jpg/thumbnail/1400x489/gravity/center/crop/!1400x489&ext=.png)        

论文的通讯作者、清华大学精密仪器系教授、类脑计算中心主任施路平教授表示，虽然这还是非常初步的一个研究，但或许能够推动通用人工智能（AGI）计算平台的进一步发展。

![](https://images.tmtpost.com/uploads/images/2019/08/5171b180a36d673c0796c5600d2c28a1_1564647942.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x919/gravity/center/crop/!1400x919&ext=.jpeg)       

本次的论文作者来自清华大学、北京灵汐科技、北京师范大学、新加坡理工大学和美国加州大学圣塔芭芭拉分校等机构。
- 论文链接：https://www.nature.com/articles/s41586-019-1424-8

![](https://images.tmtpost.com/uploads/images/2019/08/16a9e04d6af244ea188966b594f14dee_1564647943.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1848&ext=.jpeg)    

## 什么是AGI？

这款芯片可以同时融合两种方案正是其受到关注的关键所在。`通用人工智能`（Artificial General Intelligence，AGI），是一个尚未实现的研究课题，有时也被称作强人工智能，它所描述的机器智能可以理解或学习人类所能完成的任何智力任务。

![](https://static.leiphone.com/uploads/new/images/20190801/5d4264e2de9ca.png?imageView2/2/w/740)

对于AGI，部分人工智能学者认为，AGI的概念并不严肃，在实践中基本不可能实现。

另一些人则十分看好人工通用智能的发展，认为它有可能塑造人类的发展轨迹。

在Nature论文的新闻发布会中，施路平表示，“AGI是一个非常难的研究课题，但我们相信它是一定会实现的”。

施路平认为，发展通用人工智能的最佳方案之一是：<font color='red'>把人脑和电脑的优势结合起来</font>。

这种研究思路也就意味着要将`计算机科学导向`和`神经科学导向`这两种发展AGI的方法结合在一起。但是这两种方式在公式和编码方案上存在根本差异，想要结合困难重重。

也就是说，这种结合的核心挑战在于`脉冲神经网络`（SNN）和`人工神经网络`（ANN）的融合。

在生物大脑中，每个神经元都与各种输入相连。一些输入在神经元中产生激发，而另一些输入则抑制它，对于SNN（脉冲神经网络），在达到由变量（或者可能具有函数）描述的特定阈值状态时，神经元发出脉冲信号。

ANN则是是从信息处理角度对人脑神经元网络进行抽象，目前热门的AI神经网络CNN、RNN都属于ANN。

就可以理解SNN和ANN最大的差异
- ANN以精确的多位值处理信息
- 而SNN以脉冲处理信息

为了在一个平台上实现两种模型，脉冲需要表示为数字序列（1或0），以便与数字编码格式的ANN兼容。

当然，两者之间还存在其它差异，比如
- SNN在时空域中运行，而ANN依靠时钟在每个周期刷新信息。
- SNN的计算包括膜电位积分，阈值交叉和电位复位，ANN主要与乘法累加（MAC）操作和激活变换相关。
- SNN的处理需要比特可编程存储器和额外的高精度存储器来存储膜电位，发射阈值和不应期，ANN仅需要用字节存储器来进行激活存储和变换。

## 计算机科学+神经科学双导向，构建更普遍的通用平台

开发通用人工智能有两种主要方法：
- 一种是`神经科学导向`，植根于神经科学，并试图构建与大脑非常相似的电路。
- 另一种是`计算机科学导向`，以计算机科学为基础，并使用计算机来执行机器学习算法。

因为在制剂和编码方案的基本差异，这两种方法依赖于不同的和不兼容的平台，延缓了AGI的发展。

因此，通用人工智能的发展亟待一个支持更普遍的、基于计算机科学的人工神经网络以及神经科学启发的模型和算法的通用平台。

![](https://images.tmtpost.com/uploads/images/2019/08/7151e687d18f34311cd74692f5671527_1564647943.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x792/gravity/center/crop/!1400x792&ext=.jpeg)      

### 两种方法的结合促进AGI发展

这款天机（Tianjic）芯片则集成了两种方法，以提供混合、协同平台。

天机芯片采用多核架构，可重构构建模块和采用混合编码方案的流线型数据流，不仅可以适应基于计算机科学的机器学习算法，还可以轻松实现脑启动电路和多种编码方案。

![](https://images.tmtpost.com/uploads/images/2019/08/b1739c3b76e2147df3d20e7fc224d119_1564647943.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1228/gravity/center/crop/!1400x1228&ext=.jpeg)      

“天机”芯片示意图

通过资源复用，天机芯片只需百分之三的额外面积即可同时运行计算机科学和神经科学导向的绝大多数神经网络模型，支持异构网络的混合建模，形成时空域协调调度系统，发挥它们各自的优势，既能降低能耗，提高速度，又能保持高准确度。

天机芯片同时具有多个功能核心，可轻松地重新配置，使其能够适应机器学习算法和大脑启发电路。研究人员通过将其中一个芯片整合到无人驾驶的自行车中来证明这种方法的潜力，这种自行车可以实现自我平衡，通过语音控制并且可以检测和避开障碍物。

![](https://images.tmtpost.com/uploads/images/2019/08/527f1b98d719c2ffe824a14a67540858_1564647944.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1606/gravity/center/crop/!1400x1606&ext=.jpeg)      

芯片评估建模示例

在论文中，该团队表示，仅使用一个芯片，就可以在无人驾驶自行车系统中同时处理多种算法和模型，实现实时物体检测、跟踪、语音控制、避障和平衡控制。

![](https://images.tmtpost.com/uploads/images/2019/08/db856781ceda5d8aa886e72bfbcf7ed9_1564647944.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1386/gravity/center/crop/!1400x1386&ext=.jpeg)     

基于天机芯片的自动驾驶自行车多模态集成示例图

## 跨学科组队，七个院系共同参与，七年磨一“芯”

在7月30日的电话新闻发布会中，论文通讯作者、清华大学精密仪器系教授`施路平`介绍了论文的研究思路。研究团队在接受媒体的采访时表示，从2012年孕育这项研究开始，团队遇到的最大挑战不来自于科学、也不来自技术，而是在于学科的分布不利于解决当前的问题。

因此，研究团队成立了七个院系组成的类脑计算研究中心，覆盖脑科学、计算机、微电子、电子、精仪、自动化、材料等学科。

团队成员之一，加州大学圣塔芭芭拉分校博士后邓磊表示，在芯片方面，遇到的最大挑战是**如何实现深度和高效的融合**。计算机科学导向和神经科学导向是目前流行的两类神经网络模型，这两种模型的语言、计算原理、信号编码方式、应用场景都有很大不同，所以需要的计算架构和存储架构大相径庭，甚至设计的优化目标都很不一样。一些深度学习加速器和神经形态芯片，基本上都是独立的设计体系，因此深度融合并不简单。

深度融合不是深度学习加速模块和神经形态模块简单的拼合，难点在于每部分的比例难以确认，因为现实中的应用复杂多变。而且，如果构建异构的混合模型，可能还需要在两个模块之间添加专门的信号转换单元，这又会有很多额外成本，所以，如何设计一套芯片架构兼容两类模型，可以灵活的配置同时又具有高性能，是团队芯片设计中的一大挑战。

2015年，施路平团队设计出第一代“天机芯”，经不断改进设计，2017年第二代“天机芯”问世。相比于当前世界先进的IBM的TrueNorth 芯片，2017年流片成功的第二代“天机芯”密度提升20%，速度提高至少10倍，带宽提高至少100倍，灵活性和扩展性更好。

也正如MIT科技评论报道所说，“该芯片暗示了**中国在开发自己的芯片设计能力方面取得的进展**。中国研究人员表明，他们可以制造专门的AI芯片以及任何芯片。” 

## 类脑可以超越人脑吗？

其实早在2016年，谷歌就曾在愚人节那天发布过一辆理想中的自动驾驶自行车。

<iframe src="//player.bilibili.com/player.html?aid=11696654&cid=19323090&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height="600" width="100%"> </iframe>
- [无水印版](https://www.bilibili.com/video/av7135972)（中文字幕，无英文）

在谷歌的想象中，这辆“自行车”不仅平衡力超高

![](https://images.tmtpost.com/uploads/images/2019/08/a4f3742b87d55b8989267c079983c4ff_1564647945.gif?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x763&ext=.gif)       

还能够自动通过红绿灯路口，自主导航找到你的位置。

![](https://images.tmtpost.com/uploads/images/2019/08/eb45d1790480037035f7d53a4b5a0428_1564647945.gif?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x763&ext=.gif)       

但作为“愚人节视频“发布，也说明了这一技术的难点和不易实现。

<iframe src="//player.bilibili.com/player.html?aid=36837684&cid=64694826&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height="600" width="100%"> </iframe>

而在今天，清华施路平团队终于初步实现了这一想象。这样的黑科技似乎也带着一丝科幻色彩，让人畅想AGI到来的那天。

在接受采访时，施路平教授表示，类脑能否超越人脑的问题，其实和电脑是否能超越人脑的问题类似。

电脑在某些方面其实早就超过了人类，其精准快速的运算能力、强大的记忆让我们叹为观止。然而，目前在很多智能的层次，计算机和人脑还是有相当大的距离。 特别是对于不确定性的问题，比如学习、自主决策等领域。

计算机会逐渐缩小差距，至于最后能否全面超过人脑，施路平教授觉得从技术的层面来看会越来越多，“因为计算机的发展有一个特点，就是`它从不退步，它一直往前走`。但是我相信我们人是有智慧的，我们会在发展的过程当中来逐渐的完善我们对于研究领域的一个理解，来把控它的风险，因为我相信人们之所以对这个问题重视，是因为我们担心会不会像科幻电影说的那样毁灭人类。”

关于AGI是否会超越人类智慧，吴恩达在AI For Everyone课程中也表示，`完全的AGI的出现可能还需要几十甚至上百年，从时间上来说，我们也不需要多度担心`。


## [从“天机”芯片看脑科学与AI的融合](https://zhuanlan.zhihu.com/p/76323171)

许铁-巡洋舰科技

7月31日Nature杂志封面刊登了清华类脑计算团队的最新成果： 天机芯片以及由其操控的自行车。

Towards artificial general intelligence with hybrid Tianjic chip architecture[1]

Letter | Published: 31 July 2019

Towards artificial general intelligence with hybrid Tianjic chip architecture
这则信息在一天之内在AI圈子引起了热议，而大部分吃瓜群众的状态则是云里雾里。 这篇文章从脑与人工智能结合的潜力与背景， 看这系列最新工作的意义。

我们说这个新工作的核心是能够同时在芯片上高效实现人工神经网络ANN和脉冲神经网络SNN， 所谓的ANN和SNN， 事实上是神经网络发展过程的两个分支。 欲了解其背景先了解其历史。

### 神经网络家族的分合故事。

神经网络的故事从模拟单个神经元开始： 神经元是神经网络信息传输的“原子”。通过一定的方法连接这些原子，就可以得到具有智能的系统， 这算是整个人工智能“连接主义”流派的哲学根基。

那么如何构建这个认知的“原子” ？ 我们来看看最早的把连接主义引入机器学习的尝试。 最早的模拟大脑的单个神经元的尝试， 是Warren McCulloch 和 Walter Pitts 在1943 提出而来神经元的模型。 这个模型类似于某种二极管或逻辑门电路。 一定的输入进来，被神经元汇集加和， 如何这个和的总量大于一个阈值，神经元就放电， 小于一个阈值，神经元就不放电。 这个东西就好像某个微小的决策装置， 把很多因素加载在一起， 做一个最终的决策。 我们想象无数的二极管可以构成一个计算机，那么无数这这样的神经元不就可以构成一个具有计算功能的大脑吗？ 这就是感知器的概念。

这个高度简化的神经元事实上就是后来的人工神经网络ANN的基础， 简化得到的神经元事实上每一个的数学形式等价于一个加入了非线性过滤的线性回归。

![](https://www.zhihu.com/equation?tex=y+%3D+%5Cphi%28%5Csum+W_%7Bij%7DX_j+%2B+b%29+)

如果把无数这样的神经元连接起来， 就构成了所谓的人工神经网络（ANN）。

当下的深度学习工具， 无论是CNN还是RNN， 都是在这个方程基础上把更多的神经元连接起来加入不同的限制条件得来的。

然而事实上， 这个架构与真正的生物神经网络相差极远， 这个差距首要集中在单个神经元模型上。 刚刚的方程是一个把原来的生化过程简化到不能再简的结果。 这里面最致命的区别在于， spike。 通过观察上述方程我们可以看出， 神经网络输出y是一个实数。而事实上， 真实的生物神经元输出， 更加基接近的是一个0，1过程， 当神经元经历的电压超过一个数值， 它就放电。 那是不是说明这个spiking反而更简单？ 其实不是， 这里面人们忽略掉的一个信息就是spike timing以及背后的电压变化。 真实神经元的放电过程由一组微分方程(Hodykin Huxley equations 1952)表达 :

![](https://www.zhihu.com/equation?tex=+%5Cbegin%7Bgather%2A%7D+I+%3D+C_m+dV_m+%2F+dt+%2B%5Cbar%7Bg_K%7Dn%5E4%28V_m+-+V_K%29++%2B+%5Cbar%7Bg_%7BNa%7D%7Dm%5E3+h%28V_m+-+V_%7BNa%7D%29+%2B+%5Cbar%7Bg_l%7D%28V_m+-+V_l%29%5C%5C+dn%2Fdt+%3D+%5Calpha_n%28V_m%29%281-n%29+-+%5Cbeta_n%28V_m%29n%5C%5C+dm%2Fdt+%3D+%5Calpha_m%28V_m%29%281-n%29+-+%5Cbeta_m%28V_m%29n+%5C%5C+dh%2Fdt%3D+%5Calpha_h%28V_m%29%281-h%29+-+%5Cbeta_h%28V_m%29h%5C%5C+%5Clabel%7Beq%3A001%7D+++%5Cend%7Bgather%2A%7D+)

这组微分方程的解就是spiking的过程， 如下图是电压随时间的变化， 当电压积累达到一定阈值， 这个爆发的尖峰就是spike，通过spike ， 神经元可以向其它神经元发射信号。我们所谓的脑电波， 无非是大量这样的神经元的集体放电在颅外所检测到的一组信号。

![](https://pic2.zhimg.com/80/v2-d887fabe6d956a3c9b6949596eb595b1_hd.jpg)

如果用上述这种包含了重要生物细节spiking的神经元连接成网络， 我们就得到了SNN（脉冲神经网络） 也就是受， 无论SNN还是ANN，本质都是对生物神经网络的模拟， 但就其抽象程度且相差疏远。

我们看到用SNN可以用神经脉冲表达信息， 如果用ANN表达一个类似的事情是什么样的呢？ 我们用一个数字Y来表达时间窗的spike个数（频率）， 而丢弃了所有其它信息， 比如波形，相位， 不同神经元之间spike和spike之间的同步等。 这意味着什么？ 两种可能的解释：
- 1， 波形，相位， 不同的神经元之间的同步是没有意义的冗余， 去掉它们整个神经网络表达的信息没有变化， 神经元的系统等于取定时间窗后的平均发放。
- 2， 波形，相位， 不同神经元之间的同步包含很多有用的信息， 去掉它们， 可能丢失了一些关键性的信息。 然而在最粗粒化的信息处理阶段， 这种保留是足够的。

那么哪一个更准确呢？ 普林斯顿的大牛Williams Bialek 的一系列作品都指出， 神经元spike间的同步（相关性）包含和神经编码相关的关键性信息，也就是说除了平均值外， spike所包含的不同神经元之间的发放同步（或相关性）依然包含了大量的信息。

1, Weak pairwise correlations imply strongly correlated network states in a neural population 2006 Nauture [2]

2, Collective Behavior of Place and Non-place Neurons in the Hippocampal Network 2017 Neuron[3]

![](https://pic2.zhimg.com/80/v2-c53bb05a4cfa8510e3572ebde93a346d_hd.jpg)

Weak pairwise correlations imply strongly correlated network states in a neural population 2006 Nauture, 这张图说明了如果用0，1事件表达spike， 那么一个（视网膜网络）里的神经元的同步放电频率远高于用高斯独立假设得到的频率， 也就是说spike之间的同步不可忽略， 构成一种潜在编码
这两部作品的共同特点是说， 神经元spike发放之间的spike correlation可以编码大量的信息， 如果记录这些spike之间的pairwise correlation， 那么我们就可以恢复出神经活动里的大部分有用信息。

这意味着什么？ 假如神经元spike间的同步可以编码信息， 那么我们就可能用更少的spike编码更多的信息， 而这无疑对用最少的神经元放电得到更多的信息（稀疏性）大有帮助。 除此之外， 通过在spiking神经元的那组微分方程里加入更多的核膜常数（代表不同时间尺度的信息， 因为spike方程本身是一个包含大量不同时间尺度的非线性方程），我们可以得到大量局部存储的不同时间尺度的记忆（此处联想“忆阻器”）， 我们甚至可以得到某些类似LSTM非线性门的特性。这些， 都代表着Spiking Neural Network（SNN）相比当下ANN的优势。 用一个不恰当的比喻， ANN的神经元用实数表达每个神经元的状态， 而SNN好比进入到了复数域，有了相位。 在物理领域，实数到复数支撑了从经典力学到量子力学的升级。 有次看， 把SNN看成下一代的神经网络技术不言而喻。当然如果SNN这么好为什么现在工业没有用呢？ 难点在于SNN依赖于对微分方程的模拟， 对于当下的冯诺伊曼结构的计算机， 这是一个成本消耗非常大的运算。也就是说计算机为了模拟本来节省能量的生物计算可能更加耗能，同时也更加不好训练。 解决这个问题的方法， 显然是从基本硬件基础出发，去改良硬件的架构， 这也是神经拟态芯片的意义之所在。我们把树突和轴突直接用芯片来刻画， 无形之间， 就得到了一个长在硬件上的脉冲神经网络（SNN），它的能耗效率要比普通芯片高12-10000倍。

当然ANN也有一类专门的芯片来提高当下深度学习运行的效率，这就是深度学习芯片， 例如大家都了解得寒武纪等。

清华的这个天机芯片在于， 把神经拟态芯片和深度学习芯片得优势结合起来， 可以同时提高这两类神经网络ANN和SNN的效率。 我个人背景不是芯片， 所以此处不在深谈， 我们多从算法角度谈谈两者结合得意义。

![](https://pic3.zhimg.com/80/v2-ef41f7d6e1d84886b2ddda3a7e729346_hd.jpg)

Towards artificial general intelligence with hybrid Tianjic chip architecture
这一次Nature文章里的例子是自动驾驶自行车， 当然这个例子被很多人诟病，认为这个不就是一个简单的平衡游戏吗。 大家可以去github搜索cart pooling或者双足行走，这一类的toy model还不少吗？

然而我认为思考一个新发现的意义不在于它所干的那个任务low不low ， 而是看它是如何完成的。 最初的火车甚至跑不过马车，但是它的架构决定了它的上限和马车不可同日而语， 通过数年时间迭代，两者已是云泥之别。

那么我们来看一下让ANN和SNN同时在一个芯片上运行， 带来的潜力是什么。 一言以蔽之， 当下的深度学习模型，可以和大量没有被好好利用起来的计算神经科学模型， 天衣无缝的嫁接在一起。 这从无人驾驶自行车的网络架构可以略知一二。

![](https://pic3.zhimg.com/80/v2-7faf9a7000d36d819ae6fea27643819a_hd.jpg)

Towards artificial general intelligence with hybrid Tianjic chip architecture
我们来理解一下这个流程图， 首先， 这个架构可以把多模态信息融合。 比如视觉， 听觉。我们注意到， 处理听觉的是脉冲神经网络SNN（更多时间相关信息）。 处理视觉信号的网络是经典的CNN卷积神经网络，属于人工神经网络ANN家族。 然而故事还没有结束， 在CNN的下面， 有一个主管视觉追踪的CANN网络， 虽然只有一个字母之差， 这可不是卷积神经网络， 这四个字母的含义是continous attractor neural networks - 连续吸引子网络。所谓空间吸引子， 说的是一种特化了的循环神经网络， 网络的动力学导致一系列可以根据外界信号连续变化的吸引子构成， 人们通常认为，海马体内的位置细胞就是由这种连续吸引子产生的， 它们可以天然的和速度信号进行耦合， 形成对空间的神经表示， 这个CANN，就是一种连续吸引子网络， 它直接把视觉物体(人)转化为一个可以追踪的空间目标（之后可以用于躲避行人）。 大家注意， 这是一个典型的脱胎于计算神经科学的网络架构，矩阵的连接还用到了树突计算。

然后我们来看中间的那个模块， neural state machine：神经状态机。 这个网络把连续的听觉和视觉信号转化为离散的事件， 这些事件构成一个有限状态的机器，也就是我们通常说的马尔可夫链。 这一步大家已经可以看到和决策有关的网络的联系，因为一旦把连续变化的信号抽象成了这种离散的马尔可夫链， 下一步就可以交给决策网络来决策了， 这里的决策主动是动作输出， 可以控制自行车在保持平衡的同时躲避障碍， 并对周围物体发出警戒信号。 这个网络也是由一个脉冲神经网络SNN构成。

在这里， 我们不难看出这是一个典型的人工设计与机器学习结合的模块化网络， 不能不让我们想起这类工作的先行之作： Science(Eliasmith, Chris, et al. "A large-scale model of the functioning brain."science338.6111 (2012): 1202-1205.) 在这个工作里， 研究人员构建了一个叫spaun的模块化网络， 可以进行多任务学习。

Spaun的每个部分都是一个人工神经网络， 且可以与真实的脑区对应上， 比如视觉输入对应V1-V4 视皮层，它把真实的视觉信息压缩成一种低维度的编码（每个图像称为这一空间的一个点， 被称为pointer）。 这种低维的信息表示形式很容易放入到工作记忆模块里（working memory）， 最终由解码网络转换（decoding）， 被动作输出网络执行（motor）。 神经网络整体状态的调控由模拟basal ganglia的网络完成（Action Selection），它可以根据当下的任务整体调节信息的流动（如同一个综控系统， 调节每个网络之前的输入阀门）， 从而让大脑在不同的工作状态间灵活转换。 这也体现了功能大脑的概念， 我们不必拘泥于某个脑区的名称， 而是记住每个脑区对应信息处理的功能。最终我们通过监督学习或强化学习来让这个系统掌握8种截然不同的任务， 包括： 1， 抄写数字 2， 图像识别 3， 奖励学习， 4， 多个数字的工作记忆 5， 数数 6， 回答问题 7 简单的数学推理。

![](https://pic3.zhimg.com/80/v2-ca6d04c9ec0559dfca62dc7acccd5b2e_hd.jpg)

A large-scale model of the functioning brain

而当下清华的工作， 正是打造了适合这一类执行多任务的“虚拟”生物的硬件系统， 在之上， 你可以自由的搭建无论是经典的深度学习模型， 还是那些超前了的计算神经科学模型， 把他们一起组成模块化的网络， 执行多种多样的功能。

这个潜力也就不只局限在自行车了， 可以是流水线的机器人， 陪护老人的机器人，随便你去发挥想象力，无论上述那个机器人， 都需要进行多模块的信息整合以及多任务执行。假如这种建立在神经网络芯片上的模块化的网络系统可以以较低能耗长时间在真实环境里运作， 那么它带来的好处显然是特别巨大的， 这相当于引入了一个实时不间断的训练数据， 如果结合无监督学习， 强化学习，甚至神经进化等算法实时对网络进行优化，其潜力是无可限量的。

事实上， 类脑计算和AI的结合之潜力此处仅是冰山一角， 在巡洋舰之前的一些文章里，进行了更详尽的论述：
- 许铁-巡洋舰科技：[AI和脑科学是否会再度握手？](https://zhuanlan.zhihu.com/p/53779357)
- 许铁-巡洋舰科技：[深度学习与脑科学的握手-圣城会议归来](https://zhuanlan.zhihu.com/p/55925386)

参考
- https://www.nature.com/articles/s41586-019-1424-8
- https://www.nature.com/articles/nature04701
- https://www.ncbi.nlm.nih.gov/pubmed/29154129


## [张首晟在谷歌演讲：量子计算、人工智能与区块链](https://tech.ifeng.com/a/20180609/45019857_0.shtml)

![](http://p3.ifengimg.com/a/2018_23/de8945d705435dd_size245_w1280_h863.jpg)

>- 张首晟，美籍华裔物理学家，美国文理科学院院士，美国国家科学院院士、中国科学院外籍院士。
>- 曾任斯坦福大学J.G. Jackson和C.J. Wood讲座教授，并创立丹华资本从事美国和中国前沿科技领域的投资。
>- 2018年12月1日因抑郁症自杀
本文据张首晟教授近日在谷歌的主题演讲整理而成。

以下为演讲全文：

谢谢各位前来。我非常开心来到谷歌，被Daya介绍同样无比的荣幸。在此之前，我们已经彼此交流了很久，今天我想跟你们分享一些个人的看法。

关于未来信息技术内容，包括：`量子计算`，AI`人工智能`、`区块链`。特别是这三者的联系。我相信目前学术界有很多学者已经在研究这几方面的内容，但有机会能来参加此次学术会议我还是相当兴奋，因为会议研究的主要内容是：三者的内在联系。

首先跟大家分享一个“古老的”科学新发现。

多科学问题都对应着深刻的哲学问题，我们存在于一个`对立统一`的世界中，这个世界中
- 有正数，也有负数；有借款也有贷款；有阴也有阳；有好人也有坏人；天使也有魔鬼。

在现实生活中同样也存在着对应的道理。

1928年，其中一位全世界最著名的理论物理学家-狄拉克保罗，尝试将爱因斯坦相对论运用于量子力学。在数学公式推导的过程中，他遇到了不少的平方根计算。随后回想到自己高中时期的平方根问题，9的平方根不仅等于3，因为3的平方等于9，有-3的平方也等于9。所以当你对一个正数开方时会同时得到一个正数和一个负数。

狄拉克对开方得出的负数相当不解，这件事对迪拉克产生了深远的影响。他预言<font color='blue'>世界上的所有物质，都有正物质和反物质两种形态</font>。如今在威斯敏斯特教堂，你依旧能找到保留完好的迪拉克公式手稿。

2012年获得的“保罗狄拉克勋章”是对我的研究工作最值得肯定。就像我刚才讲的一样：当你对一个数开方，可以得到一正一负两个数字，存在负数是宇宙的一大规律。也就是说只要是宇宙中的物质，就一定存在反粒子。现在看来这是一个再正常不过的完美等式。但在1928年，那个没有反物质的年代，提出这样的理论很不容易。比如当时的人认为：电子的反粒子是一种质量相等但带负电的粒子--质子，虽然质子带的电荷与电子相反，但它的质量却是电子的2000多倍所以那时根本没有人相信他。

但你们猜他说什么？老子的公式如此超前，你们这帮学渣还是先去练级吧。人们确实去提升等级了。狄拉克非常幸运，五年之后，在观测宇宙辐射的时候（地球上很难观测到，但宇宙中存在），科学家们捕捉到了反粒子，并命名为正电子和电子质量相同但带电相反。

我觉得这是人类历史上一次伟大的假设。前期假设很美好，后期结果也很给力。如今人类已经将反粒子应用于医疗方面，比如著名的医学成像技术--`正电子层析成像技术`，就是利用了反粒子的理论研究出来的。好莱坞也有很多类似的电影题材，比如大家所熟知的`达芬奇密码`的续集，`天使与魔鬼`（原著作者丹布朗，主演汤姆汉克斯）电影的高潮部分就是一段天使与魔鬼为争夺反物质而展开的史诗般战斗。

宇宙中到处可见`反物质`，如果你拥有了`反物质`或者`反粒子`，灭霸估计都难奈你何。但这一切都是基于一个美好的推论上，但人类的好奇心从未停止。在狄拉克的伟大假设之后，又有一位伟大的物理学家走入了我们的视野：`埃托马略安娜`。

他提出了一个问题：<font color='red'>有没有一种物质不含反粒子，或者有没有一种物质，本身就是他自己的反物质</font>。他提出假设，写下等式。但这次他没有那么幸运，没有人相信他，没有人见过这个公式，他本人也比较失望。从那以后，这个问题就成了基础科学中一个未解之谜。

我们有一个科学亟待解决问题列表。比如在这个列表上有什么是`上帝粒子`和`波色子`？好在在2012年日内瓦的一个实验室内上述问题有了答案。再比如`引力波`，它的提出人`爱因斯坦`就没有`狄拉克`这么幸运了。100年后才被人们发现有引力波这种物质，前两年才得到证实引力波的存在。这就是那个神奇的列表反物质粒子也在其中。而诸如什么物质的反物质是它本身这样的问题也就是玛丽安娜费米粒子问题，一直在这个列表的最顶端。

也许寻找玛丽安娜费米粒子是科学家们最感兴趣的问题。就像我刚才讲的一样。玛丽安娜非常失望，因为没有人相信他。

安娜是意大利人。但他登上从纳皮尔开往巴勒莫的渡船后从此消失。这是科学界的一个未解之谜。从他消失到今年已经整整80年了，不过告诉大家一个“好消息”：不仅他消失了，他撰写的文献也没有找到。这才是我今天的重点好嘛。他当时是写下了推导的公式，但是没有告诉任何人公式放置的地点。这就是为什么我们花了80年去寻找它的原因，但我们在斯坦福的科研小组提出了在哪里和怎样找到这些粒子？

2010年至2015年前，我们小组撰写了三篇文献。第一篇就是**准确预测粒子的位置**。令我们吃惊的是该粒子并不在大型的粒子加速器中，而在我们常见的一种半导体器件中。之前我已经介绍过了，我们小组十年前发现的一种物质，学名叫`拓扑绝缘体`，在这种绝缘体中放一些磁性的掺杂剂。拓扑绝缘体的材料是一些普通的绝缘体，而磁性掺杂剂是铬这种物质。这样在两种物体的表面，就会形成一个超导体。我们认为在这种条件下，能够捕捉到玛丽安娜费米粒子但仅仅这样还远远不够。我们不仅要找出粒子存在的位置，还需要找到需要测量的物理量，好在常识帮到了我们。一般情况下，粒子都有两面性，像硬币的两面，有正面，有反面，有正粒子，有反粒子。但是玛丽安娜费米粒子只存在一种粒子：**只有正粒子，没有负粒子**。他就是传说中的半粒子所以这个半粒子的概念，将会在我接下来的量子计算演讲中异常重要。

好了，不管怎样，玛丽安娜费米粒子是普通粒子的半粒子对于普通粒子都会存在一定的电导率或导电率。这种电导率一般都能被量子能极化，表现出零级一级二级等能级普通粒子的能级是离散的整数。所以，如果玛丽安娜费米粒子半粒子那么它表现出的能级特征应该是普通等级的1/2能级3/2能级。所以在半粒子这个系统中，你能够测量导电率，但一定要在半能级的位置进行测量。

去年在与加州大学加州洛杉矶分校的同事合作中，他们将我们提出的理论模型变为现实。在理论研究的基础上，测量了玛丽安娜费粒子的能量。在一二这种整数能级的中间会有1/2这样的半能级。1/2能级就是玛丽安娜费米粒子为半粒子的关键证据，普通粒子整数能级。玛丽安娜费米粒子半步能级去年《科学》杂志将该成果刊登后，我们好好庆祝了一番。

在那个激动的时刻，我又想起了曾经看过的电影--天使与魔鬼。我觉得我们在天堂只找到了天使，并没有找到魔鬼，所以我们称该粒子为天`使粒子`。所以说了这么多，到底有什么用？传统的计算机已经相当强大，但他们擅长的东西并不全面。我给两个超大的数字让计算机做加法，他秒秒钟就算出来了。例如谷歌云，他算得超级快。但如果给计算机一个数字，让她产生两个相关的数字。比如15等于5×3，但11就不能。你可能说11等于1×11，但是没有意义。如果给一个超级超级超级大的数字，它分解成两个相关的数字，像分解15一样，或者像11不能分解，传统的计算机怕是要蒙圈了。唯一的办法就是进行海量的搜索，从2开始一直搜索下去，到永远。

所以计算机运行的最大问题是什么？像谷歌云这样的计算，本质就是一个寻找最优解的过程。当机器寻找最优解时就会搜索所有的可能性，包括寻找最短路径等方式。这个过程都要花费大量的时间做最优化搜索，这会消耗大量的时间。这就是为什么计算机还需要不断更新迭代的原因？

让我们进入到`量子世界`看看，量子世界的秘密是什么？假设屏幕上有一对双缝，我用一把普通的手枪分别射击双缝子弹。要么通过左边，要么通过右边的缝隙。在屏幕后方你将看到两个弹痕，左右各一个。但如果你尝试通过双缝射击两个基本粒子，情况就不一样了。背后看到的不是左右两个弹痕，而是一副复杂的干涉图样。当两个粒子同时穿过双缝，干涉图样产生，他同时穿过左右两个缝隙。如果不是同时穿过，干涉则不能产生。所以量子世界就是一个平行的世界：**两个粒子同一时间同时穿过两个缝隙**。

很多人就在思考刚才的问题。传统计算机解决复杂问题的能力，也许可以使用一台量子计算机，同一时间同时搜索所有可能的答案。也就是说，理论上，计算机可以同时搜索所有的可能答案，然后立马给你计算答案，能够这样迅速的提高计算机的计算能力，想想就好兴奋呢！

我接下来跟大家分享一下`人工智能`，人工智能也是一个基本概念，60年代就已经提出来。之所以今天人工智能能够有突飞猛进的发展，主要是三个大的潮流的汇总。
- **计算能力**：根据摩尔定律的迭代，每过18个月能够翻倍，如果用量子计算的话，不只是按摩尔定律18个月翻倍，而是完全从量变到质变的，我们的计算能力在不断增长，和过去40年差不多。
- **大数据**：另外互联网和物联网的产生，造成大量的大数据，大数据又是帮机器能够真正学习，再好的算法，再powerful的计算机没有数据的话不能达成最佳的人工智能
- **算法**：另外也有智能算法的发现，并且有突飞猛进的变化。

但是整个人工智能，大家虽然看到它突飞猛进在改变，但是我觉得还是处在非常早期，它今后的前景还是非常广阔。为什么这么讲呢？做一个简单的类比，比如我们曾经看到鸟飞，人也非常想飞，但是早期学习飞行只是简单的仿生，我们在自己的手臂上绑上翅膀。但这是简单的仿生，但真正达到飞行的境界是由于我们理解了飞行的第一性原理就是`空气动力学`，有了数学原理和数学方程之后就可以人为设计最佳的飞行，就是现在的飞机飞得又高又快又好，但是并不像鸟，这是非常核心的一点。可能现在人工智能是在简单地模仿人的神经元，但是我们更应该思考的，在这里面有一个基础科学重大突破的机会，就是我们真正去理解那个智慧和智能的基本原理，基本的数学原理，这样真正能够使人工智能有突飞猛进的变化。

另外大家经常问的到底用什么样的判据能够真正衡量人工智能达到人的标准？大家可能听说过`图灵测试`，图灵测试是说人跟机器对话，但是我们不知道大在背面到底是人还是机器。整个对话的过程中，你如果花了一天的时间根本感觉不出来，那就是说机器人好像已经达到人的水平。我是不太赞同，虽然图灵是一个伟大的计算机科学家，但是我并不赞同这个判决。人也是进化的过程，人的很多情感并不是理性的情感，要让一个理性的机器学一个非理性的人的大脑可能并不是那么容易，比如你可能故意激怒机器人的话，说不定它也不怎么会理你。

所以我想提出一个新的判据，**机器怎么说哪一天真正超越人的智力？**人最伟大的一点就是我们能够做科学的发现，最好的判据就是**哪一天机器人真能够做科学发现，更好地指导科学发现**，那一天机器就超过人了。

最近我在人工智能里面写了一篇文章，将会在美国的科学院杂志上发表，题目叫“Atom2Vec”，人类最伟大的科学发现之一，有相对论、量子力学，在化学里面最伟大的发现就是元素周期表的发现。今天的机器假定我们根本不知道元素周期表这件事情，今天的机器在没有任何辅导的情况下，他自己能不能**自动发现元素周期表**？我们输入的就是所有存在的科学元素的名字，把这些化合物的名字输入这个算法里面，结果这个机器自然地发现了元素周期表，它可以做出人类认为最伟大的科学发现。然后我们这个程序可以帮助我们发现新药，也可以用机器学习的办法发现新的材料。

接下来我会再跟大家分享我最后一个题目`区块链`，人工智能在突飞猛进发展，但是人工智能最缺少的是数据，恰恰今天数据是处在完全中心垄断的状态里面，不能帮助机器合理地学习。大家听说在一个星期之前Facebook很多个人的数据被盗一样，至少在没有被允许下就用。在今天的世界个人会产生出很多的数据，个人的基因数据、医疗数据、教育数据、行为数据等。但是很多这些数据都是掌握在中心机构里面，没有达到真正的去中心化。但是区块链的产生就是能够产生一个数据市场。所以我理想的世界，未来每人拥有自己所有的数据，这是完全去中心化的储存，这样黑客也不可能黑每个人的数据。然后用一些加密的算法在区块链上真正能够达到既保护个人的隐私，又能够做出良好的计算。

所以我把今后区块链的整个理念用一句话来描写，叫“In Math we trust”，我们的信念建筑在数学上。这张表大家应该记得，我看到很多人在照相，某一天它肯定会为整个区块链和整个IT领域里面最基础的，它既是最基础的数学，又是能导致数据市场里面保护个人隐私，又能够做出合理的统计性的计算。比如有一种非常神奇的计算方法叫零知识证明，它能够向你证明我的数据是非常有价值的，但是又不告诉你真正隐私的数据在哪。

我今天报告的题目主要是有一个核心的理念，就是要使得IT真正能够发展，既需要物理学，又需要数学。深圳在应用方面做得不错，但是由于大学还不是在全世界范围里面最领先的大学，但是我建议最核心的投资，这一类的数学和物理，跟IT领域真正有紧密的联系。

有了区块链之后，这个数据市场的产生，我们也真正能够使得**社会变得更加公平**，我们现在社会最大的不公平是我们**容易歧视一些少数派**。但是在机器学习的过程中最需要的就是那些少数派所拥有的数据。如果今天机器学习的精准率达到90%了，我要使90%达到99%，它需要的不是已经学过的数据，而是跟以前最不一样的数据。往往是少数派拥有的数据对机器学习来讲是最有价值的。一旦我们建筑在区块链的基础上，再加上这些奇妙的数学算法之后，我们就能够真正达到数据市场，在这个数据市场里面，这些少数派所拥有的数据是最可贵的。这样的话我们真正能够把一个丑小鸭变成一个美天鹅，因为丑小鸭并不是丑，只是跟别人不一样而已，在这个世界里面真正达成区块链和人工智能互相共存的世界理念，它们是会最有价值的。

整个区块链，大家对它的认识还不是最根本的`第一性原理`的认识。用最基本的物理学原理来讲，达到共识就是大家都同意同一个账本，就相当于在物理学里面，比如磁铁本来是杂乱无章的，但是到了铁磁态里面它们指向的方向都是同一样的。所以达到共识在自然世界里面有，在今天的人文世界里面也有。但这种现象是叫`熵减`的现象，达到共识，大家都朝一个方向的话，这个状态的熵是远远比杂乱无章的熵要小。达到这个共识是非常难的，因为熵总是在增的，今天你要把它减是很难的事情。在区块链上能达到一个共识系统都是用一种算法，在这上面是需要消耗能量。大家可能一开始不太理解为什么这件事情听起来不合理，一些账户为什么要耗费能量。从物理学第二定理来讲，这是非常合理的一件事情，因为达到共识本身是熵减，但整个世界的熵一定要增加，所以在达到共识的同时一定要把另外一些熵排除出去。这种没有中心化的机制跟自然世界里面磁铁从杂乱无章的状态达到有序的铁磁状态非常相像，这付出的代价也是必然的趋势。

我在这里跟大家分享，我除了做斯坦福大学教授之外，也是丹华资本创办人，我们主要的核心理念就是要**把今天最前沿的科技和投资要紧密联系起来，要用第一性原理的思维方式来理解今天的世界**。

我另外想讲的是我是来自学界，我们在整个人工智能领域里面需要做两个大的桥梁，一个是要学界和产业界做紧密的联系，在学界有最好的物理、最好的数学和算法的发现和发明。在今年1月8日，我非常荣幸在人民代表大会堂受到习总书记给我授予的中华人民共和国国际科技合作奖。我们整个世界科学是最无止境、最没有国界的，科学能真正把人类带到超越国界的，今天我们所要解决的人工智能、量子计算都是整个人类的问题。所以我们一定要把我们的眼光不要放在自己的局部，而是放眼整个全球和整个世界。在这个过程中，中国也是一个非常大的机遇，大家都想回答的问题，我们中国除了把应用科技做得好，能不能在中国有真正原创科技的产生。我今天跟大家介绍的这些都是最基本的物理和最基本的数学原理，我们这方面能够做好的话，而且这些原理听起来比较抽象，比如熵增原理，正负电子。但是在最基本的层次上，这是我们今天这个世界的奇妙，它真正能够给整个IT行业提供最基本的科学技术发展的前景。


# 结束