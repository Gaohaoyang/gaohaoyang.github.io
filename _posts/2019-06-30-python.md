---
layout: post
title:  "Python技能"
date:   2019-06-30 19:17:00
categories: 技术工具
tags: Python Numpy Pandas pyecharts virtualenv pypy yaml 面向对象 装饰器 anaconda conda 设计模式 多进程 多线程 regex GUI 界面
author : 鹤啸九天
excerpt: Web开发相关技术知识点
mathjax: true
---

* content
{:toc}

# 总结

- 【2021-1-23】python代码调用过程可视化工具，[ryven](https://ryven.org/index)
  - ![](https://ryven.org/img/examples/ryven1.png)


- aadict包：在dict的基础上封装了一层，使其能够像操作属性一样使用字典。使得后续操作更加简便且易读，还可以预防不必要的异常出现。
- 代码示例

```python
from addict import Dict

configs = Dict()

configs.platform.status = "on"
configs.platform.web.task.name = "测试-1204"
configs.platform.web.periods.start = "2020-10-01"
configs.platform.web.periods.end = "2020-10-31"
# 获取不存在的key时会返回一个空字典，不用担心报KeyError，对返回值做判空处理即可
app_configs = configs.platform.app
assert app_configs == {}
```

# Python语法

- 【2021-12-8】Python基础知识闯关游戏：[CheckiO](https://py.checkio.org/)
  - ![](https://p6.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/8c1d4ebf3a9549f5a97422bc30bcea2d.png)

## 基础数据结构

Python中的内置数据结构（Built-in Data Structure）:列表list、元组tuple、字典dict、集合set
- list
  - list的显著特征：
    - 列表中的每个元素都可变的，意味着可以对每个元素进行修改和删除；
    - 列表是有序的，每个元素的位置是确定的，可以用索引去访问每个元素；
    - 列表中的元素可以是Python中的任何对象；
    - 可以为任意对象就意味着元素可以是字符串、整数、元组、也可以是list等Python中的对象。
    - Python中包含6中內建的序列：列表，元组，字符串、Unicode字符串、buffer对象和xrange对象
- tuple
  - 元组Tuple，用法与List类似，但Tuple一经初始化，就不能修改，没有List中的append(), insert(), pop()等修改的方法，只能对元素进行查询
- dict
  -  字典dictionary全称这个概念就是基于现实生活中的字典原型，生活中的使用名称-内容对数据进行构建，Python中使用键(key)-值(value)存储，也就是java、C++中的map。
  - 字典中的数据必须以键值对的形式出现，即k,v： 
    - key:必须是可哈希的值，比如intmstring,float,tuple,但是，list,set,dict不行 ; value:任何值
  - 键不可重复，值可重复,键若重复字典中只会记该键对应的最后一个值
  - 字典中键(key)是不可变的，何为不可变对象，不能进行修改；而值(value)是可以修改的，可以是任何对象。在dict中是根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。
- set
  - 集合更接近数学上集合的概念。集合中每个元素都是无序的、不重复的任意对象。可以通过集合去判断数据的从属关系，也可以通过集合把数据结构中重复的元素减掉。集合可做集合运算，可添加和删除元素。
  - 集合内数据无序，即无法使用索引和分片, 集合内部数据元素具有唯一性，可以用来排除重复数据, 集合内的数据:str,int,float,tuple,冰冻集合等，即内部只能放置可哈希数据
  - frozen set:冰冻集合是不可以进行任何修改的集合
frozenset是一种特殊集合
  - 常用方法
    - intersection：交集
    - difference：差集
    - union：并集
    - issubset：检查一个集合是否为另一个子集
    - issuperset：检查一个集合是否为另一个超集 


```python
mylist = ['Google', 'Yahoo', 'Baidu']
#变更索引位置1Yahoo的内容为Microsoft
mylist[1] = 'Microsoft'
#获取索引位置1到5的数据，注意这里只会取到索引位置4,这里叫做取头不取尾
mylist[1:5]   # 'Tencent', 'Microsoft', 'Baidu', 'Alibaba'
#获取从最头到索引位置5的数据
mylist[ :5]   #'Google', 'Tencent', 'Microsoft', 'Baidu', 'Alibaba'

#获取从索引位置2开到最后的数据
mylist[2:]    #'Microsoft', 'Baidu', 'Alibaba','Sina'
mylist.append('Alibaba')  #运行结果： ['Google', 'Microsoft', 'Baidu', 'Alibaba']
mylist.insert(1, 'Tencent')  # ['Google', 'Tencent', 'Microsoft', 'Baidu', 'Alibaba']
# 删除尾部元素
mylist.pop()      # 会返回被删除元素
# 删除指定位置的元素
mylist.pop(1)  # 删除索引为1的元素，并返回删除的元素
mylist.remove('Microsoft') #删除列表中的Microsoft
del mylist[1:3]       #删除列表中索引位置1到位置 3 的数据
mylist.sort()          # 排序 [1, 2 ,4, 5]
# 【2021-10-22】list元素排序，非原地
table_data = sorted(table_data,key=lambda x:x[1], reverse=True)
print(len(mylist)) # 长度

a = [1,2,3,4,5,6]
#在a的数据基础上每个数据乘以10，再生成一个列表b，
b = [i*10 for i in a]
#生成一个从1到20的列表
a = [x for x in range(1,20)]
#把a中所有偶数生成一个新的列表b
b = [m for m in a if m % 2 == 0]
print(b)

# tuple
a = (1,2,3,4)

# dict
d = {}
d = dict() # 创建空字典2
d = {"one":1,"two":2,"three":3,"four":4} #直接赋值方式
d = dict.fromkeys(d.keys(), "222")
d = {k:v for k,v in d.items()} #常规字典生成式
d = {k:v for k,v in d.items() if v % 2 ==0} #加限制条件的字典生成方式
print(d.get("one333"))
del d["one"] #删除一个数据,使用del
d.clear() # 清空字典
print(d)

if "two" in d:
    print("key")

#for k in d:
#for v in d.values():
for k in d.keys():
    print(k,d[k])
for k,v in d.items():
    print(k,'--->',v)
#for key, value in enumerate(words):

# 通用函数：len,max,min,dict
d = {"one":1,"two":2,"three":3,"four":4}
print(max(d), min(d), len(d))

#集合的定义
s = set()
s = frozenset() # 冰冻集合
s = set([1,2,3])
s.add(6)
s.remove(2)

s1 = {1,2,3,4,5,6,7}
s2 = {5,6,7,8,9}

#交集
s_1 = s1.intersection(s2)
#差集
s_2 = s1.difference(s2)
#并集
s_3 = s1.union(s2)
#检查一个集合是否为另一个子集
s_4 = s1.issubset(s2)
print("检查子集结果：",s_4)
#检查一个集合是否为另一个超集
s_5 = s1.issuperset(s2)
print("检查超集结果：",s_5)

```

## 高级数据结构

- 【2021-3-11】[Python高级数据结构详解](https://www.jb51.net/article/62930.htm)
- Collection、Array、Heapq、Bisect、Weakref、Copy以及Pprint这些数据结构的用法
- Collections
  - collections模块包含了内建类型之外的一些有用的工具，例如Counter、defaultdict、OrderedDict、deque以及nametuple。其中Counter、deque以及defaultdict是最常用的类。
  - Counter：统计频次
  - Deque：双端队列
    - Deque是一种由队列结构扩展而来的双端队列(double-ended queue)，队列元素能够在队列两端添加或删除。因此它还被称为头尾连接列表(head-tail linked list)
    - Deque支持线程安全的，经过优化的append和pop操作，在队列两端的相关操作都能够达到近乎O(1)的时间复杂度。虽然list也支持类似的操作，但是它是对定长列表的操作表现很不错，而当遇到pop(0)和insert(0, v)这样既改变了列表的长度又改变其元素位置的操作时，其复杂度就变为O(n)了
  - Defaultdict: 默认字典
- Array
  - array模块定义了一个很像list的新对象类型，不同之处在于它限定了这个类型只能装一种类型的元素。
  - 省空间，但时间慢：如存储一千万个整数，用list至少需要160MB的存储空间，而使用array只需要40MB。但虽然说能够节省空间，array上基本操作比list慢。
  - 列表推导式(list comprehension)时，会将array整个转换为list，使得存储空间膨胀。一个可行的替代方案是使用生成器表达式创建新的array
- heapq
  - heapq模块使用一个用堆实现的优先级队列。堆是一种简单的有序列表，并且置入了堆的相关规则。堆是一种树形的数据结构，树上的子节点与父节点之间存在顺序关系。
  - 函数：
    - heappush(heap, x) : 将x压入堆中
    - heappop(heap): 从堆中弹出最小的元素
    - heapify(heap) : 让列表具备堆特征
    - heapreplace(heap, x) : 弹出最小的元素，并将x压入堆中
    - nlargest(n, iter) : 返回iter中n个最大的元素
    - nsmallest(n, iter): 返回iter中n个最小的元素
- Bisect
  - bisect模块能够提供保持list元素序列的支持，使用了二分法完成大部分的工作。它在向一个list插入元素的同时维持list是有序的。
- Weakref
  - weakref模块能够帮助我们创建Python引用，却不会阻止对象的销毁操作。
  - strong reference是一个对对象的引用次数、生命周期以及销毁时机产生影响的指针。
  - Weak reference则是对对象的引用计数器不会产生影响。当一个对象存在weak reference时，并不会影响对象的撤销。这就说，如果一个对象仅剩下weak reference，那么它将会被销毁。
- Copy()
  - 通过shallow或deep copy语法提供复制对象的函数操作。shallow和deep copying的不同之处在于对于混合型对象的操作(混合对象是包含了其他类型对象的对象，例如list或其他类实例)。
  1. 对于shallow copy而言，它创建一个新的混合对象，并且将原对象中其他对象的引用插入新对象。
  2. 对于deep copy而言，它创建一个新的对象，并且递归地复制源对象中的其他对象并插入新的对象中。
- Pprint()
  - Pprint模块能够提供比较优雅的数据结构打印方式，如果你需要打印一个结构较为复杂，层次较深的字典或是JSON对象时，使用Pprint能够提供较好的打印结果。

```python
from collections import Counter
 
li = ["Dog", "Cat", "Mouse", 42, "Dog", 42, "Cat", "Dog"]
a = Counter(li)
print(a) # Counter({'Dog': 3, 42: 2, 'Cat': 2, 'Mouse': 1})
print(len(set(li))) # 4
print(a.most_common(3)) # [('Dog', 3), ('Cat', 2), ('Mouse', 1)]

from collections import deque

q = deque(range(5))
q.append(5)
q.appendleft(6)
print q
print q.pop()
print q.popleft()
print q.rotate(3) # 队列的旋转操作,Right rotate(正参数)是将右端的元素移动到左端，而Left rotate(负参数)则相反

from collections import defaultdict

location = defaultdict(['a', 'b']) # 有序
location = defaultdict(('a', 'b')) # 无序

# 对于较大的array，这种in-place修改能够比用生成器创建一个新的array至少提升15%的速度
import array

a = array.array("i", [1,2,3,4,5])
b = array.array(a.typecode, (2*x for x in a)) # 节省空间
for i, x in enumerate(a): # 提效
    a[i] = 2*x

import heapq
 
heap = []
for value in [20, 10, 30, 50, 40]:
    heapq.heappush(heap, value) # 入堆

while heap:
    print heapq.heappop(heap) # 出堆

nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
print(heapq.nlargest(3, nums)) # Prints [42, 37, 23]
print(heapq.nsmallest(3, nums)) # Prints [-4, 1, 2]
expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price']) # 针对字典的复杂操作

import bisect
 
a = [(0, 100), (150, 220), (500, 1000)]
bisect.insort_right(a, (250,400))
print bisect.bisect(a, (550, 1200)) # 5 寻找插入点
print a # [(0, 100), (150, 220), (250, 400), (500, 1000)]



import weakref

a = Foo() #created
b = a() # 强引用
b = weakref.ref(a) # 弱引用
b = weakref.proxy(a) # proxy更像是一个strong reference，但当对象不存在时会抛出异常
# 删除strong reference的时候，对象将立即被销毁
del a

import copy

a = [1,2,3]
b = [4,5]
c = [a,b]

d = c # 正常复制
print id(c) == id(d)          # True - d is the same object as c
print id(c[0]) == id(d[0])    # True - d[0] is the same object as c[0]

d = copy.copy(c) # Shallow Copy 浅拷贝，创建一个新的容器，其包含的引用指向原对象中的对象
print id(c) == id(d)          # False - d is now a new object
print id(c[0]) == id(d[0])    # True - d[0] is the same object as c[0]

d = copy.deepcopy(c) # Deep Copy 深拷贝，创建的对象包含的引用指向复制出来的新对象
print id(c) == id(d)          # False - d is now a new object
print id(c[0]) == id(d[0])    # False - d[0] is now a new object

import pprint

matrix = [ [1,2,3], [4,5,6], [7,8,9] ]
a = pprint.PrettyPrinter(width=20)
a.pprint(matrix)

# [[1, 2, 3],
#  [4, 5, 6],
#  [7, 8, 9]]

```

## import 工具包导入

使用 import 导入的东西只有三种： 包, 模块, 其他对象.
- `包`:  __init__.py 文件所在目录
  - 该文件用于组织包（package），方便管理各个模块之间的引用、控制着包的导入行为。
  - 可以是空文件，表示导入所在目录的所有文件，也可以指定导入的包 __ALL__ = ['a.py','b.py']，但不建议写模块，以保证该文件简单。
    - **模糊**导入时，形如from package import *，*是由__all__定义的。
    - **精确**导入，形如 from package import *、import package.class。
  - __path__也是一个常用变量，是个列表，默认情况下只有一个元素，即当前包（package）的路径。修改   path   可改变包（package）内的搜索路径。
- `模块`: 单个 .py 文件
- 其他`对象`: 除了 包 和 模块 以外的 Python Object
使用 import 的两种格式：
- import package/module
- from package/module import object
单独使用 import 的时候， 导入的只能是 `包` 或 `模块`. 而 from ... import ... 的形式则可以从 `包` 或 `模块` 中导入任意`对象`。

Python在导入import包的时候，有绝对导入和相对导入方式。
- **绝对**导入：import p1.m1 或者 from p1 import m1 等。
- **相对**导入：from . import m1 或者 from .. import m1 或者 from ..p1 import m1 或者 from .m1 import f1等。 
  - 相对导入的方式只能用在 `包` **内部**， 语法格式为：from . import object, 
  - . 代表**当前**目录, .. 代表**父级**目录， 之后每多一个点代表目录上升一层。
  - 代表相对路径的符号 . 只能出现在 from 后面而不能出现在 import 后面， 即：
比较而言，绝对导入更为简便清晰，相对导入则可维护性强，但是容易出错。

[史上最详解的 导入（import）](https://blog.csdn.net/weixin_38256474/article/details/81228492)
- （1）标准导入：“标准”import，顶部导入
  - ![](https://img-blog.csdn.net/2018072714235219?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI1NjQ3NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
- （2）顺序导入
  - 嵌套导入；各个模块的Local命名空间的独立的。即：
    - test模块 import moduleA后，只能访问moduleA模块，不能访问moduleB模块。虽然moduleB已加载到内存中，如需访问，还得明确地在test模块 import moduleB。实际上打印locals()，字典中只有moduleA，没有moduleB。
    - ![](https://img-blog.csdn.net/20180727142629596?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI1NjQ3NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
  - 循环导入/嵌套导入
    - ![](https://img-blog.csdn.net/20180727142811352?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI1NjQ3NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
 
[python导入相关](https://rgb-24bit.github.io/blog/2018/python-import.html)，绝对导入可以在任何地方使用， 所有非 相对导入 都是绝对导入。

绝对导入根据 sys.path 来查找 包 或 模块. sys.path 是一个列表， 通常情况下会包含
- 内建模块 的索引路径
- 第三方库 的保存路径
- 环境变量 PYTHONPATH 列出的目录
- 脚本所在目录或当前目录
前三个路径一般不需要怎么管， 容易出现问题的地方是第四个 脚本所在目录或当前目录.

首先，需要清楚的一点是：这个路径会被添加到 sys.path 最前面， 所以如果该路径下存在和内建或第三方库同名的模块或包， 使用绝对导入会优先导入那个同名的模块。然后就是确定添加的这个目录到底是 脚本所在目录 还是 当前目录 了。

汇总一下：
- 直接执行脚本 时添加的路径是 脚本所在目录.
- 使用 Python -m 的方式执行脚本时， Python2 添加的是 脚本所在目录, 而 Python3 添加的是 当前目录.
- 同一目录下， 同名的 包 和 模块, 包 的导入优先级比 模块 高。可以得出的一个优先级排序为：
  - 当前目录或脚本所在目录 ==> 内建模块 ==> 第三方库
  - 包 ==> 模块
- import 会生成 .pyc 文件, .pyc 文件的执行速度不比 .py 快， 但是加载速度更快
- 重复 import 只会执行第一次 import
- 如果在 执行过程中 中 import 的模块发生改动，可以通过 reload 函数重新加载
- from xxx import * 会导入除了以 _ 开头的所有变量，但是如果定义了 __all__, 那么会导入 __all__ 中列出的东西
- import xxx.object 的方式不能直接使用 object, 仍然需要通过 xxx.object 的方式使用
- import xxx.object as obj 的方式可以直接使用 obj
Python3.4 之后的版本中， 内置函数 reload 被移除了， 要使用可以通过 from importlib import reload 导入

```python
# -*- coding: utf-8 -*-
# 绝对导入
import sys
print(sys.path[0:1])
# 相对导入
from . import utils  # True
import .utils  # False

from xxx import * # 会导入除了以 _ 开头的所有变量，但是如果定义了 __all__, 那么会导入 __all__ 中列出的东西
import xxx.object # 不能直接使用 object, 仍然需要通过 xxx.object 的方式使用
import xxx.object as obj # 直接使用 obj

# 批量导入
from click import (
    argument,
    command,
    echo,
    edit,
    group,
    Group,
    option,
    pass_context,
    Option,
    version_option,
    BadParameter,
)

import sys, os

print(__file__)    #当前.py文件的位置
print(os.path.abspath(__file__))  #返回当前.py文件的绝对路径
print(os.path.dirname(os.path.abspath(__file__)))   #当前文件的绝对路径目录，不包括当前 *.py 部分，即只到该文件目录
print(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) #返回文件本身目录的上层目录    
print(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))  #每多一层，即再上一层目录

print(os.path.realpath(__file__))   #当前文件的真实地址
print(os.path.dirname(os.path.realpath(__file__))) # 当前文件夹的路径

path = os.path.dirname(os.path.abspath(__file__))
sys.path.append(path)   #将目录或路径加入搜索路径

print(__name__)
```

## 时间计算

time和datetime两个模块，转换流程：[时间格式转换图](https://blog.csdn.net/ncut_wxj/article/details/108011326)
- ![img](https://img-blog.csdnimg.cn/20200814181152376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25jdXRfd3hq,size_16,color_FFFFFF,t_70#pic_center)


代码：

```python
import time
import datetime

print('time用法')
time_now = int(time.time())              # 获取当前时间的时间戳
print(int(datetime.datetime.now().timestamp()))     # 获取当前时间的时间戳
print(int(time.time()))              # 获取当前时间的时间戳
today = datetime.datetime.today().date()
yestoday = today + datetime.timedelta(days=-1)
tomorrow = today + datetime.timedelta(days=1)
print(today) # 2019-01-30
print(yestoday)# 2019-01-29
print(tomorrow)# 2019-01-31
print('datetime用法')
dt_now = datetime.datetime.fromtimestamp(time_now)
print(type(dt_now), dt_now)   # <class 'datetime.datetime'> 2020-12-16 10:40:34
print(int(datetime.datetime.now().timestamp()))     # 获取当前时间的时间戳
print('字符串转datetime')
str_p = '2021-10-25 15:29:08'
dateTime_p = datetime.datetime.strptime(str_p,'%Y-%m-%d %H:%M:%S')
print(str_p, dateTime_p) # 2019-01-30 15:29:08
print('datetime转字符串')
print(dateTime_p.strftime("%d/%b/%Y:%H:%M:%S"))    # 16/Dec/2020:11:01:37
print(dateTime_p.strftime('%Y-%m-%d %H:%M:%S'))    # 2020-06-16 10:31:08
print('时间差')
#字符串时间差
start ="2018-06-19 17:37:31"
end = "2019-07-30 17:37:31"
start=time.strptime(start, "%Y-%m-%d %H:%M:%S")
end=time.strptime(end, "%Y-%m-%d %H:%M:%S")
userStart=datetime.datetime(start[0],start[1],start[2])
userEnd=datetime.datetime(end[0],end[1],end[2])
print ((userEnd-userStart).days) # 0 天数
# print (end-start).total_seconds() # 30.029522 精确秒数
# print (end-start).seconds # 30 秒数
# print (end-start).microseconds # 29522 毫秒数
a1='2017-10-04 09:01:04'
a2='2017-10-05 10:02:50'
test1=datetime.datetime.strptime(a1, "%Y-%m-%d %H:%M:%S")
test2=datetime.datetime.strptime(a2, "%Y-%m-%d %H:%M:%S")
diff=test2-test1
print(diff.days)
print(diff.total_seconds())
print(diff.total_seconds()//60)
```

# 安装

## Python库目录

```shell
python -c "import sys; print(sys.path)"
```

## 自动编译安装python

- 【2020-7-3】脚本如下：

```shell

#-----自定义区------
# 下载python3
src_file='https://www.python.org/ftp/python/3.8.3/Python-3.8.3.tgz'
file_name="${src_file##*/}"
install_dir=~/bin
#-------------------
 
[ -e ${file_name} ]||{
        wget ${src_file}
        echo "下载完毕..."
}&& echo "文件已存在, $file_name"
# 解压
tar zxvf ${file_name}
echo "安装目录: $install_dir"
# 安装
new_dir=${file_name%.*}
cd $new_dir
./configure --prefix=${install_dir}/python38
# 如果不设置安装目录prefix, 就会提示sudo权限
make && make install
echo "安装完毕，请设置环境变量"
 
# 设置环境变量
#vim ~/.bash_profile
echo "
alias python3='${install_dir}/python38/bin/python3.8'
alias pip3='${install_dir}/python38/bin/pip3'
" >> ~/.bash_profile
 
echo '生效'
source ~/.bash_profile


echo '修改pip源'
mkdir ~/.pip
echo "
[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
[install]
trusted-host=mirrors.aliyun.com
" > ~/.pip/pip.conf

# 或者一行命令设置
#pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

```

## pip

Python工具包查询网站 [pypi](https://pypi.org/): Find, install and publish Python packages with the Python Package Index


pip工具包

```shell
# pip版本
pip -v

# 从备用索引安装
pip install --index-url http://my.package.repo/simple/ SomeProject 
# 在安装期间搜索附加索引，PyPI
pip install --extra-index-url http://my.package.repo/simple SomeProject
# 指定源
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package matplotlib
# 设为默认
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
# 指定版本
pip install 模块名==版本号
# 安装特定的源存档文件。
pip install ./downloads/SomeProject-1.0.4.tar.gz
# whl包
pip install test.whl
# 批量安装
pip install -r requirements.txt
# 升级
pip install --upgrade package_name
# 查看信息
pip show -f package_name
# 查看已安装的库
pip list
# 已经安装的库中，看哪些需要版本升级
pip list -o
# 把已经安装的库信息保存到到本地txt文件中
pip freeze > requirements.txt
# 验证已安装的库是否有兼容依赖问题
pip check package-name
# 将库下载到本地指定文件，保存为whl格式
pip download package_name -d "要保存的文件路径"
# 卸载
pip uninstall package_name
```

pip install "project\[extra]"
就您而言，您就是installing对splinter的新增支持的软件包django。方括号（\[]）不是特定的语法，只是约定。确实，您正在安装名为的软件包"splinter\[django]"。

来自的解释@chetner：

该命令pip install splinter django将安装两个名为splinter和的软件包django。splinter[django]，另一方面，安装的一个变体splinter，其包含包支持对django。请注意，它与django程序包本身无关，只是splinter程序包为启用的特定功能集定义的字符串。

## pypy

[PyPy是不是真的比Python快？](https://www.toutiao.com/i7029122055677444616/)
-  Python 编写的程序运行不快，这种慢虽无大碍，但为了获得更高的性能，我们需要再切换到另一种编程语言吗？不一定。我们可以放弃python.py的运行方式，转而使用 PyPy 即时编译器。
- Python 创建者 Guido von Rossum 都建议将 PyPy 用于关键性能的 Python 程序。

pypy是Python的**JIT版本**，如果存在大量**高耗时**且**重复执行**的代码那么pypy运行速度比Python快很多. 
- pypy的JIT有开销，代码第一次执行时要做jit故比Python第一次执行慢
- 若多次执行那么pypy执行的是都是jit后的代码，运算速度会大大提高，明显超过Python。

## anaconda

- 下载

```shell
# mac环境下安装
#brew cask install anaconda
brew install anaconda
export PATH="/usr/local/anaconda3/bin:$PATH"

# 官方地址，https://www.anaconda.com/products/individual，上面有最新版本地址
wget https://repo.anaconda.com/archive/Anaconda3-2021.05-Linux-x86_64.sh

# 获取mincoda linux最新版
wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
# mincoda mac用户
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh

# 清华镜像地址: https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/, 找最新下载地址
wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh

bash Anaconda3-2019.03-Linux-x86_64.sh
# [2021-6-15]注意：直接使用以上命令会出错：from conda.cli import main ModuleNotFoundError: No module named 'conda'
# 解法：加-u
bash Anaconda3-2019.03-Linux-x86_64.sh -u 

```

- 安装完成之后会多几个应用
   - Anaconda Navigtor ：用于管理工具包和环境的图形用户界面，后续涉及的众多管理命令也可以在 Navigator 中手工实现。
   - Jupyter notebook ：基于web的交互式计算环境，可以编辑易于人们阅读的文档，用于展示数据分析的过程。
   - qtconsole ：一个可执行 IPython 的仿终端图形界面程序，相比 Python Shell 界面，qtconsole 可以直接显示代码生成的图形，实现多行代码输入执行，以及内置许多有用的功能和函数。
   - spyder ：一个使用Python语言、跨平台的、科学运算集成开发环境。
- 加入环境变量
   - 安装器若提示“`Do you wish the installer to prepend the Anaconda install location to PATH in your /home/<user>/.bash_profile ?`，建议输入“yes”。
   - 如果输入“no”，则需要手动添加路径。添加 export PATH="/<anaconda_path>/bin:$PATH" 在 .bashrc 或者 .bash_profile 中。

- 注意：
   - 不要擅自在bash_profile中添加alias别名！会导致虚拟环境切换后python、pip转换失效

```shell
# anaconda 环境
export PATH="~/anaconda3/bin:$PATH"
# 以下语句不要添加！
alias python='/home/wangqiwen004/anaconda3/bin/python'
alias pip='/home/wangqiwen004/anaconda3/bin/pip'
# 如果仍然失效，强制使用变量切换
sra(){
    CONDA_ROOT="~/anaconda3"
    env=$1
    conda activate $env
    export LD_LIBRARY_PATH="$CONDA_ROOT/envs/$env/lib:$LD_LIBRARY_PATH" 
    export PATH=$CONDA_ROOT/envs/$env/bin:$PATH
}
# 【2020-7-10】以上方法不支持默认环境base的切换，优化如下：
sra(){
    CONDA_ROOT="~/anaconda3"
    # 获取当前虚拟环境名称列表(不含base)
    env_list=(`conda info -e | awk '{if($1!~/#|base/)printf $1" "}'`)
    env=$1
    conda activate $env
    echo "env=$env, str=${env_list[@]}"
    # 判断是否匹配已有环境名称
    # echo "${env_list[@]}" | grep $env && echo "yes" || echo "no"
    #[[ "$1" =~ "${env_str}" ]] && echo "yes" || echo "no"
    #[[ ${env_list[@]/${env}/} != ${env_list[@]} ]] && {
    res="no"
    for i in ${env_list[@]}
    do
         [ "$i" == "$env" ] && res="yes"
    done
    [ $res == "yes" ] && {
        echo "找到目标环境$env"
        export LD_LIBRARY_PATH="$CONDA_ROOT/envs/$env/lib:$LD_LIBRARY_PATH"
        export PATH=$CONDA_ROOT/envs/$env/bin:$PATH
    }||{
        echo "启用默认环境base"
        env="base"
        export LD_LIBRARY_PATH="$CONDA_ROOT/lib:$LD_LIBRARY_PATH"
        export PATH=$CONDA_ROOT/bin:$PATH
    }
    echo "环境切换完毕: --> $env"
}
alias srd='conda deactivate'
# 激活的使用方法
sra learn
```

- 注意：不要这样加！

### 常用命令

- 汇总如下：
   -  [anaconda完全手册](https://www.jianshu.com/p/eaee1fadc1e9)
   - [Anaconda介绍、安装及使用教程](https://zhuanlan.zhihu.com/p/32925500)

```shell
conda --version # 查看版本
activate # 切换到base环境
activate learn # 切换到learn环境
conda create -n learn python=3 # 创建一个名为learn的环境并指定python版本为3(的最新版本，也可以是2.7、3.6等))
conda create -n learn numpy matplotlib python=2.7 # 创建环境同时安装必要的包
conda create -n py36_tf1 python=3.6 tensorflow==1.11 # [2020-7-21]
conda create --prefix="D:\\my_python\\envs\\my_py_env"  python=3.6.3 # 自定义虚拟环境
conda create --name env_name --clone learn # 克隆环境 learn -> env_name
conda env list # 列出conda管理的所有环境, conda info -e 
source activate learn # linux下激活虚拟环境conda activate，windows下为：activate learn
source deactivate # linux下关闭虚拟环境conda deactivate，windows下为：deactivate
conda list # 列出当前环境的所有包
conda list -n learn # 列出某环境下的所有包
conda install requests #安装requests包, 同pip install
conda install -n your_env_name [package] # 即可安装package到your_env_name中
conda remove requests #卸载requets包
conda remove -n learn --all # 删除learn环境及下属所有包
conda remove --name learn  package_name  # 删除learn环境下某个包
# pip install openpyxl -U
# conda update openpyxl
conda update requests # 更新requests包
# conda update --all # 更新所有库
conda search pyqtgraph # 搜索包(模糊查找)
conda search --full-name pyqtgraph # 精确查找
conda env export > environment.yaml # 导出当前环境的包信息
conda env create -f environment.yaml # 用配置文件创建新的虚拟环境

# 添加Anaconda的TUNA镜像
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
# TUNA的help中镜像地址加有引号，需要去掉
# -------- 清华镜像 ---------
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
#Conda Forge
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
#msys2（可略）
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
#bioconda（可略）
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
#menpo（可略）
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/
#pytorch
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
# for legacy win-64（可略）
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/
conda config --set show_channel_urls yes
#-------- 中科大镜像 --------
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/
conda config --set show_channel_urls yes

#-------- 北外镜像 ---------
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main/
#Conda Forge
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/conda-forge/
#msys2（可略）
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/msys2/
#bioconda（可略）
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/bioconda/
#menpo（可略）
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/menpo/
#pytorch
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/pytorch/
# for legacy win-64（可略）
conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/cloud/peterjc123/
# 设置搜索时显示通道地址
conda config --set show_channel_urls yes

# 【2021-6-15】直接修改文件
vim ~/.condarc

channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
ssl_verify: true

```

### 问题解决

- 使用conda install 安装各种包的时候速度很慢，参考：[conda install速度慢](https://blog.csdn.net/mojiewangday/article/details/105583026)
- 解决
   - 修改conda镜像路径
   - 执行如下命令，更换仓库径路为清华镜像路径

```
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
```
   - 在自己用户目录C:\Users<你的用户名>下生成一个文件，名字为：~/.condarc

```
conda config --set show_channel_urls yes
```
   - 修改.condarc文件为如下:

```
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
show_channel_urls: true
ssl_verify: true
```
- 执行完上述三步，conda的镜像路径就更换完毕，如不放心可以 conda info 查看 channel URLs 信息已经更改。

- 【2020-8-22】执行conda install flask-restplus时，pip没问题
   - Solving environment: failed with initial frozen solve. Retrying with flexible solve
   - 解决：执行
      - conda config --add channels conda-forge
      - conda config --set channel_priority flexible

【2021-7-15】问题：
- PackagesNotFoundError: The following packages are not available from current channels
- 解决：conda config --add channels https://anaconda.org (缺失的源)

【2021-9-22】更换清华源后，依然很慢：Collecting package metadata (repodata.json) 出现卡顿/失败
- 解决办法: 将.condarc中的清华源的https全部换成http，或者将代理软件（clash for windows）设置为全局代理
- conda清除国内源：conda config --remove-key channels

# Python功能

## 格式化输出

主要方法：
- %
- format

```python
a = 3.1415
b = 'hello'
c = 'world'

print('%.1f' % a)  # 取1位小数
print('{}'.format(a))
print('{0} {1} {0}'.format(b,c))  # 打乱顺序
print('{a} {tom} {a}'.format(tom='hello',a='world'))  # 带关键字
print('%.3e' % 1.11)  # 取3位小数，用科学计数法
print('{:.2f}'.format(a))
print(f'{a:.2f}') # format的隐含模式
```

## 路径文件

除了os，还有Path，代码：

```python
import os

os.path.abspath(path)	#返回绝对路径
os.path.basename(path)	#返回文件名
os.path.commonprefix(list)	#返回list(多个路径)中，所有path共有的最长的路径
os.path.dirname(path)	#返回文件路径
os.path.exists(path)	#路径存在则返回True,路径损坏返回False
# 判断是否已经存在该目录
if not os.path.exists(File_Path):
    # 目录不存在，进行创建操作
    os.mkdir(File_Path) # 创建一层目录
    os.makedirs(File_Path) #使用os.makedirs()方法创建多层目录
    print("目录新建成功：" + File_Path)
os.path.lexists	#路径存在则返回True,路径损坏也返回True
os.path.expanduser(path)	#把path中包含的"~"和"~user"转换成用户目录
os.path.expandvars(path)	#根据环境变量的值替换path中包含的"$name"和"${name}"
os.path.getatime(path)	#返回最近访问时间（浮点型秒数）
os.path.getmtime(path)	#返回最近文件修改时间
os.path.getctime(path)	#返回文件 path 创建时间
os.path.getsize(path)	#返回文件大小，如果文件不存在就返回错误
os.path.isabs(path)	#判断是否为绝对路径
os.path.isfile(path)	#判断路径是否为文件
os.path.isdir(path)	#判断路径是否为目录
os.path.islink(path)	#判断路径是否为链接
os.path.ismount(path)	#判断路径是否为挂载点
os.path.join(path1[, path2[, ...]])	#把目录和文件名合成一个路径
os.path.normcase(path)	#转换path的大小写和斜杠
os.path.normpath(path)	#规范path字符串形式
os.path.realpath(path)	#返回path的真实路径
os.path.relpath(path[, start])	#从start开始计算相对路径
os.path.samefile(path1, path2)	#判断目录或文件是否相同
os.path.sameopenfile(fp1, fp2)	#判断fp1和fp2是否指向同一文件
os.path.samestat(stat1, stat2)	#判断stat tuple stat1和stat2是否指向同一个文件
os.path.split(path)	#把路径分割成 dirname 和 basename，返回一个元组
os.path.splitdrive(path)	#一般用在 windows 下，返回驱动器名和路径组成的元组
os.path.splitext(path)	#分割路径中的文件名与拓展名
os.path.splitunc(path)	#把路径分割为加载点与文件
os.path.walk(path, visit, arg)	#遍历path，进入每个目录都调用visit函数，visit函数必须有3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有文件名，args则为walk的第三个参数
os.path.supports_unicode_filenames	#设置是否支持unicode路径名

from pathlib import Path
p.cwd() # 获取当前路径
p.stat()  # 获取当前文件的信息
p.exists()  # 判断当前路径是否是文件或者文件夹
p.glob(filename)  # 获取路径下的所有符合filename的文件，返回一个generator
p.rglob(filename)  # 与上面类似，只不过是返回路径中所有子文件夹的符合filename的文件
p.is_dir()  # 判断该路径是否是文件夹
p.is_file()  # 判断该路径是否是文件
p.iterdir()  #当path为文件夹时，通过yield产生path文件夹下的所有文件、文件夹路径的迭代器
P.mkdir(parents=Fasle)  # 根据路径创建文件夹,parents=True时，会依次创建路径中间缺少的文件夹
p_news = p/'new_dirs/new_dir'
p_news.mkdir(parents=True)
P.open(mode=’r’, buffering=-1, encoding=None, errors=None, newline=None)  #类似于open()函数
p.rename(target)  # 当target是string时，重命名文件或文件夹;当target是Path时，重命名并移动文件或文件夹
p.replace(target)  # 重命名当前文件或文件夹，如果target所指示的文件或文件夹已存在，则覆盖原文件
p.parent(),p.parents()  # parent获取path的上级路径，parents获取path的所有上级路径
p.is_absolute()  # 判断path是否是绝对路径
p.match(pattern)  # 判断path是否满足pattern
p.rmdir()  # 当path为空文件夹的时候，删除该文件夹
p.name  # 获取path文件名
p.suffix  # 获取path文件后缀
```

## 正则表达式

正则解析，[图](https://pic3.zhimg.com/80/v2-6be63a41e531f003f2931160fdadaffa_720w.jpg) 源自[Python正则表达式](https://www.jianshu.com/p/5a34f2bf394a)

![](https://pic3.zhimg.com/80/v2-6be63a41e531f003f2931160fdadaffa_720w.jpg)

Python的**re模块**主要定义了9个常量、12个函数、1个异常
re.compile模式：
- re.I(re.IGNORECASE): 忽略大小写（括号内是完整写法，下同）
- M(MULTILINE): 多行模式，改变'^'和'$'的行为（参见上图）
- S(DOTALL): 点任意匹配模式，改变'.'的行为
- L(LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定
- U(UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性
- X(VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释


前后查找的操作符：
- (?=)	正向前查找
- (?!)	负向前查找
- (?<=)	正向后查找
- (?<!)	负向后查找

正则表达re模块共有12个函数，概览：
- search、match、fullmatch：查找**一个**匹配项
  - search：查找任意位置的匹配项
  - match：必须从字符串开头匹配
  - fullmatch：整个字符串与正则完全匹配
  - 以上三种方法返回match对象，几个常用的方法如下：
    - m.start() 返回匹配到的字符串的起使字符在原始字符串的索引
    - m.end() 返回匹配到的字符串的结尾字符在原始字符串的索引
    - m.group() 返回指定组的匹配结果
    - m.groups() 返回所有组的匹配结果
    - m.span() 以元组形式给出对应组的开始和结束位置
- findall、finditer：查找**多个**匹配项
  - 1）findall： 从字符串任意位置查找，返回一个列表
  - 2）finditer：从字符串任意位置查找，返回一个迭代器，适用大量匹配项
- split： 分割
  - re.split(r"[;:]","var A;B;C:integer;")
- sub，subn：替换
  - re.sub('\d+','*','aaa34bvsa56s',count=1)
  - 与 re.sub函数 功能一致，只不过返回一个元组 (字符串, 替换次数)
  - re.subn('\d','*','aaa34bvsa56s')#每个数字都替换一次
- compile函数、template函数: 将正则表达式的样式编译为一个 正则表达式对象

正则语法总结：[图](https://upload-images.jianshu.io/upload_images/3326314-f7e9014ceb942f11.png)
![](https://upload-images.jianshu.io/upload_images/3326314-f7e9014ceb942f11.png)

代码示例

```python
import re

p = re.compile(r'(\w+) (\w+)(?P<sign>.*)', re.DOTALL)

print ("正则表达式:", p.pattern) # (\w+) (\w+)(?P<sign>.*)
print ("匹配模式:", p.flags) # 48
print ("分组数目:", p.groups) #  3
print ("别名分组:", p.groupindex) # {'sign': 3}

m = re.match(r'(\w+) (\w+)(?P<sign>.*)', 'hello world!')
 
print ("原始字符串:", m.string) # 要匹配的原始字符串
print ("原始正则表达式:", m.re) # 要匹配的原始正则
print ("索引范围: [{}, {}]".format(m.pos, m.endpos)) # [0, 12]
print ("捕获的最后一个分组索引:", m.lastindex) # 3
print ("捕获的最后一个分组别名:", m.lastgroup) # sign
print ("获取多个组:", m.group(1, 2)) # ('hello', 'world')
print ("获取全部组（元组）:", m.groups()) # ('hello', 'world', '!')
print ("获取全部别名组（字典）:", m.groupdict()) # {'sign': '!'}
print ("第2个字符串范围: [{},{}]".format(m.start(2), m.end(2))) # (6, 11)
print ("第2个字符串范围:", m.span(2)) # (6, 11)
print ("局部重排:", m.expand(r'\2 \1\3')) # world hello!

# 槽位字典
pattern_city = re.compile('(?P<city>西安|武汉|青岛|广州|重庆)市?(?P<district>城六|咸阳|高陵|长安)区?',re.X)
pattern_loan = re.compile('(?P<loan>全款|公积金|商业|组合)贷款?')

pattern_info = re.compile('(?P<city>西安|武汉|青岛|广州|重庆)市?(?P<district>城六|咸阳|高陵|长安)区?(?P<loan>全款|公积金|商业|组合)贷款?',re.X)

slot_dict = {'city': '-', 'loan':'-'}

query = '西安长安区商业贷款'
res1 = pattern_info.match(query)
print(res1) # match对象
print(res1.groupdict()) # 返回字典（含别名）
res2 = pattern_info.findall(query) # 返回列表
print(res2)
```

**regex模块**

【2021-8-9】[Python的regex模块——更强大的正则表达式引擎](https://www.cnblogs.com/animalize/p/4949219.html)

内置的re模块不支持一些高级特性，比如下面这几个：
- 固化分组    Atomic grouping
- 占有优先量词    Possessive quantifiers
- 可变长度的逆序环视    Variable-length lookbehind
- 递归匹配    Recursive patterns
- （起始/继续）位置锚\G    Search anchor
2009年，Matthew Barnett写了一个更强大正则表达式引擎——**regex模块**，这是一个Python的第三方模块。
- 安装：pip install regex
除了上面这几个高级特性，还有很多有趣、有用的东西，本文大致介绍一下，很多内容取自regex的文档。

regex基本兼容re模块，现有的程序可以很容易切换到regex模块：import regex as re；

regex有Version 0和Version 1两个工作模式，其中的Version 0基本兼容现有的re模块，以下是区别：

||Version 0  （基本兼容re模块）	|Version 1|
|---|---|---|
|启用方法|默认模式| 设置regex.DEFAULT_VERSION = regex.V1，或者在表达式里写上(?V1)|
|内联flag|内联flag只能作用于整个表达式，不可关闭。|内联flag可以作用于局部表达式，可以关闭。|
|字符组	|只支持简单的字符组。|字符组里可以有嵌套的集合，也可以做集合运算（并集、交集、差集、对称差集）。|
|大小写匹配	| 默认支持普通的Unicode字符大小写，如Й可匹配й。这与Python3里re模块的默认行为相同。|默认支持完整的Unicode字符大小写，如ss可匹配ß。可惜不支持Unicode组合字符与单一字符的大小写匹配，所以感觉这个特性不太实用。可以在表达式里写上(?-f)关闭此特性。|

V1模式默认开启.FULLCASE（完整的忽略大小写匹配）。通常用不上这个，所以在忽略大小写匹配时用(?-f)关闭.FULLCASE即可，这样速度更快一点，例如：(?i-f)tag

Version 0模式和re模块不兼容之处
- \s的范围。
  - 在re中，\s在这一带的范围是0x09 ~ 0x0D，0x1C ~ 0x1E。
  - 在regex中，\s采用的是Unicode 6.3+标准的\p{Whitespace}，在这一带的范围有所缩小，只有：0x09 ~ 0x0D。

- regex有模糊匹配（fuzzy matching）功能，能针对字符进行模糊匹配，提供了3种模糊匹配：
  - i，模糊插入
  - d，模糊删除
  - s，模糊替换
  - 以及e，包括以上三种模糊

```python
import regex as re

# 两次匹配都是把捕获到的内容放到编号为1捕获组中，在某些情况很方便
regex.match(r"(?|(first)|(second))", "first").groups() # ('first',)
regex.match(r"(?|(first)|(second))", "second").groups() # ('second',)

# 局部范围的flag控制。在re模块，flag只能作用于整个表达式，现在可以作用于局部范围；全局范围的flag控制，如 (?si-f)<B>good</B>
# (?i:)是打开忽略大小写，(?-i:)则是关闭忽略大小写。
# 如果有多个flag挨着写既可，如(?is-f:)，减号左边的是打开，减号右边的是关闭。
regex.search(r"<B>(?i:good)</B>", "<B>GOOD</B>") # <regex.Match object; span=(0, 11), match='<B>GOOD</B>'>

# 可重复使用的子句
regex.search(r'(?(DEFINE)(?P<quant>\d+)(?P<item>\w+))(?&quant) (?&item)', '5 elephants') # <regex.Match object; span=(0, 11), match='5 elephants'> ， 此例中，定义之后，(?&quant)表示\d+，(?&item)表示\w+。如果子句很复杂，能省不少事。

# 模糊匹配：匹配hello，其中最多容许有两个字符的错误。
regex.findall('(?:hello){s<=2}', 'hallo')
# ['hallo']

# 部分匹配。可用于验证用户输入，当输入不合法字符时，立刻给出提示。

# 编译好的正则式用pickle存储到文件，直接pickle.load()就不必再次编译，节省时间

```

## 参数处理

Python获取用户参数的[几种方式](https://blog.csdn.net/liuyingying0418/article/details/100126348)：
- input()函数
- sys.argv模块
- argparse模块
- getopt模块

### input函数

python2中input与python3的input不一样, python2中raw_input 与 python3 中的input 比较类似
- raw_input(): python2独有
  - 小括号中放入的是提示信息，用来在获取数据之前给用户的一个简单提示
  - 在从键盘获取了数据以后，会存放到等号右边的变量中
  - 把用户输入的任何值都作为字符串来对待
- input()函数与raw_input()类似，但其接受的输入必须是**表达式**

```python

# python 2
data = input() # 输入23、"hello"(字符串必须有引号，否则报错)
data = input('plase: ')
data = raw_input("hello, please input") # 不限类型
# Python 3
data = input("please enter the data: ")
# 无论输入的是什么，最终data的数据类型都是“str”
print(data)
```

### sys.argv

sys标准库最常用的是sys.argv，用来调用命令行参数，这些命令行参数以链表形式存储于 sys 模块的 argv 变量。一律是**字符串**形式
- sys.argv\[0]表示脚本本身

```python
import sys
# python test.py one two three
print(sys.argv) # [‘test.py’, ‘one’, ‘two’, ‘three’]
print(sys.argv[0]) # 脚本名称
print(os.path.abspath(sys.argv[0])) # 脚本绝对路径

```

### argparse

parser.add_argument 方法的type参数理论上可以是**任何**合法的类型
- 但有些参数传入格式比较麻烦，例如list，所以一般用bool, int, str, float这些基本类型
- 更复杂的需求可以通过str传入，然后手动解析。
- bool类型的解析比较特殊，传入任何值都会被解析成True，传入空值时才为False

```python
import argparse

parser = argparse.ArgumentParser()
parser.description='please enter two parameters a and b ...'
parser.add_argument("-a", "--inputA", help="this is parameter a", dest="argA", type=int, default="0")
parser.add_argument("-b", "--inputB", help="this is parameter b",  type=int, default="1")
args = parser.parse_args()

print("parameter a is :",args.argA)
print("parameter b is :",args.inputB)
```

```shell
python test.py -h # 参数说明
python test.py -a 2 -b 3

```

### tf.app.run

TensorFlow参数处理

tensorflow只提供以下几种方法：4种方法，分别对应str, int,bool,float类型的参数
- tf.app.flags.DEFINE_string
- tf.app.flags.DEFINE_integer
- tf.app.flags.DEFINE_boolean
- tf.app.flags.DEFINE_float 。
这里对bool的解析比较严格，传入1会被解析成True，其余任何值都会被解析成False。

脚本中需要定义一个接收一个参数的main方法：def main(_):，这个传入的参数是脚本名，一般用不到， 所以用下划线接收。
- 以batch_size参数为例，传入这个参数时使用的名称为--batch_size，也就是说，中划线不会像在argparse 中一样被解析成下划线。

tf.app.run()会寻找并执行入口脚本的main方法。也只有在执行了tf.app.run()之后才能从FLAGS中取出参数。
- 从它的签名来看，它也是可以自己指定需要执行的方法的，不一定非得叫main：

```python
import tensorflow as tf

tf.app.flags.DEFINE_string('gpus', None, 'gpus to use')
tf.app.flags.DEFINE_integer('batch_size', 5, 'batch size')

FLAGS = tf.app.flags.FLAGS

def main(_):
    print(FLAGS.gpus)
    print(FLAGS.batch_size)

if __name__=="__main__":
    tf.app.run()
```


### getopt

getopt.getopt(args, shortopts, longopts=[])
- args指的是当前脚本接收的参数，它是一个列表，可以通过sys.argv获得
- shortopts 是短参数，类似-v，-h这样的参数。短参数后面有冒号 “:” 表示该参数有输入值。
- longopts 是长参数，类似–help，–version这样的参数。长参数后面带等号 “=” 表示参数有输入值

输入 -v 的时候打印脚本的版本信息，不执行脚本

通过getopt工具包实现
- [Python实现文件上传下载](https://blog.csdn.net/songling515010475/article/details/106409521)，使用socket

```python
import sys
import socket
import getopt
import time
 
upFileName = ""
 
#服务端涵数
def server_handle(port):
    #创建服务端套接字
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    #绑定IP和端口
    server.bind(('0.0.0.0', port))
    #监听
    server.listen(10)
    print("[*] Listening on 0.0.0.0:%d"%port)
    while True:
        client_socket, addr = server.accept()
        download_file(client_socket)
#客户端涵数
def client_handle(target, port):
    #创建socket连接
    client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    client.connect((target, port))
    #将字符串文件名转成字节发送,socket套接字是要用byte传输
    client.send(upFileName.encode('utf-8'))
    time.sleep(1)
    upload_file(client)
    #传输完文件后关闭文件流
    client.close()
 
#文件下载涵数
def download_file(socket):
    #读取socket传过来的文件名数据
    fileName = socket.recv(1024)
 
    #因为socket传过来的是字节码,所以这里需要转成字符串
    fileName = fileName.decode()
    print("[*]Receive the file:%s"%fileName)
 
    #定义一个byte型的变量
    fileBuffer = "".encode('utf-8')
 
    #循环从socket中读取数据
    while True:
        #一次读取1024个字节
        data = socket.recv(1024)
        if data:
            #读取的数据累加保存在变量中
            fileBuffer += data
        else:
            #如果读到没有数据了就跳出结束
            break;
 
    #以写字节的形式打开一个文件
    f = open("_"+fileName, 'wb')
    #写文件
    f.write(fileBuffer)
    #关闭打开的文件
    f.close()
 
#文件上传涵数
def upload_file(socket):
    #以读byte字节的形式打开文件
    f = open(upFileName, 'rb')
 
    #读取文件
    data = f.read()
 
    #关闭打开文件
    f.close()
 
    #发送文件数据
    socket.send(data)
 
#定义usage涵数（命令行提示信息）
def usage():
    print("help info: python upload.py -h")
    print("client: python upload.py -t [target] -p [port] -u [uploadfile]")
    print("server: python filename.py -lp [port]")
    sys.exit()
 
def main():
    global upFileName   #文件名
    target = ""     #目标IP
    port = 0        #目标端口
    help = False    #显示帮助信息
    listen = False  #是否监听
 
    #利用getopt模块获取命令行参数
    opts, args = getopt.getopt(sys.argv[1:], "t:p:u:hl")
    for o, a in opts:
        if o == "-t":
            target = a;
        elif o == "-p":
            port = int(a)
        elif o == "-u":
            upFileName = a
        elif o == "-h":
            help = True
        elif o == "-l":
            listen = True
        else:
            #断言，传入的参数有误
            assert False, "Unhandled Option"
    #打印帮助信息
    if help:
        usage()
 
    #区分客户端和服务端
    if listen:
        server_handle(port)
    else:
        client_handle(target, port)
 
if __name__ == "__main__":
    main()
```


### 环境变量

环境变量已经存在系统中，python脚本中直接通过 os.getenv('ENV_NAME') 就能拿到指定的环境变量。
- os.environ模块获取有关系统的各种信息
- [os.environ模块环境变量详解](https://blog.csdn.net/happyjacob/article/details/109279118)

```python
# demo.py
import os

VAR1 = os.getenv('VAR1')
VAR2 = os.getenv('VAR2')

print(f"var1:{VAR1}")
print(f"var2:{VAR2}")

# os.environ 是环境变量的字典，但类型并不是 <class ‘dict’>，不是所有字典的函数都能用
os.environ.keys() # 主目录下所有的 key
# 常见变量——win
os.environ['HOMEPATH']:当前用户主目录。
os.environ['TEMP']:临时目录路径。
os.environ["PATHEXT"]:可执行文件。
os.environ['SYSTEMROOT']:系统主目录。
os.environ['LOGONSERVER']:机器名。
os.environ['PROMPT']:设置提示符。
# 常见变量——linux
os.environ['USER']:当前使用用户。
os.environ['LC_COLLATE']:路径扩展的结果排序时的字母顺序。
os.environ['SHELL']:使用shell的类型。
os.environ['LAN']:使用的语言。
os.environ['SSH_AUTH_SOCK']:ssh的执行路径。

# 设置环境变量
os.environ['环境变量名称']='环境变量值' #其中key和value均为string类型
os.putenv('环境变量名称', '环境变量值')
os.environ.setdefault('环境变量名称', '环境变量值')
# 修改
os.environ['环境变量名称']='新环境变量值'
# 获取
os.environ['环境变量名称']
os.getenv('环境变量名称')
os.environ.get('环境变量名称', '默认值')	#默认值可给可不给，环境变量不存在返回默认值
print(os.environ.get("HOME"))
print(os.environ.get("HOME", "default"))	#环境变量HOME不存在，返回	default
# 删除
del os.environ['环境变量名称']
del(os.environ['环境变量名称'])
# 判断是否存在
'环境变量值' in os.environ   # 存在返回 True，不存在返回 False


```

除此以外，还可以在 python 运行时指定环境变量。

```shell
# 临时环境变量
VAR1="test" VAR2=12 python demo.py
```

脚本可以拿到环境变量，但是在系统中用 env 命令是查不到的。export 是临时环境变量，只在当前 shell 有效。而上面这种设置环境变量的方式只对当前脚本有效。


## 类型提示

Python的主要卖点之一就是它是动态类型的，这一点也不会改变。而在2014年9月，Guido van Rossum (Python BDFL) 创建了一个Python增强提议(PEP-484)，为Python添加**类型提示**（Type Hints）。并在一年后，于2015年9月作为Python3.5.0的一部分发布了。于是对于存在了二十五年的Python，有了一种标准方法向代码中添加类型信息
- 仅仅作用提示作用：输入函数的第一个参数 first_name，输入点号（.）然后敲下 Ctrl+Space 来触发代码补全

```python
def test(a: str) -> str:
    print(a)
    return 3

def document_frequency(term: str, corpus: str) -> tuple[int, int]:
    """
    Calculate the number of documents in a corpus that contain a
    given term
    @params : term, the term to search each document for, and corpus, a collection of
             documents. Each document should be separated by a newline.
    @returns : the number of documents in the corpus that contain the term you are
               searching for and the number of documents in the corpus
    @examples :
    >>> document_frequency("first", "This is the first document in the corpus.\\nThIs\
is the second document in the corpus.\\nTHIS is \
the third document in the corpus.")
    (1, 3)
    """
    corpus_without_punctuation = corpus.lower().translate(
        str.maketrans("", "", string.punctuation)
    )  # strip all punctuation and replace it with ''
    docs = corpus_without_punctuation.split("\n")
    term = term.lower()
    return (len([doc for doc in docs if term in doc]), len(docs))

```


## 网络请求

request工具包

### get方法

```python
# -*- coding:utf-8 -*-
import requests
import json

headers = {'user-agent': 'my-app/0.0.1'}
payload = {'key1': 'value1', 'key2': 'value2'}

r = requests.get("http://httpbin.org/get", params=payload)
r = requests.get(url, headers=headers) # header

print(r.url) # 请求网址
print(r.text) # 返回内容
print(r.encoding) # 编码
# http://httpbin.org/get?key2=value2&key1=value1

```

### post方法
- 1、带数据的post
- 2、带header的post
- 3、带json的post
- 4、带参数的post
- 5、普通文件上传
- 6、定制化文件上传
- 7、多文件上传
返回信息：
- ![](https://images2017.cnblogs.com/blog/77835/201709/77835-20170907152822351-1210277893.png)


```python
# -*- coding:utf-8 -*-
import requests
import json
 
host = "http://httpbin.org/"
endpoint = "post"
url = ''.join([host,endpoint])
data = {'key1':'value1','key2':'value2'}
# 带数据的post
r = requests.post(url, data=data)
# 带header的post
headers = {"User-Agent":"test request headers"}
r = requests.post(url, headers=headers)
#response = r.json()
print (r.text)
# 带json的post
data = {
    "sites": [
                { "name":"test" , "url":"www.test.com" },
                { "name":"google" , "url":"www.google.com" },
                { "name":"weibo" , "url":"www.weibo.com" }
    ]
}
r = requests.post(url, json=data)
# 带参数的post
params = {'key1':'params1','key2':'params2'}
# r = requests.post(url)
r = requests.post(url, params=params)
# 文件上传
files = {
            'file':open('test.txt','rb')
        }
r = requests.post(url,files=files)
# 自定义文件名，文件类型、请求头
files = {
        'file':('test.png',open('test.png','rb'),'image/png')
}
r = requests.post(url,files=files)
print (r.text)
# 多文件上传
files = [
    ('file1',('test.txt',open('test.txt', 'rb'))),
    ('file2', ('test.png', open('test.png', 'rb')))
    ]
r = requests.post(url,files=files)
print (r.text)
#流式上传
with open( 'test.txt' ) as f:
    r = requests.post(url,data = f)

```

## yaml

YAML是JSON（源）的超集。每个有效的JSON文件也是一个有效的YAML文件。这意味着您拥有所有期望的类型：整数，浮点数，字符串，布尔值，空值。以及序列和图。

### yaml介绍

- `YAML`是一种直观的能够被电脑识别的的**数据序列化**格式，容易被人类阅读，并且容易和脚本语言交互。`YAML`类似于`XML`，但是语法比XML简单得多，对于转化成数组或可以hash的数据时是很简单有效的。
  1. **大小写**敏感
  2. 使用**缩进**表示层级关系
  3. 缩进时不允许使用Tab，只允许使用**空格**
  4. 缩进的空格**数目不重要**，只要相同层级的元素左对齐即可
  5. \# 表示注释，从它开始到行尾都被忽略
- 支持的数据类型
  - 字符串，整型，浮点型，布尔型，null，时间，日期
- 主要特性，更多：[Python YAML用法详解](https://blog.csdn.net/lmj19851117/article/details/78843486)
  - & 锚点 和 * 引用
  - 强制转换，用!!实现
  - 同一个yaml文件中，可以用 --- 来分段
  - 构造器(constructors)、表示器(representers)、解析器(resolvers )
  - 包含子文件：!include
- 安装
  - pip install pyyaml

### yaml示例

- 【2021-4-6】[大多数程序员都不知道的6个YAML功能](https://www.toutiao.com/i6934590069487518212/)
- config.yaml内容：

```yaml
name: Tom Smith
name: 'Tom Smith' # str等效表达
# 长字符串(换行符非必须,仅为了好看) , > 
disclaimer: >
    Lorem ipsum dolor sit amet, consectetur adipiscing elit.
    In nec urna pellentesque, imperdiet urna vitae, hendrerit
    odio. Donec porta aliquet laoreet. Sed viverra tempus fringilla.
# 多行字符串, | 相当于行间换行符\n
mail_signature: |
      Martin Thoma
      Tel. +49 123 4567

age: 37
list_by_square_bracets_0: 
  - foo
  - bar
list_by_square_bracets_1: [foo, bar] # list的等效表达

spouse:
    name: Jane Smith
    age: 25
map_by_curly_braces: {foo: bar, bar: baz} # dict的等效表达
children:
 - name: Jimmy Smith
   age: 15
 - name1: Jenny Smith
   age1: 12
# YAML支持11种写布尔值的方法
bool_a : yes # true/True
bool_b : no # false/False
# 三个-表示多文档，返回list，如 [{'foo': 'bar'}, {'fizz': 'buzz'}]
---
# 这个例子输出一个字典，其中value包括所有基本类型
str: "Hello World!"
int: 110
float: 3.141
boolean: true  # or false
None: null  # 也可以用 ~ 号来表示 null
time: 2016-09-22t11:43:30.20+08:00  # ISO8601，写法百度
date: 2016-09-22  # 同样ISO8601
name: &name 灰蓝 # 设置被引用字段别名
tester: *name # * 取引用内容(仅含值)
# 成对引用(锚)
localhost: &localhost1
    host: 127.0.0.1
user:
    <<: *localhost1 # <<表示按照K/V形式成对展开，合并键
    db: 8

a: !!str 3.14 # 转字符串
b: !!int "123" # 转int
# 复杂类型
tuple_example: !!python/tuple
  - 1337
  - 42
set_example: !!set {1337, 42}
date_example: !!timestamp 2020-12-31
```

- 操作方法

```python
import yaml

# 文件
f = open(r'config.yml')
# 字符串
f = '''
---
name: James
age: 20
---
name: Lily
age: 19
'''
y = yaml.load(f) 
y = yaml.load_all(f) # 多个yaml区域
for data in y:
    print(data)
# 转成yaml文档
obj1 = {'name': 'Silenthand Olleander',
            'race': 'Human',
            'traits': ['ONE_HAND', 'ONE_EYE']
}
obj2 = {"name": "James", "age": 20}
print(yaml.dump(obj1，))
# 中文输出
import json
print(json.dumps(obj1, ensure_ascii=False, indent=2))
print(yaml.dump(d,default_flow_style=False, indent=2, allow_unicode=True))
f = open(r'out_config.yml','w')
print(yaml.dump(obj2,f))
yaml.dump_all([obj1, obj2], f) # 一次输出多个片区
```

### 高级功能

- 【2021-3-16】文件包含，YAML不包括任何种类的“import”或“include”语句。不过可以通过重写构造器来实现
  - 研究源码（[yaml文件嵌套](https://blog.csdn.net/tanruixing/article/details/88128818)）发现：yaml嵌套还是基于在load中重载一个钩子类，对yaml的value进行解析处理
  - 通过value前缀判定的！注意下面的a:后面要有一个空格。
- 参考：
  - [yaml 锚点*和包含include](http://www.bdata-cap.com/newsinfo/36658.html)
  - [yaml文件嵌套](https://blog.csdn.net/tanruixing/article/details/88128818)
  - [如何在Yaml文件引用其他Yaml文件(使用python Pyyaml)](https://www.cnblogs.com/robynn/p/8253783.html)


```yaml
# === 文件 bar.yaml ====
- 3.6
- [1, 2, 3]

# === 文件 foo.yaml ====
a: 1
b:
    - 1.43
    - 543.55
# 包含别的文件
c: !include bar.yaml
```

- python调用代码

```python
import os
import yaml

class Loader(yaml.Loader):

    def __init__(self, stream):
        self._root = os.path.split(stream.name)[0]
        super(Loader, self).__init__(stream)

    def include(self, node):
        filename = os.path.join(self._root, self.construct_scalar(node))
        with open(filename, 'r') as f:
            return yaml.load(f, Loader)
# 添加新的语法标记
Loader.add_constructor('!include', Loader.include)

def load_yaml(yaml_file):
    """
    :param yaml_file:
    :return:
    """
    with open(yaml_file, 'r') as f:
        config = yaml.load(f, Loader)
    return config

y = load_yaml('foo.yaml')
print(yaml.dump(y))
```
- 简洁版

```python
import yaml
import os

def yaml_include(loader, node):
# Get the path out of the yaml file
	file_name = os.path.join(os.path.dirname(loader.name), node.value)
	with open(file_name) as inputfile:
		return yaml.load(inputfile)

yaml.add_constructor("!include", yaml_include)
stream = open('foo.yaml', 'r')
print(yaml.dump(yaml.load(stream)))
```

- 或者

```python

#!/usr/bin/python
import os.path
import yaml
 
class IncludeLoader(yaml.Loader):
    def __init__(self, *args, **kwargs):
        super(IncludeLoader, self).__init__(*args, **kwargs)
        self.add_constructor('!include', self._include)
        if 'root' in kwargs:
            self.root = kwargs['root']
        elif isinstance(self.stream, file):
            self.root = os.path.dirname(self.stream.name)
        else:
            self.root = os.path.curdir
 
    def _include(self, loader, node):
        oldRoot = self.root
        filename = os.path.join(self.root, loader.construct_scalar(node))
        self.root = os.path.dirname(filename)
        data = yaml.load(open(filename, 'r'))
        self.root = oldRoot
        return data
 
class Config(object):
    def __init__(self, path):
        config_file = open(path, 'r')
        self.config_content = yaml.load(config_file, IncludeLoader)
        config_file.closed
 
    def getConfigContent(self):
        return self.config_content
```




## 打日志

日志级别等级
- CRITICAL > ERROR > WARNING > INFO > DEBUG > NOTSET

### logging

[logging](https://docs.python.org/3/library/logging.html)模块

- [python日志基于时间切分和基于文件大小切分](https://www.jianshu.com/p/5a4e226444bd)
- 代码：

```python
#！coding:utf-8
import logging
import logging.handlers
import datetime, time

#logging    初始化工作
logger = logging.getLogger("zjlogger")
logger.setLevel(logging.DEBUG)

# 添加TimedRotatingFileHandler
# (1) 定义一个1秒换一次log文件的handler, 保留3个旧log文件
rf_handler = logging.handlers.TimedRotatingFileHandler(filename="all.log",when='S',interval=1, backupCount=3)
#handler = logging.handlers.RotatingFileHandler(LOG_FILE, maxBytes=1024 * 1024, backupCount=5, encoding='utf-8')  # 实例化handler

# (2) 写入文件myapp.log，如果文件超过100个Bytes，仅保留5个文件。
handler = logging.handlers.RotatingFileHandler('myapp.log', maxBytes=100, backupCount=5)

rf_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(filename)s[:%(lineno)d] - %(message)s"))

#在控制台打印日志
handler = logging.StreamHandler()
handler.setLevel(logging.DEBUG)
handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

logger.addHandler(rf_handler)
logger.addHandler(handler)

# logging格式化输出
d={"a":1, "c":[3,1,2]}
logger.info("this is %s, %s", d['a'], d)

while True:
    # 不同日志等级
    logger.debug('debug message')
    logger.info('info message')
    logger.warning('warning message')
    logger.error('error message')
    logger.critical('critical message')
    time.sleep(1)
```

### loguru模块

- 【2021-3-30】[不想手动再配置logging？那可以试试loguru](https://blog.csdn.net/BF02jgtRS00XKtCx/article/details/109126972)
- logging库采用模块化设计，虽然可以设置不同的 handler 来进行组合，但是在配置上通常较为繁琐；而且如果不是特别处理，在一些多线程或多进程的场景下使用 logging 还会导致日志记录会出现错乱或是丢失的情况。
- **loguru库**不仅能够减少繁琐的配置过程还能实现和logging类似的功能，同时还能保证日志记录的**线程进程安全**，又能够和 logging 相兼容，并进一步追踪异常也能进行代码回溯。一个专为像我这样懒人而生日志记录库
- logger 本身就是一个已经实例化好的对象，如果没有特殊的配置需求，那么自身就已经带有通用的配置参数；同时它的用法和 logging 库输出日志时的用法一致, 可配置部分相比于 logging 每次要导入特定的handler再设定一些formatter来说是更为「傻瓜化」了
- 日志文件留存、压缩，甚至自动清理。可以通过对 rotation 、compression 和 retention 三个参数进行设定来满足：
rotation 参数能够帮助我们将日志记录以大小、时间等方式进行分割或划分

```python
#!pip install loguru
from loguru import logger

logger.debug("debug message"    ) 
logger.info("info level message 中文信息输出 ") 
logger.warning("warning level message") 
logger.critical("critical level message")

# 可配置
import os
 
logger.add(os.path.expanduser("~/Desktop/testlog.log"))
# 序列化配置：通过 serialize 参数将其转化成序列化的 json 格式，最后将导入类似于 MongoDB、ElasticSearch 这类数 NoSQL 数据库中用作后续的日志分析。
logger.add(os.path.expanduser("~/Desktop/testlog.log"), serialize=True)
# loguru 集成了一个名为 better_exceptions 的库，不仅能够将异常和错误记录，并且还能对异常进行追溯
logger.add(os.path.expanduser("~/Desktop/exception_log.log"), backtrace=True, diagnose=True)
# 与logging兼容
import logging.handlers
file_handler = logging.handlers.RotatingFileHandler(LOG_FILE, encoding="utf-8")
logger.add(file_handler)
# -------------
logger.info("hello, world!")

# 日志自动清理
LOG_DIR = os.path.expanduser("~/Desktop/logs")
LOG_FILE = os.path.join(LOG_DIR, "file_{time}.log")
if os.path.exits(LOG_DIR):
    os.mkdir(LOG_DIR)
# ①自动切分日志，大小、时间等方式进行分割或划分
logger.add(LOG_FILE, rotation = "200KB")
# ②分割文件的数量越来越多，可以进行压缩对日志进行压缩、留存
logger.add(LOG_FILE, rotation = "200KB", compression="zip")
# ③只想保留一段时间内的日志并对超期的日志进行删除；
#   当然对 retention 传入整数时，该参数表示的是所有文件的索引，而非要保留的文件数；只有两个时间最近的日志文件会被保留下来，其他都被直接清理掉了
logger.add(LOG_FILE, rotation="200KB",retention=1)
for n in range(10000):
    logger.info(f"test - {n}")
                                                                                                                       
```

- loguru 还为输出的日志信息带上了不同的颜色样式（schema），使得结果更加美观
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy81bXQwZXd2OU9TM0xNdE5uOUZxeWhScnB1a2lhc1B6WjhxQ0FVUFg3N3JpYlM1ZVFpY3dPTWVObG5vbkFoNDlGMVlKcmE0cmpuQjNvTTFoYUJpYTNwNXlNY0EvNjQw?x-oss-process=image/format,png)

## Python版本转换

- 【2020-8-24】Python代码版本转换

```shell
2to3 -help # 帮助
2to3 -w .　　#将当前整个文件夹代码从python2转到python3
# python2文件会在.py后面再加上一个后缀.bak，而新生成的python3文件使用之前python2文件的命名

```

### virtualenv

- 【2018-1-3】[Python--Virtualenv简明教程](http://python.jobbole.com/85398/)，[virtualenv官方文档](http://virtualenv.readthedocs.org/en/latest/virtualenv.html)
- python沙盒环境，virtualenv创建一个拥有自己安装目录的环境, 这个环境不与其他虚拟环境共享库, 能够方便的管理python版本和管理python库
- （1）安装：

```shell
pip install virtualenv
#或者由于权限问题使用sudo临时提升权限
sudo pip install virtualenv
virtualenv -h #获得帮助
```
- （2）创建：
    - 用virtualenv管理python环境
    - virtualenv ENV  # 创建一个名为ENV的目录, 并且安装了ENV/bin/python
    - 生成ENV目录，包含bin（解释器）、include和lib（python库）文件夹
    - 运行 virtualenv --system-site-packages ENV, 会继承/usr/lib/python2.7/site-packages下的所有库, 最新版本virtualenv把把访问全局site-packages作为默认行为
- （3）激活虚拟环境：

```shell
cd ENV
source ./bin/activate  #激活当前virtualenv
(ENV)➜  ENV git:(master) ✗ #注意终端发生了变化
```

【2020-5-14】注意：windows下没有bin目录，参考，执行方法：.\scripts\activate.bat

- （4）关闭
    - deactivate
- （5）指定python版本
    - 可以使用-p PYTHON_EXE选项在创建虚拟环境的时候指定python版本

```shell
#创建python2.7虚拟环境
➜  Test git:(master) ✗ virtualenv -p /usr/bin/python2.7 ENV2.7
virtualenv -p "C:\Program Files (x86)\Python\Python27" py2
```


## Python依赖包

- 【2020-8-23】python项目依赖包管理
- 安装：
   - pip install -r requirements.txt
- 自动生成requirements.txt
   - pip install pipreqs 
   - pipreqs /path/to/project
- 生成requirements.txt文件

```shell
pip freeze  #显示所有依赖
pip freeze > requirement.txt  #生成requirement.txt文件
pip install -r requirement.txt  #根据requirement.txt生成相同的环境
```

- 对比分析

|工具包|优点|缺点|
|---|---|---|
|pip freeze|包含列表完全|不相关的依赖包也会包含进来|
|pipreqs|只会包含项目 imports 的包|包含列表不是很完全|
|pip-compile|精准控制项目依赖包|需要手动操作，不方便|

## 转可执行包

给别人写了个python文件，功能实现了，但怎么交付呢？

两种方案：
- 直接给python文件，然后让对方自行安装python。
- 把python文件和python环境一起给对方，直接点点点即可。

【2021-11-23】pyinstaller 可以把python文件直接打包成可执行文件，符合需求。

```shell
# pip安装
pip install pyinstaller
pip install pyinstaller --trusted-host https://pypi.org --trusted-host https://files.pythonhosted.org

# 或源码安装
git clone https://github.com/dkw72n/pyinstaller.git
python setup.py install
```

pyinstaller用法：
* -F	指定打包后只生成一个exe格式的文件
* -D	–onedir 创建一个目录，包含exe文件，但会依赖很多文件（默认选项）
* -c	–console, –nowindowed 使用**控制台**，无界面(默认)
* -w	–windowed, –noconsole 使用**窗口**，无控制台
* -p	添加搜索路径，让其找到对应的库。
* -i	改变生成程序的icon**图标**


```shell
# 打包
pyinstaller -F demo.py 
pyinstaller.py -F -p C:\python27; ..\demo.py  # 注意当前目录是我在下一级目录里
pyinstaller.py -F -p C:\python27; -i ..\a.ico ..\demo.py # icon图标

```

# 高级语法

Python三器：`装饰器`、`迭代器`和`生成器`

## 装饰器

- 【2021-4-26】[不懂Python装饰器，你敢说会Python?](http://www.toutiao.com/i6954182546359910924)

- 场景：多个函数中添加计时代码
- 解法：装饰器

### 定义

把原来的函数给包了起来，在不改变原函数代码的情况下，在外面起到了装饰作用，这就是传说中的装饰器。它其实就是个普通的函数。

### 示例

```python
import time

# （1）不带参数装饰器
def timer(func):
 '''统计函数运行时间的装饰器'''
 def wrapper():
  start = time.time()
  func()
  end = time.time()
  used = end - start
  print(f'{func.__name__} used {used}')
 return wrapper

# 先调用timer函数，生成一个包装了step1的新的函数timed_step1.
# 剩下的就是调用这个新的函数time_step1()，它会帮我们记录时间。
timed_step1 = timer(step1)
timed_step1()
# 简洁版
timer(step1)()

# （2）带参数的装饰器
#   wrapper使用了通配符，*args代表所有的位置参数，**kwargs代表所有的关键词参数。这样就可以应对任何参数情况。
#   wrapper调用被装饰的函数的时候，只要原封不动的把参数再传递进去就可以
def timer(func):
 '''统计函数运行时间的装饰器'''
 def wrapper(*args, **kwargs):
  start = time.time()
  func(*args, **kwargs)
  end = time.time()
  used = end - start
  print(f'{func.__name__} used {used}')
 return wrapper

# @符号，语法糖衣
@timer
def step1(num):
 print(f'我走了#{num}步')

step1(5)

# （3）带返回值的装饰器
def timer(func):
 '''统计函数运行时间的装饰器'''
 def wrapper(*args, **kwargs):
  start = time.time()
  ret_value = func(*args, **kwargs)
  end = time.time()
  used = end - start
  print(f'{func.__name__} used {used}')
  return ret_value
 return wrapper

@timer
def add(num1, num2):
 return num1 + num2

sum = add(5, 8)
print(sum)
```



# python技能


## uuid生成

- [python生成并处理uuid的方法](https://blog.csdn.net/yl416306434/article/details/80569688)

- uuid是128位的全局唯一标识符（univeral unique identifier），通常用32位的一个字符串的形式来表现。有时也称guid(global unique identifier)。python中自带了uuid模块来进行uuid的生成和管理工作。（具体从哪个版本开始有的不清楚。。）
- python中的uuid模块基于信息如MAC地址、时间戳、命名空间、随机数、伪随机数来uuid。具体方法有如下几个：　　
   - uuid.uuid1()　　基于MAC地址，时间戳，随机数来生成唯一的uuid，可以保证全球范围内的唯一性。
   - uuid.uuid2()　　算法与uuid1相同，不同的是把时间戳的前4位置换为POSIX的UID。不过需要注意的是python中没有基于DCE的算法，所以python的uuid模块中没有uuid2这个方法。
   - uuid.uuid3(namespace,name)　　通过计算一个命名空间和名字的md5散列值来给出一个uuid，所以可以保证命名空间中的不同名字具有不同的uuid，但是相同的名字就是相同的uuid了。【感谢评论区大佬指出】namespace并不是一个自己手动指定的字符串或其他量，而是在uuid模块中本身给出的一些值。比如uuid.NAMESPACE_DNS，uuid.NAMESPACE_OID，uuid.NAMESPACE_OID这些值。这些值本身也是UUID对象，根据一定的规则计算得出。
   - uuid.uuid4()　　通过伪随机数得到uuid，是有一定概率重复的
   - uuid.uuid5(namespace,name)　　和uuid3基本相同，只不过采用的散列算法是sha1

一般而言，在对uuid的需求不是很复杂的时候，uuid1方法就已经够用了

```python
import uuid

name = 'test_name'
# namespace = 'test_namespace'
namespace = uuid.NAMESPACE_URL

print uuid.uuid1()
print uuid.uuid3(namespace,name)
print uuid.uuid4()
print uuid.uuid5(namespace,name)
```

## 性能优化

- 【2020-9-10】[Python语言优化](https://www.cnblogs.com/pypypy/p/11995237.html)
- 原生的python通常都是由cpython实现，而cpython的运行效率，确实让人不敢恭维，比较好的解决方案有cython、numba、pypy等等

### cython

![](https://yqfile.alicdn.com/d0a10d313a638bc6a18eb6ef4b1632920a2b133a.png)


### numba

![](https://yqfile.alicdn.com/94af3cf79a6a076262e647cf491247928939ff79.jpeg)

### pypy

![](https://yqfile.alicdn.com/ae64deb6d0ce804914e023290429be7812e62a16.jpeg)

## 异步

- Python语言没有真正的进程，而是通过协程来实现，多线程也受制于GIL
  - Python因为有GIL（全局解释锁）这玩意，不可能有真正的多线程的存在，因此很多情况下都会用multiprocessing实现并发，而且在Python中应用多线程还要注意关键地方的同步，不太方便，用**协程**代替**多线程**和**多进程**是一个很好的选择，因为它吸引人的特性：主动调用/退出，状态保存，避免cpu上下文切换等…
- 参考  
  - [从0到1，Python异步编程的演进之路](https://zhuanlan.zhihu.com/p/25228075)

多线程

```python
mutex = threading.Lock() #创建锁
mutex.acquire([timeout]) #锁定
# 锁定方法acquire可以有一个超时时间的可选参数timeout。如果设定了timeout，则在超时后通过返回值可以判断是否得到了锁，从而可以进行一些其他的处理。
mutex.release() #释放
```

完整示例

```python
#!/usr/bin/env python
#coding=utf-8
import threading
import time
 
class MyThread(threading.Thread):
    def run(self):
        global num
        time.sleep(1)
 
        if mutex.acquire(1): 
            num = num+1
            msg = self.name+' set num to '+str(num)
            print msg
            mutex.release()
num = 0
mutex = threading.Lock()
def test():
    for i in range(5):
        t = MyThread()
        t.start()
if __name__ == '__main__':
    test()
```

输出：
- Thread-1 set num to 1
- Thread-3 set num to 2
- Thread-4 set num to 3
- Thread-5 set num to 4
- Thread-2 set num to 5


```python
import threading
import time

lock = threading.Lock() #创建锁

def fun(data):
    try:
        lock.acquire(True) #锁定
        print("------> fun 1:",time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())),data)
        time.sleep(5)
        print("------> fun 2:", time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())),data)
    finally:
        lock.release()#释放

threading.Thread(target = fun, name='socket_tcp_server', kwargs={'data':100}).start()
threading.Thread(target = fun, name='socket_tcp_server', kwargs={'data':200}).start()
threading.Thread(target = fun, name='socket_tcp_server', kwargs={'data':300}).start()
threading.Thread(target = fun, name='socket_tcp_server', kwargs={'data':400}).start()
```


### 协程

- 协程，又称作Coroutine。从字面上来理解，即协同运行的例程，它是比是线程（thread）更细量级的用户态线程
  - 特点是允许用户的主动调用和主动退出，挂起当前的例程然后返回值或去执行其他任务，接着返回原来停下的点继续执行。
- 问题
  - 函数都是线性执行的，怎么会说执行到一半返回，等会儿又跑到原来的地方继续执行
  - 答案是用yield语句
    - yield能把一个函数变成一个generator，与return不同，yield在函数中返回值时会保存函数的状态，使下一次调用函数时会从上一次的状态继续执行，即从yield的下一条语句开始执行
    - 好处：数列较大时，可以一边循环一边计算的机制，节省了存储空间，提高了运行效率
  - 操作系统具有getcontext和swapcontext这些特性，通过系统调用，我们可以把上下文和状态保存起来，切换到其他的上下文，这些特性为coroutine的实现提供了底层的基础。操作系统的Interrupts和Traps机制则为这种实现提供了可能性
  - ![](https://pic2.zhimg.com/80/v2-a4989f7971c96d897c94b9d956ee743d_720w.png)

代码

```python
def fib(max):
    n, a, b = 0, 0, 1
    while n  max:
        # 每次调用函数时，都要耗费大量时间循环做重复的事情
        # print b
        # 用yield，则会生成一个generator，需要时，调用它的next方法获得下一个值
        yield b
        a, b = b, a + b
        n = n + 1
```
用协程实现生产者-消费者模式

```python
#-*- coding:utf-8
def consumer():
    status = True
    while True:
        n = yield status
        print("我拿到了{}!".format(n))
        if n == 3:
            status = False

def producer(consumer):
    n = 5
    while n > 0:
    # yield给主程序返回消费者的状态
        yield consumer.send(n)
        n -= 1

if __name__ == '__main__':
    # 由于yield，不同于一般函数执行，Python会当做一个generator对象
    c = consumer() 
    # 将consumer（即变量c，它是一个generator）中的语句推进到第一个yield语句出现的位置
    #    函数里的status = True和while True:都已经被执行了，程序停留在n = yield status的位置（未执行）
    c.send(None) # 如果漏写这一句，那程序直接报错
    # 定义了producer的生成器，注意的是这里我们传入了消费者的生成器，来让producer跟consumer通信。
    p = producer(c)
    # 循环地运行producer和获取它yield回来的状态
    for status in p:
        if status == False:
            print("我只要3,4,5就行啦")
            break
    print("程序结束")
```
- 让生产者发送1,2,3,4,5给消费者，消费者接受数字，返回状态给生产者，而我们的消费者只需要3,4,5就行了，当数字等于3时，会返回一个错误的状态。最终我们需要由主程序来监控生产者－消费者的过程状态，调度结束程序。
- 生产者p调用了消费者c的send()方法，把n发送给consumer（即c），在consumer中的n = yield status，n拿到的是消费者发送的数字，同时，consumer用yield的方式把状态（status）返回给消费者，注意：这时producer（即消费者）的consumer.send()调用返回的就是consumer中yield的status！消费者马上将status返回给调度它的主程序，主程序获取状态，判断是否错误，若错误，则终止循环，结束程序。上面看起来有点绕，其实这里面generator.send(n)的作用是：把n发送generator(生成器)中yield的赋值语句中，同时返回generator中yield的变量（结果）。
- 结果

```
我拿到了5!
我拿到了4!
我拿到了3!
我只要3,4,5就行啦
程序结束
```

- Coroutine与Generator
- 相似：
  - 都是不用return来实现重复调用的函数/对象，都用到了yield(中断/恢复)的方式来实现。
- 区别
  - generator总是生成值，一般是迭代的序列
  - coroutine关注的是消耗值，是数据(data)的消费者
  - coroutine不会与迭代操作关联，而generator会
  - coroutine强调协同控制程序流，generator强调保存状态和产生数据
- **协程**相比于**多进程**和**多线程**的优点
  - ①多进程和多线程创建开销大
  - ②一个难以根治的缺陷，处理进程之间或线程之间的协作问题，因为是依赖多进程和多线程的程序在不加锁的情况下通常是不可控的，而协程则可以完美地解决协作问题，由用户来决定协程之间的调度。

### asyncio

- asyncio是python 3.4中新增的模块，它提供了一种机制，使得你可以用协程（coroutines）、IO复用（multiplexing I/O）在单线程环境中编写并发模型。
- 根据官方说明，asyncio模块主要包括了：
  - 具有特定系统实现的事件循环（event loop）;
  - 数据通讯和协议抽象（类似Twisted中的部分);
  - TCP，UDP,SSL，子进程管道，延迟调用和其他;
  - Future类;
  - yield from的支持;
  - 同步的支持;
  - 提供向线程池转移作业的接口;

下面来看下asyncio的一个例子：

```python
import asyncio

async def compute(x, y):
    print("Compute %s + %s ..." % (x, y))
    await asyncio.sleep(1.0)
    return x + y

async def print_sum(x, y):
    result = await compute(x, y)
    print("%s + %s = %s" % (x, y, result))

loop = asyncio.get_event_loop()
loop.run_until_complete(print_sum(1, 2))
loop.close()
```

### 效率进阶之路

- 爬虫效率进阶之路：
  - （1）urllib和urllib2包抓5个页面总共耗时7.6秒
  - （2）requests包6.5秒！虽然比用urllib快了1秒多，但是总体来说，他们基本还是处于同一水平线的，程序并没有快很多，这一点的差距或许是requests对请求做了优化导致的。
  - （3）lxml库→正则，继续提升1s
  - （4）多线程：threading库有效的解决了阻塞等待的问题，足足比之前的程序快了80%！只需要1.4秒就可完成电影列表的抓取。
    - 多线程受限于GIL，能否用多进程提速？
  - （5）多进程：ProcessPoolExecutor库实现多进程
    - ThreadPoolExecutor和ProcessPoolExecutor是Python3.2之后引入的分别对线程池和进程池的一个封装，如果使用Python2.x，需要安装futures这个库才能使用
    - 多进程带来的优点（cpu处理）并没有得到体现，反而创建和调度进程带来的开销要远超出它的正面效应，拖了一把后腿。即便如此，多进程带来的效益相比于之前单进程单线程的模型要好得多。
  - （6）基于协程的网络库，叫做gevent，异步功能，只有1.2秒，果然很快
    - gevent给予了我们一种以同步逻辑来书写异步程序的能力，看monkey.patch_all()这段代码，它是整个程序实现异步的黑科技
    - 但gevent的魔术给他带来了一定的困惑，并非Pythonic的清晰优雅
  - （7）async/await：同步的requests库改成了支持asyncio的aiohttp库，使用3.5的async/await语法（3.5之前用@asyncio.coroutine和yield from代替）写出了协程版本，1.7s
    - 清晰优雅的协程可以说实现异步的最优方案之一
    - 协程的机制使得我们可以用同步的方式写出异步运行的代码。
  - 思考：
    - 更换零件带来的优化小，而且扩展性有限
    - 网络应用通常瓶颈都在IO层面，解决等待读写的问题比提高文本解析速度来的更有性价比！
- 但Python在3.5版本中引入了关于协程的语法糖async和await
  - 用async修饰将普通函数和生成器函数包装成异步函数和异步生成器
  - 通过await调用async修饰的异步函数
  - async 用来声明一个函数为异步函数，异步函数的特点是能在函数执行过程中挂起，去执行其他异步函数，等到挂起条件（假设挂起条件是sleep(5)）消失后，也就是5秒到了再回来执行。
  - await 用来用来声明程序挂起，比如异步程序执行到某一步时需要等待的时间很长，就将此挂起，去执行其他的异步程序。
- 参考
  - [Python Async/Await入门指南](https://zhuanlan.zhihu.com/p/27258289)

```python
# 异步函数（协程）
async def async_function():
    return 1
# 异步生成器
async def async_generator():
    yield 1
# 通过类型判断可以验证函数的类型
import types
print(type(function) is types.FunctionType)
print(type(generator()) is types.GeneratorType)
print(type(async_function()) is types.CoroutineType)
print(type(async_generator()) is types.AsyncGeneratorType)

# 直接调用异步函数不会返回结果，而是返回一个coroutine对象：
print(async_function())
## <coroutine object async_function at 0x102ff67d8>

# 协程需要通过其他方式来驱动，因此可以使用这个协程对象的send方法给协程发送一个值：
print(async_function().send(None))
# 改进：捕获协程的真正返回值，新建run函数驱动协程
def run(coroutine):
    try:
        coroutine.send(None)
    except StopIteration as e:
        return e.value
# 在协程函数中，可以通过await语法来挂起自身的协程，并等待另一个协程完成直到返回结果：
async def async_function():
    return 1

async def await_coroutine():
    result = await async_function()
    print(result)
    
run(await_coroutine())
# 1


```


## 任务调度

### 定期调度 —— Schedule

[简单强大的Python库！Schedule—实用的周期任务调度工具](https://www.toutiao.com/i7056953729911620104/)

在Linux服务器上周期性地执行某个 Python 脚本

（1）最出名的选择应该是 Crontab 脚本，但是 Crontab 具有以下缺点：
1. 不方便执行秒级的任务。
2. 当需要执行的定时任务有上百个的时候，Crontab的管理就会特别不方便。
（2）Celery，但是 Celery 的配置比较麻烦，如果只是需要一个轻量级的调度工具，Celery 不会是一个好选择。

在你想要使用一个轻量级的任务调度工具，而且希望它尽量简单、容易使用、不需要外部依赖，最好能够容纳 Crontab 的所有基本功能，那么 Schedule 模块是你的不二之选。

```python
# pip install schedule
import schedule
import time

def job:
  print("I'm working...")

# scedule.every(时间数).时间类型.do(job)
# 执行一次
schedule.every.day.at('22:30').do(job)
# 每10分钟执行一次 job 函数
schedule.every(10).minutes.do(job)
# 每十分钟执行任务
schedule.every(10).minutes.do(job)
# 每个小时执行任务
schedule.every.hour.do(job)
# 每天的10:30执行任务
schedule.every.day.at("10:30").do(job)
# 每个月执行任务
schedule.every.monday.do(job)
# 每个星期三的13:15分执行任务
schedule.every.wednesday.at("13:15").do(job)
# 每分钟的第17秒执行任务
schedule.every.minute.at(":17").do(job)
# do 将额外的参数传递给job函数
schedule.every(2).seconds.do(greet, name='Alice')

while True:
  schedule.run_pending
  time.sleep(1)
```


### 多进程任务调度框架

- 【2021-1-21】多年前写的多任务调度框架，每天处理20T上网数据

```python
# ***************************************************************************
# *
# * Copyright (c) 2012 Baidu.com, Inc. All Rights Reserved
# *
# **************************************************************************/
  
#/**
# * @file start.py
# * @author wangqiwen@baidu.com(zhanglun@baidu.com)
# * @date 2013/04/26 16:32
# * detect if data is ready
# * process data use codes defined in conf
# * output data to path in conf
# * multi thread , multi job commit
# * log is added
# **/
 
#import packages:
import ConfigParser
import string
import os
import sys
import threading
import time
import datetime
import logging
import urllib, re
import commands
import json
 
sys.path.append('.')
 
from optparse import OptionParser
 
#define class:
#job spec conf
class JobSpecConf:
    def __init__(self):
        self.job_name = None
        self.input_ready = []
        self.inputs = []
        self.must_input = []
        self.code_path = None
        self.detect_start_time = 0
        self.detect_end_time = 0
        self.delay_before_start = 0
        self.output_ready = None
        self.map_con_num = 0
        self.reduce_num = 0
 
#load jon conf
def loadJobConf(conf_file,date):
    config = ConfigParser.ConfigParser()
    config.read(conf_file)
    global_conf.map_dict['$date'] = date
    global_conf.map_dict['$date_pre'] = getPreDate(date=date)
    # tranform job conf info
    job_conf_list = []
    try:
        for section in config.sections():
            # all job session name starts with 'job' in configre file
            if not section.startswith('job'):
                continue
            # new job conf object
            job_spec_conf = JobSpecConf()
            job_spec_conf.job_name = config.get(section,"job_name")
            # update job_name in map_dict
            global_conf.map_dict['$job_name'] = job_spec_conf.job_name
            # get input path & ready
            item_list = config.options(section)
            path_list = [multiReplace(config.get(section,i),global_conf.map_dict) for i in item_list if i.startswith('input_path_')]
            ready_list = [multiReplace(config.get(section,i),global_conf.map_dict) for i in item_list if i.startswith('input_ready_')]
            job_spec_conf.input_number = len(path_list)
            if len(path_list) != len(ready_list):
                logger.error("configure file(%s) error: input path & ready in section %s doesn't match !" %(conf_file,section))
                return job_conf_list
            job_spec_conf.inputs = path_list
            job_spec_conf.input_ready = ready_list
            if 'must_input' in item_list:
                job_spec_conf.must_input = [multiReplace(config.get(section,'input_ready_%s'%(i)),global_conf.map_dict) for i in config.get(section,"must_input").split('&')]
                logger.info('[%s] must_input = %s'%(job_spec_conf.job_name,repr(job_spec_conf.must_input)))
            # get other info
            job_spec_conf.output = multiReplace(config.get(section,"output"),global_conf.map_dict)
            job_spec_conf.output_ready = multiReplace(config.get(section,"output_ready"),global_conf.map_dict)
            job_spec_conf.code_path = multiReplace(config.get(section,"code_path"),global_conf.map_dict)
            job_spec_conf.detect_start_time = config.get(section,"detect_start_time")
            job_spec_conf.detect_end_time = config.get(section,"detect_end_time")
            job_spec_conf.delay_before_start = config.getint(section,"delay_before_start")
            job_spec_conf.map_con_num = config.get(section,"map_con_num")
            job_spec_conf.reduce_num = config.get(section,"reduce_num")
            job_conf_list.append(job_spec_conf)
        logger.info("job conf info: %s" %(repr(job_conf_list)))
    except Exception,err:
        logger.error("error:(%s) when loading configure file(file:%s,section:%s)" %(err,conf_file,section))
    return job_conf_list
 
def multiReplace(str,dict):
    rx = re.compile('|'.join(map(re.escape,dict)))
    def one_xlat(match):
        return dict[match.group(0)]
    return rx.sub(one_xlat,str)
  
 
#init logger
def initlog(date,job_type):
    logger = logging.getLogger('%s.py' % job_type)
    hdlr = logging.FileHandler('../log/%s/%s_%s.txt' % (now,job_type,date),mode="wb")
    formatter = logging.Formatter('[%(levelname)s] [%(asctime)s]: %(message)s')
    hdlr.setFormatter(formatter)
    logger.addHandler(hdlr)
    logger.setLevel(logging.DEBUG)
    return logger
 
def send_mail(mail_alarm='on',title='mail title',content='mail content',receiver=None):
    """
        usage: send_email(title,content,receiver)
        shell: echo -e "hello" | mail -s "title" receivers
    """
    if mail_alarm != 'on':
        logger.info('alarm mail is off ...')
        return 0
    if receiver == None:
        logger.info('Mail receiver address (%s) invalid !' %(receiver))
        exit(-1)
    code = os.system("echo -e \"%s\" | mail -s \"%s\" \"%s\"" %(content,title,receiver))
    if 0 == code:
        logger.info('Success to send mail (%s:%s) to %s' %(title,content,receiver))
        return 0
    else:  
        logger.error('Fail to send mail (%s:%s) to %s, error code (%s) ,program exit ...' %(title,content,receiver,code))
        exit(-1)
 
def get_jobtracker_running_job_name_ids(url):
    while True:
        try:
            lines = urllib.urlopen(url).readlines()
        except:
            raise
            return False
        if lines:
            break
        else:
            logger.error("%s not reachable" % url)
     
    found = False
    jobs = {}
    for line in lines:
        line = line.strip()
        if found == True:
            if line.startswith('<h2'):
                break
            o = re.search('(job_[0-9]+_[0-9]+).+id="name_[0-9]+">([^<]+)<', line)
            if o:
                name, jid = o.groups()
                jobs[name] = jid
        if line == """<h2 id="running_jobs">Running Jobs</h2>""":
            found = True
    return jobs
 
#define class:
#global conf
class GlobalConf:
    def __init__(self):
        self.retry_interval = 0
        self.output_path = ''
        self.root_code_path = ''
        self.hadoop_client = ''
        self.re_run_number = 0
        self.jobtracker = ''
        self.map_dict = {'$output_path':'-','$date_pre':'-','$date':'-','$job_name':'-'}
        self.mail_receiver_in = None
        self.mail_alarm = 'on'
        self.mail_receiver_out = None
 
#define functions:
#load global config
def globalConfLoad(config_file):
    #load conf
    config = ConfigParser.ConfigParser()
    config.read(config_file)
    #init conf
    global_conf = GlobalConf()
    global_conf.retry_interval = config.getint("global","retry_interval")
    global_conf.output_path = config.get("global","output_path")
    global_conf.map_dict['$output_path'] = global_conf.output_path
    global_conf.root_code_path = config.get("global","root_code_path")
    global_conf.hadoop_client = config.get("global","hadoop_client")
    global_conf.re_run_number = config.getint("global","re_run_number")
    global_conf.jobtracker = config.get("global", "jobtracker")   
    global_conf.mail_receiver_in = config.get("global","mail_receiver_in")
    global_conf.mail_receiver_out = config.get("global","mail_receiver_out")
    global_conf.mail_alarm = config.get("global","mail_alarm")
    return global_conf
 
#test path exist
def checkHadoopFile(path,date,global_conf):
    path_after_parse = multiReplace(path,global_conf.map_dict)
    cmd = '%s fs -test -e %s' % (global_conf.hadoop_client,path_after_parse)
    code, msg = commands.getstatusoutput(cmd)
    if code == 0:
        return True
    elif msg:
        logger.warning('hadoop file (%s) not found , error_id : %s' %(path_after_parse,msg))
        return False
    return False
 
def getPreDate(n = 1 , date = 'today'):
    '''
        get string of date before n days
    '''
    #date_pre = (datetime.datetime.strptime(date,'%Y%m%d')+datetime.timedelta(days=1)).strftime('%Y%m%d')
    if date == 'today':
        date_object = datetime.date.today()
    else:
        date_object = datetime.datetime.strptime(date,'%Y%m%d')
    date_pre = (date_object + datetime.timedelta(days=-n)).strftime('%Y%m%d')
    return date_pre
 
def stopTask(job_spec_conf, date):
    task_prefix = "%s_%s_%s" % (options.pipeline, date, job_spec_conf.job_name)
    found = True
    while found:
        found = False
        running_jobs = get_jobtracker_running_job_name_ids(global_conf.jobtracker)
        for job in running_jobs:
            if job.startswith(task_prefix):
                logger.info("%s: killing job %s " % (job_spec_conf, running_jobs[job]))
                os.system('%s job -kill %s' % (global_conf.hadoop_client, running_jobs[job]))
                found = True
 
def cleanData(job_spec_conf, date, stop = False):
    if stop:
        stopTask(job_spec_conf, date)
    data_path = job_spec_conf.output
    ready_path = job_spec_conf.output_ready
    if 0 == os.system('%s fs -test -e %s' %(global_conf.hadoop_client,ready_path)):
        os.system('%s fs -rmr %s && %s fs -rmr %s' %(global_conf.hadoop_client,ready_path,global_conf.hadoop_client,data_path))
        logger.info("[%s] clean data (%s,%s)" %(job_spec_conf.job_name,data_path,ready_path))
 
def startMultiThead(date, tasks, options):
    logger.info('Begin to run the whole job of day: %s' % date)
    all_job_list = []
    all_job_list = loadJobConf(options.config_file,date)
    all_job_dict = {}
    for job in all_job_list:
        all_job_dict[job.job_name] = job
    logger.info('all jobs in conf : %s' % json.dumps([i.job_name for i in all_job_list]))
    # select some jobs
    if tasks:
        job_conf_list = []
        for jobname in tasks:
            if jobname in all_job_dict:
                job_conf_list.append(all_job_dict[jobname])
            else:
                logger.error('job name (%s) error ! please check with configure file(%s),all job names:%s'%(jobname,options.config_file,repr(all_job_dict.keys())))
                return False
    else:
        job_conf_list = all_job_list
    # check whether each job need to run or not
    job_conf_list = [c for c in job_conf_list if checkTask(c, date, options)]
    logger.info('jobs need to run : %s' % repr([i.job_name for i in job_conf_list]))
    if len(job_conf_list) <= 0:
        logger.info('no job in list , exit ...')
        return False
    # clean old data
    for c in job_conf_list:
        cleanData(c, date, True)
    if options.kill_task:
        return True
    # start multithread
    if options.parallel:
        # run all jobs at the same time
        threads = [threading.Thread(target = tryRunTask, args = (c, date, options)) for c in job_conf_list]
        for t in threads:
            t.start()
        for t in threads:
            t.join()
    else:
        # run one by one
        for c in job_conf_list:
            tryRunTask(c, date, options)
    logger.info('End of day: %s' % date)
    
def runOneTask(job_spec_conf, date, options):
    start_time = datetime.datetime.strptime(getPreDate(n=0)+job_spec_conf.detect_start_time,'%Y%m%d%H:%M')
    end_time = datetime.datetime.strptime(getPreDate(n=0)+job_spec_conf.detect_end_time,'%Y%m%d%H:%M')
    # wait some time until start
    if job_spec_conf.delay_before_start > 0:
        logger.info('[%s] sleep %s mins before start to detect ...'%(job_spec_conf.job_name,job_spec_conf.delay_before_start))
        time.sleep(job_spec_conf.delay_before_start*60)
    # Initialize input path
    input_ready_number = 0
    detect_input_dict = {}
    for i,v in enumerate(job_spec_conf.input_ready):
        detect_input_dict[v] = job_spec_conf.inputs[i]
    input_ready_list = []
    input_path_list = []
    # waiting
    while True:
        now_time = datetime.datetime.now()
        time_info = '[now %s,start %s,end %s]' %(str(now_time),str(start_time),str(end_time))
        #count ready input file
        tmp_key_list = detect_input_dict.keys()
        for tmp_input_ready in tmp_key_list:
            if checkHadoopFile(tmp_input_ready,date,global_conf):
                logger.info('[%s] detect input file (%s): ready ...' % (job_spec_conf.job_name,tmp_input_ready))
                input_ready_list.append(tmp_input_ready)
                input_path_list.append(detect_input_dict[tmp_input_ready])
                del detect_input_dict[tmp_input_ready]
            else:
                logger.warning('[%s] detect input file (%s): not ready... %s' % (job_spec_conf.job_name,tmp_input_ready,time_info))
        input_ready_number = len(input_ready_list)
        logger.info('[%s] detect result : ready num => %d, must input num => %d, all input num => %d...' % (job_spec_conf.job_name,input_ready_number,len(job_spec_conf.must_input),job_spec_conf.input_number))
        # check whether match min input
        match = 0
        if input_ready_number > 0:
            match = 1
        for i in job_spec_conf.must_input:
            if i not in input_ready_list:
                match = 0
                break
        if options.run_force and match :
            logger.warning("[%s] run forcely... input data ready info : %s/%s " %(job_spec_conf.job_name,input_ready_number,job_spec_conf.input_number))
            break
        #too early
        if now_time < start_time:
            logger.info('[%s] time enough , wait until start time ... %s' %(job_spec_conf.job_name,time_info))
            logger.info('[%s] sleep %d minutes (retry_interval)' % (job_spec_conf.job_name,global_conf.retry_interval))
            time.sleep(global_conf.retry_interval*60)
            continue
        #all ready
        if input_ready_number == job_spec_conf.input_number :
            logger.info('[%s] detect_start_time %s , detect_end_time %s , all inputs are ready ...' %(job_spec_conf.job_name,job_spec_conf.detect_start_time,job_spec_conf.detect_end_time))
            break
        # too late
        if options.enable_timeout and now_time >= end_time:
            if match:
                logger.warning('[%s] input ready before time over, ... input data ready info : %s/%s ' %(job_spec_conf.job_name,input_ready_number,job_spec_conf.input_number))
                break
            else:
                logger.warning('[%s] time over , but input files not enough , exit now ... input data ready info : %s/%s ' %(job_spec_conf.job_name,input_ready_number,job_spec_conf.input_number))
                exit(-1)
        logger.info('[%s] sleep %d minutes (retry_interval)' % (job_spec_conf.job_name,global_conf.retry_interval))
        time.sleep(global_conf.retry_interval*60)
             
    # run
    hadoop_job_cmd = 'sh %s%s %s %s %s %s %s %s %s %s %s &>../log/%s/%s_%s.txt' % (
                global_conf.root_code_path,
                job_spec_conf.code_path,
                global_conf.hadoop_client,
                '"%s"' % (';'.join(input_path_list)),
                job_spec_conf.output,
                job_spec_conf.job_name,
                global_conf.root_code_path,
                date,
                "%s_%s_%s" % (options.pipeline, date, job_spec_conf.job_name),
                job_spec_conf.map_con_num,
                job_spec_conf.reduce_num,
                now,
                job_spec_conf.job_name,
                date)
    logger.info('[%s] hadoop job command: %s' % (job_spec_conf.job_name, hadoop_job_cmd))
    code, msg = commands.getstatusoutput(hadoop_job_cmd)
    if code != 0:
        logger.error('[%s]: job Failled when running, error_code = %s(%s)' %(job_spec_conf.job_name,code,msg))
        title = '[merge-wise][ERROR] [%s] Job failed when running !'%(job_spec_conf.job_name)
        content = '[ERROR] [%s] Job failed when running , error_code = %s(%s)'%(job_spec_conf.job_name,code,msg)
        logger.error('mail_receiver_in=%s'%(global_conf.mail_receiver_in))
        send_mail(global_conf.mail_alarm,title,content,global_conf.mail_receiver_in)
        return False
    # result info : all input,ready input,miss input
    result_dict = {'input_list':[],'input_num':0,'ready_list':[],'ready_num':0,'miss_list':[],'miss_num':0}
    for i in job_spec_conf.input_ready:
        if i in input_ready_list:
            result_dict['ready_list'].append(i)
        else:
            result_dict['miss_list'].append(i)
        result_dict['input_list'].append(i)
    result_dict['ready_num'] = len(result_dict['ready_list'])
    result_dict['miss_num'] = len(result_dict['miss_list'])
    result_dict['input_num'] = len(result_dict['input_list'])
    logger.info('[%s] result_dict : %s' %(job_spec_conf.job_name,repr(result_dict)))
     
    # create ready file
    output_ready = job_spec_conf.output_ready
    hadoop_ready_cmd = 'echo %s | %s fs -put - %s' %(json.dumps(result_dict),global_conf.hadoop_client,output_ready)
    logger.info('create ready file : %s' %(hadoop_ready_cmd))
    code, msg = commands.getstatusoutput(hadoop_ready_cmd)
    if code != 0:
        logger.error('[%s] fail to create ready file (%s) , error_code = %s(%s)'%(job_spec_conf.job_name,output_ready,code,msg))
        title = '[merge-wise][ERROR][%s] Failed to create ready file !'%(job_spec_conf.job_name)
        content = '[ERROR] [%s] Failed to create ready file (%s),error_code = %s(%s)'%(job_spec_conf.job_name,output_ready,code,msg)
        send_mail(global_conf.mail_alarm,title,content,global_conf.mail_receiver_in)
        return False
    if result_dict['miss_num'] > 0:
        miss_source_info = ','.join([i.strip().split('/')[-3] for i in result_dict['miss_list']])
        logger.info('[%s] job finished at the end without sources(%s)' %(job_spec_conf.job_name,miss_source_info))
        title = '[merge-wise][WARNING][%s] Job finished at the end without sources(%s)' %(job_spec_conf.job_name,miss_source_info)
        content = '[WARNING][%s] Job finished at the end without sources(%s)\n\nmiss_info = %s\n\nready_info = %s' %(job_spec_conf.job_name,miss_source_info,repr(result_dict['miss_list']),repr(result_dict['ready_list']))
        send_mail(global_conf.mail_alarm,title,content,global_conf.mail_receiver_out)
    if options.signal_zk:
        cmd_out = os.system("%s cr -register  %s -cronID %s" % (global_conf.hadoop_client, job_spec_conf.output, job_spec_conf.job_name))
        if cmd_out != 0:
            title = '[merge-wise][ERROR][%s] Failed to reigster zk data (%s)!'%(job_spec_conf.job_name,job_spec_conf.output)
            content = '[ERROR][%s] Failed to reigster zk data (%s) ! error_code = %s '%(job_spec_conf.job_name, job_spec_conf.output ,str(cmd_out))
            send_mail(global_conf.mail_alarm,title,content,global_conf.mail_receiver_in)
            logger.error('[%s] job Failled, reigster zk data (%s) error, error_code = %s' %(job_spec_conf.job_name, job_spec_conf.output,str(cmd_out)))
            return False
    logger.info('[%s] job finish.' % (job_spec_conf.job_name))
    return True
 
def checkTask(job_spec_conf, date, options):
    # check whether job needs to run or not
    output_ready = job_spec_conf.output_ready
    if options.rerun or options.run_force:
        return True
    #if options.fix_data and checkMissTask(job_spec_conf, date):
    #    return True
    if checkHadoopFile(output_ready, date, global_conf):
        logger.info('check task %s : exist, %s' %(output_ready,job_spec_conf.job_name))
        return False
    else:
        logger.info('check task %s : not exist, %s' %(output_ready,job_spec_conf.job_name))
        return True
 
def tryRunTask(job_spec_conf, date, options):
    logger.info('try to run task %s of %s' % (job_spec_conf.job_name, date))
    for i in range(options.retry):
        if runOneTask(job_spec_conf, date, options):
            return
        if i == (options.retry - 1):
            break
        logger.error('Task %s on %s failed, try again ...' % (job_spec_conf.job_name, date))
        time.sleep(options.retry_sleep)
        cleanData(job_spec_conf, date, False)
    logger.error('Task %s on %s failed ...' % (job_spec_conf.job_name, date))
     
#main define here:
def main():
    global options
    global logger
    global global_conf
 
    usage = "usage: %start.py [options] [tasks]"
    parser = OptionParser(usage=usage)
    parser.add_option("-f", "--disable_timeout",
                      action = "store_false", dest = "enable_timeout", default = True,
                      help = "disable job timeout")
    parser.add_option("-d", "--date", dest = "date", default = getPreDate(), help = "last day for job")
    parser.add_option("-n", "--total_day", type = "int", dest = "total_day", default = 1, help = "total day for job")
    parser.add_option("-s", "--sequence_run", action = "store_false", dest = "parallel", default = True, help = "run task one by one")
    parser.add_option("-x", "--fix_data", action = "store_true", dest = "fix_data", default = False, help = "fix data")
    parser.add_option("-p", "--pipeline", dest = "pipeline", default = "start", help = "pipeline name")
    parser.add_option("-r", "--retry", type = "int", dest = "retry", default = 1, help = "job retry times")
    parser.add_option("-R", "--rerun", action = "store_true", dest = "rerun", default = False, help = "rerun tasks")
    parser.add_option("-w", "--retry_sleep", type = "int", dest = "retry_sleep", default = 300, help = "job retry sleep time, in seconds")
    parser.add_option("-a", "--run_force", action = "store_true", dest = "run_force", default = False, help = "run job no matter the job has run already or data are not all ready")
    parser.add_option("-c", "--config_file", dest = "config_file", default = "conf/job_conf.ini", help = "configure file path")
    parser.add_option("-K", "--kill", action = "store_true", dest = "kill_task", default = False, help = "Kill tasks")
    parser.add_option("-S", "--signal", action = "store_true", dest = "signal_zk", default = False, help = "Signal data reay in zk")
 
    (options, tasks) = parser.parse_args()
    logger = initlog(options.date, options.pipeline)
    global_conf = globalConfLoad(options.config_file)
    logger.info('=================================================')
    logger.info('options=%s tasks=%s' %(repr(options),repr(tasks)))
    #logger.info('options=%s tasks=%s' %(repr(options),repr(tasks)))
    # get previous n days list before date, then start it
    for i in xrange(options.total_day):
        date_i = getPreDate(n=i,date=options.date)
        startMultiThead(date_i, tasks, options)
    logger.info('Finish. Time to quit soon ...')
#main start:
if __name__ == '__main__':
    # call build.sh to update local directory
    os.system('sh build.sh')
    now = getPreDate( n = 0 )
    main()
 
# */* vim: set expandtab ts=4 sw=4 sts=4 tw=400: */
```

- 【2021-1-26】其它调度框架，[Python 实现并发Pipeline](https://zhuanlan.zhihu.com/p/260175181)
- 对于Pipeline 根据侧重点的不同，有两种实现方式
1. 用于加速多线程任务的pipeline
    - 用于加速多线程任务的 Pipeline 主要强调 任务的顺序执行， 转移之间不涉及过于复杂的逻辑。所以 每个pipe 通过自身调用 next pipe。整体上强调 后向连续性。
2. 用于控制流程的pipeline
    - 用于流程控制的piepline， 强调任务的 逻辑性， 由外部 manager 来控制 pipeline 的执行方向。整体上强调前向的依赖性， 使用拓扑排序确定执行顺序。

## 终端文本可视化

### rich

[python之Rich库使用入门](https://blog.csdn.net/qq_43954124/article/details/112772262)
- 打印彩色字体，表单，进度条与状态动画，高级数据类型)

Rich是一个Python库，用于将丰富的文本（带有颜色和样式）写入终端，并用于显示高级内容，例如表格。
使用Rich使您的命令行应用程序更具视觉吸引力，并以更具可读性的方式呈现数据。Rich还可以通过漂亮的打印和语法突出显示数据结构来作为有用的调试辅助工具。

安装：pip install Rich

![](https://pic1.zhimg.com/80/v2-caaf7522240c7c403446cccb6f98d78c_720w.jpg)

进度条

```python
from rich.progress import track
from time import sleep
for step in track(range(100), description="Writing Medium Story..."):
    sleep(0.1)
```    

- <iframe src="https://vdn1.vzuu.com/SD/e1b60454-34a7-11eb-ad71-26236b17892b.mp4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height="600" width="100%"> </iframe>

[一款杀手级的Python工具](https://zhuanlan.zhihu.com/p/326876547)


## 桌面提示

【2022-1-25】[5个方便好用的Python自动化脚本](https://www.toutiao.com/i7056585992664269344)

自动桌面提示
- 这个脚本会自动触发windows桌面通知，提示重要事项，比如说：您已工作两小时，该休息了, 可以设定固定时间提示，比如隔10分钟、1小时等

用到的第三方库：
- win10toast - 用于发送桌面通知的工具

```python
from win10toast import ToastNotifier
import time
toaster = ToastNotifier()

header = input("What You Want Me To Remember\n")
text = input("Releated Message\n")
time_min=float(input("In how many minutes?\n"))

time_min = time_min * 60
print("Setting up reminder..")
time.sleep(2)
print("all set!")
time.sleep(time_min)
toaster.show_toast(f"{header}", f"{text}", duration=10, threaded=True)
while toaster.notification_active(): time.sleep(0.005) 
```

![](https://p26.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/99d1ee7bd4fa4415b4466b7624a6a732?from=pc)


# 面向对象

面向对象三大特点：**封装**、**继承**和**多态**

## 接口实现

接口的特点如下：
- 1、类通过继承接口的方式，来继承接口的抽象方法；
- 2、接口并不是类（虽然编写类和方法的方式很相似）；
- 3、类描述对象的属性和方法（实现接口的类，必须实现接口内所描述的所有方法，否则必须声明为抽象类）；
- 4、接口包含类要实现的方法（接口无法被实例化，但可以被实现）；

总结：接口只定义规范，不负责具体实现（具体实现由具体的实现者完成）

python中也有interface的概念，但是python其本身不提供interface的实现，需要通过第三方扩展库来使用类似interface的功能，一般都是Zope.interface
- Python面向对象编程之Zope.interface安装使用（ @implementer）implements

```python
# coding=utf-8
from zope.interface import Interface
from zope.interface.declarations import implementer
 
# 定义接口
class MyMiss(Interface):
    def imissyouatlost(self,miss):
        """Say i miss you at lost to miss"""
 
@implementer(MyMiss) # 继承接口
class Miss:
    def imissyouatlost(self,somebody):
        """Say i miss you at lost to somebody"""
        return "i miss you at lost, %s!" % somebody
 
if __name__ == '__main__':
    z = Miss()
    hi = z.imissyouatlost('Zy')
    print(hi)

```


# Python生态系统


## Numpy

- 【2020-12-28】[NumPy初学教程，可视化指南](https://www.toutiao.com/i6911204024628806148/)
  - ![](https://p3-tt.byteimg.com/origin/pgc-image/21a2426ec0304256950e4f80596b2b4a?from=pc)
  - ![](https://p3-tt.byteimg.com/origin/pgc-image/cc4fbb6975bf4799b413cb5ec9c694f3?from=pc)

- Numpy知识点汇总

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170415-1.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170415-2.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170415-3.png)

Reference
> 《Python for data analysis》 <br>
[NumPy Reference — NumPy v1.12 Manual](https://docs.scipy.org/doc/numpy/reference/?v=20170515184114)

### 基本操作

```python
import numpy as np

a = np.arange(9).reshape(3,3)
b = a.view() # 视图方法创造一个新的数组对象指向同一数据
print 'a=\n', a
print '生成同型矩阵：\n', np.zeros_like(a)
np.empty_like(a), np.ones_like(a)
print 'a形状参数：', len(a), a.size, a.shape

b = [[2,4,1],[1,3,2]]
print np.reshape(b, (3,2))

c = (a==3) | (a==5)
print '数值筛选:下标\n{}\n取出的数值{}'.format(c, a[c])
a[2,1:] = 0
print '分块赋值后的a=\n{}'.format(a)
print 'np.all(a)={}, np.any(a)={}'.format(np.all(a), np.any(a))

a = np.arange(9) # 一维数组
a = a.reshape(3,3) # 一维变二维 (9,) -> (3,3)
print 'a=', a
print 'double:\n', a*2 # 逐个元素处理
a1 = np.repeat(a, 2) # 元素重复几遍（列向）
print 'repeat用法:(2)\n', a1
a1 = np.repeat(a, 2, axis=0) # 行向重复
print 'repeat用法:(2, axis=0)\n', a1
#print(np.repeat(a, (2, 1), axis=0))
a2 = np.tile(a, 2) # 以对象为单位重复
print 'tile用法:(2)\n', a2
a2 = np.tile(a, (2,2)) # 对a重复2*2
print 'tile用法:(2,2)\n', a2
a = np.squeeze(a)  # 从数组的形状中删除单维条目，即把shape中为1的维度去掉
```

### 拼接

Python中numpy数组的合并有很多方法，如
- list.append(): list方法，占用内存大
- np.concatenate()：不会占用太多内存
- np.stack()
- np.hstack()：水平拼接
- np.vstack()：垂直拼接
- np.dstack()
其中最泛用的是第一个和第二个。第一个可读性好，比较灵活，但是占内存大。第二个则没有内存占用大的问题

复制操作:
- np.repeat：复制的是多维数组的每一个元素；axis来控制复制的行和列
- np.tile：复制的是多维数组本身；

```python
import numpy as np

a = np.arange(9) # 一维数组
a = a.reshape(3,3) # 一维变二维 (9,) -> (3,3)
print 'a=', a
print 'double:', a*2 # 逐个元素处理
a1 = np.repeat(a, 2) # 元素重复几遍
print 'repeat用法:', a1
a2 = np.tile(a, 2) # 矩阵重复
print 'tile用法:', a2
a = np.squeeze(a)  # 从数组的形状中删除单维条目，即把shape中为1的维度去掉
a = np.arange(9).reshape(3,3)
b = a * 2

print '水平拼接:', np.hstack((a,b)) # 水平拼接
print '水平拼接:', np.concatenate((a,b),axis=1) # 水平拼接
print '垂直拼接:', np.concatenate((a,b),axis=0) # 水平拼接
print '垂直拼接:', np.vstack((a,b))
print '纵轴拼接:', np.dstack((a,b))
#print '列组合:', column_stack(a) # 一维场景，二维同hstack
#print '行组合:', row_stack(a) # 一维场景，二维同vstack
```

### 代数&矩阵

```python
import numpy as np

a=[[400,-201],[-800,401]]
rank = np.linalg.matrix_rank(a) # 秩
norm = np.linalg.norm(a) # 范数
det = np.linalg.det(a) # 特征值 -399.99999
inv = np.linalg.inv(a) # 求逆
pinv = np.linalg.pinv(a) # 求伪逆
value, vector = np.linalg.eig(a) # 特征值和特征向量
value = np.linalg.eigvals(a) # 特征值
cond = np.linalg.cond(a) # 条件数 2503,病态
qr = np.linalg.qr(a) # 	QR分解: 正交矩阵*上三角
svd = np.linalg.svd(a) #  SVD分解

# one-hot
print(np.eye(5)) # 5*5单位矩阵
print(np.eye(5,4)) # 5*4矩阵，非方阵
print(np.eye(5,5,k=1)) # 单位阵，对角线上移k位
print(np.eye(5,5,k=-1)) # 单位阵，对角线下移k位
# ------ one-hot 编码-------
#设置类别的数量
num_classes = 10
#需要转换的整数
arr = [1,3,4,5,9]
#将整数转为一个10位的one hot编码
print(np.eye(num_classes)[arr])

# 由one-hot转换为普通np数组
data = [argmax(one_hot)for one_hot in one_hots]

```


### 文件处理

Numpy提供了几种数据保存的方法
- 二进制：只能保存为二进制文件，且不能保存当前数据的行列信息
  - tofile与fromfile
  - save与load：Numpy专用的二进制格式保存数据，它们会自动处理元素类型和形状等信息。savez()提供了将多个数组存储至一个文件的能力，调用load()方法返回的对象，可以使用数组名对各个数组进行读取。这种方法，保存文件的后缀名字一定会被置为.npy
- 文本格式：
  - savetxt与loadtxt

```python
#------二进制-------
a.tofile("filename.bin")
 b = numpy.fromfile("filename.bin",dtype = **)
np.save("a.npy", a.reshape(3,4))
c = np.load("a.npy")
# 存储多个数组到一个文件
a = np.array([[1,2,3],[4,5,6]])
b = np.arange(0,1.0,0.1)
c = np.sin(b)
np.savez("result.npz", a, b, sin_arr=c)  #使用sin_arr命名数组c
r = np.load("result.npz") #加载一次即可
#------文本-------
numpy.savetxt("filename.txt",a)
b =  numpy.loadtxt("filename.txt")
```



## Pandas

- Pandas 提供了数据结构——DataFrame，可以高效的处理一些数据分析任务。我们日常分析的数据，大多是存储在类似 excel 的数据表中，Pandas 可以灵活的按列或行处理数据，几乎是最常用的工具了。
- 【2021-12-8】[PandasTutor——一个用于可视化pandas操作的神器](https://www.datalearner.com/blog/1051638704435903)，[Pandas Tutor](https://pandastutor.com/vis.html)将pandas的操作变成可视化的过程，让我们充分理解这个过程。
  - ![](https://p5.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/adfbdc102c0c49a1a03e6fbf087fb08f?from=pc)
  - ![](https://p5.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/18eae93d73584418a821eb610467e207?from=pc)
  - ![](https://p5.toutiaoimg.com/origin/tos-cn-i-qvj2lq49k0/146f5bb7806d46d68d8dd6dcbc00aef6?from=pc)

```python
import pandas as pd
import io

csv = '''
breed,type,longevity,size,weight
German Shepherd,herding,9.73,large,
Beagle,hound,12.3,small,
Yorkshire Terrier,toy,12.6,small,5.5
Golden Retriever,sporting,12.04,medium,60.0
Bulldog,non-sporting,6.29,medium,45.0
Labrador Retriever,sporting,12.04,medium,67.5
Boxer,working,8.81,medium,
Poodle,non-sporting,11.95,medium,
Dachshund,hound,12.63,small,24.0
Rottweiler,working,9.11,large,
Boston Terrier,non-sporting,10.92,medium,
Shih Tzu,toy,13.2,small,12.5
Miniature Schnauzer,terrier,11.81,small,15.5
Doberman Pinscher,working,10.33,large,
Chihuahua,toy,16.5,small,5.5
Siberian Husky,working,12.58,medium,47.5
Pomeranian,toy,9.67,small,5.0
French Bulldog,non-sporting,9.0,medium,27.0
Great Dane,working,6.96,large,
Shetland Sheepdog,herding,12.53,small,22.0
Cavalier King Charles Spaniel,toy,11.29,small,15.5
German Shorthaired Pointer,sporting,11.46,large,62.5
Maltese,toy,12.25,small,5.0
'''

dogs = pd.read_csv(io.StringIO(csv))

(dogs[dogs['size'] == 'medium']
 .sort_values('type')
 .groupby('type').median()
)
```


### 介绍

Pandas(Python data analysis)是一个Python数据分析的开源库。名字源于panel data（计量经济学术语，面板数据）和python data analysis

pandas三种数据结构：
- Series（一维）: 系列(Series)是能够保存任何类型的数据(整数，字符串，浮点数，Python对象等)的一维标记数组。轴标签统称为索引。
- DataFrame（二维）
- Panel（三维）

[Pandas按行按列遍历Dataframe的几种方式](https://blog.csdn.net/sinat_29675423/article/details/87972498)
- ![](https://img-blog.csdnimg.cn/20190227142817847.png)
- 简单对上面三种方法进行说明：
    - iterrows(): 按行遍历，将DataFrame的每一行迭代为(index, Series)对，可以通过row[name]对元素进行访问。
    - itertuples(): 按行遍历，将DataFrame的每一行迭代为元祖，可以通过row[name]对元素进行访问，比iterrows()效率高。
    - iteritems():按列遍历，将DataFrame的每一列迭代为(列名, Series)对，可以通过row[index]对元素进行访问。

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-1.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-2.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-3.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-4.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-5.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-6.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-7.png)

### Series

系列(Series)是能够保存任何类型的数据(整数，字符串，浮点数，Python对象等)的一维标记数组。轴标签统称为索引
- ![](https://ask.qcloudimg.com/http-save/yehe-6739646/7t523md5n4.png?imageView2/2/w/1620)
- 数据访问
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/gpui6hrkgk.png?imageView2/2/w/1620)
- 序列聚合
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/0gu7wvsxmz.png?imageView2/2/w/1620)

```python
import pandas as pd
import numpy as np

# 从ndarray创建series
pd.Series(np.array([1,2,3,4])) # index自动设置：0-3
# 从字典创建series
pd.Series({'a':1, 'b':2, 'c':3}) # index为字典的key: a,b,c
```

### DataFrame

DataFrame(数据帧)是带有标签的二维数据结构，列的类型可能不同。可以想象成一个电子表格或SQL表，或者 Series 对象的字典。它一般是最常用的pandas对象。
- ![](https://ask.qcloudimg.com/http-save/yehe-6739646/k1xbd1yghd.png?imageView2/2/w/1620)
- ![](https://ask.qcloudimg.com/http-save/yehe-6739646/o7ujyacfgd.jpeg?imageView2/2/w/1620)

创建方式：列表、字段

```python
import pandas as pd
import numpy as np

# 从 list 创建 dataframe
pd.DataFrame([[1,2],[3,4]]) # index自动设置
# 从 字典 创建 dataframe
pd.DataFrame({'a':[1,3], 'b':[2,4]}) # columns 为字典的key: a,b
pd.DataFrame({'a':[1,3], 'b':[2,4]}, columns=['a','b']) 
```

#### 读文件

python中pd读取文件
- parse_dates(**动词**，主动解析格式）
  - parse_dates = True : 尝试解析index为日期格式；
  - parse_dates = [ 0,1,2,3,4] : 尝试解析0，1，2，3，4列为时间格式；
  - parse_dates = [ [ ’考试日期’,‘考试时间’] ] :传入多列名，尝试将其解析并且拼接起来,parse_dates[[0,1,2]]也有同样的效果；
  - parse_dates = {’考试安排时间’:[ ‘考试日期’,‘考试时间’]}，将会尝试解析日期和时间拼接起来，并将列名重置为‘考试安排时间’；
  - 注意：重置后列名不能和原列名重复
- date_parser(**名词**，指定解析格式去解析某种不常见的格式）
  - date_parser需要配合parse_dates工作，具体需要传入函数
  - 例如时间为2021年2月24日，可以传入
  - parse_dates=[ 0 ]
  - date_parser=lambda x:pd.to_datetime(x,format=’%Y年%m月%d日’）


#### 从github加载

【2022-1-24】直接加载github数据

```python
import pandas as pd

# github repo 中文件地址，需要转换："https://github.com/sksujan58/Multivariate-time-series-forecasting-using-LSTM/blob/main/train.csv"
url = "https://raw.githubusercontent.com/sksujan58/Multivariate-time-series-forecasting-using-LSTM/master/train.csv"
#df = pd.read_csv(url,parse_dates=["Date"])
#df0 = pd.read_csv(url)
#df = pd.read_csv("train.csv", parse_dates=["Date"],index_col=[0])
df = pd.read_csv(url, parse_dates=["Date"], index_col=[0]) # Date格式转换（str→date），指定Date作为索引列

```


#### 常规操作

- [图解pandas模块21个常用操作](https://cloud.tencent.com/developer/article/1593598?from=article.detail.1814957)


- 列选择
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/rv8daoc5wc.jpeg?imageView2/2/w/1620)
- 行选择
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/m6wdwy9hq3.png?imageView2/2/w/1620)
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/kcwx2xv583.png?imageView2/2/w/1620)
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/kexh9kk11o.png?imageView2/2/w/1620)
- 元素选择
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/gg3b55edy7.png?imageView2/2/w/1620)
- 条件查询：对各类数值型、文本型，单条件和多条件进行行选择
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/t6gy3dq9br.png?imageView2/2/w/1620)
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/y2rlucz5h2.png?imageView2/2/w/1620)
- 聚合
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/bzoezk1eds.png?imageView2/2/w/1620)
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/ezls6rc5e2.jpeg?imageView2/2/w/1620)
  - 聚合函数: 
    - data.function(axis=0) 按列计算
    - data.function(axis=1) 按行计算
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/k5egk8ill6.jpeg?imageView2/2/w/1620)
- 分组统计
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/8e9dxw31fo.jpeg?imageView2/2/w/1620)
- 透视表：透视表是pandas的一个强大的操作，大量的参数完全能满足你个性化的需求。
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/zwax57zwp5.png?imageView2/2/w/1620)
- 缺失值
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/fwgt2gstw7.jpeg?imageView2/2/w/1620)
- 查找替换: pandas提供简单的查找替换功能，如果要复杂的查找替换，可以使用map(), apply()和applymap() 
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/sn7r5r6vot.jpeg?imageView2/2/w/1620)
- 数据合并: 两个DataFrame的合并，pandas会自动按照索引对齐，可以指定两个DataFrame的对齐方式，如内连接外连接等，也可以指定对齐的索引列。
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/r5v945asbm.png?imageView2/2/w/1620)
- 更改列名（columns index）
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/d6qgw6ld3w.png?imageView2/2/w/1620)
- apply函数: 单值运算
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/4mkr8aei3v.jpeg?imageView2/2/w/1620)
  - ![](https://ask.qcloudimg.com/http-save/yehe-6739646/b3vcd1zfvw.png?imageView2/2/w/1620)

### 三板斧

[数据处理三板斧——map、apply、applymap详解](https://zhuanlan.zhihu.com/p/100064394)

Pandas三板斧（map、apply和applymap）可以对DataFrame进行逐**行**、逐**列**和逐**元素**的操作，对应这些操作
- map: 
  - 字典还是函数进行映射，map方法都是把对应的数据**逐个**当作参数传入到字典或函数中，得到映射后的值。
- apply: 
  - apply方法的作用原理和map方法类似，区别在于apply能够传入功能更为**复杂的函数**。
  - ![](https://pic4.zhimg.com/80/v2-98f8b09e26abe17e850ed125950fecdf_720w.jpg)
- applymap:
  - applymap的用法比较简单，会对DataFrame中的每个单元格执行指定函数的操作，虽然用途不如apply广泛，但在某些场合下还是比较有用的
- 数据
  - ![](https://pic4.zhimg.com/80/v2-656d29d7df031238286e085bfa50293b_720w.jpg)

```python
# 数据准备
boolean=[True,False]
gender=["男","女"]
color=["white","black","yellow"]
data=pd.DataFrame({
    "height":np.random.randint(150,190,100),
    "weight":np.random.randint(40,90,100),
    "smoker":[boolean[x] for x in np.random.randint(0,2,100)],
    "gender":[gender[x] for x in np.random.randint(0,2,100)],
    "age":np.random.randint(15,90,100),
    "color":[color[x] for x in np.random.randint(0,len(color),100) ]
})

# ----- map ------
# ① 使用字典进行映射
data["gender"] = data["gender"].map({"男":1, "女":0})
​
# ② 使用函数
def gender_map(x):
    gender = 1 if x == "男" else 0
    return gender
# 注意这里传入的是函数名，不带括号
data["gender"] = data["gender"].map(gender_map)

# ------ apply -----
def apply_age(x,bias):
    return x+bias
#以元组的方式传入额外的参数
data["age"] = data["age"].apply(apply_age,args=(-3,))
# 沿着0轴求和
data[["height","weight","age"]].apply(np.sum, axis=0)
# 沿着0轴取对数
data[["height","weight","age"]].apply(np.log, axis=0)
# 计算BMI
def BMI(series):
    weight = series["weight"]
    height = series["height"]/100
    BMI = weight/height**2
    return BMI
data["BMI"] = data.apply(BMI,axis=1)

# ------ applymap -----
# 浮点数保留两位小数
df.applymap(lambda x:"%.2f" % x)

```


### 查看数据

代码：

```python
import pandas as pd

#查看、检查数据
df.head(n)# 查看DataFrame对象的前n行
df.tail(n)# 查看DataFrame对象的最后n行
df.shape()# 查看行数和列数
df.info()# 查看索引、数据类型和内存信息
df.describe()# 查看数值型列的汇总统计
s.value_counts(dropna=False)# 查看Series对象的唯一值和计数
df.apply(pd.Series.value_counts)# 查看DataFrame对象中每一列的唯一值和计数

# 数据统计
df.describe()# 查看数据值列的汇总统计
df.mean()# 返回所有列的均值
df.corr()# 返回列与列之间的相关系数
df.count()# 返回每一列中的非空值的个数
df.max()# 返回每一列的最大值
df.min()# 返回每一列的最小值
df.median()# 返回每一列的中位数
df.std()# 返回每一列的标准差

# 查找数据
df = pd.DataFrame({'BoolCol': [1, 2, 3, 3, 4],'attr': [22, 33, 22, 44, 66]}, index=[10,20,30,40,50])
df = pd.DataFrame({'BoolCol': [1, 2, 3, 3, 4],'attr': [22, 33, 22, 44, 66]})
print(df)
print(df['attr']) # series对象

a1 = df[(df.BoolCol==3)&(df.attr==22)].index.tolist() # 返回下标
a2 = df[(df.BoolCol==3)&(df.attr==22)].values.tolist() # 返回数值
print(a1,a2)

#df.index # 行序号
df.columns # 列名
df.values # 数据内容， 当df是series类型时直接转ndarray类型
#df['lon'],df['lat'],df[:30] # 按照列名读取数据
#df.ix[:30,:3] # 使用ix、loc或者iloc(按照下标组合)进行行列双向读取，即切片操作
#df.ix[:20,['lon','lat']] # 跨属性组合选取
key_list = ['total_bedrooms','population']
df.loc[:100, key_list] # 同上?
#new = df.iloc[:20,[1,2]]
#new.describe # 基本统计信息
#type(new)
#df[df.lon>117] # 按照数值过滤筛选
#df[df.time<'2016-07-20']
#new.values.tolist() # DataFrame转成list结构
#[2018-11-2]另外一种方法：np.array(new).tolist()
#df.sort(columns='time') # 排序
#[2018-10-12] 将pandas元素提取(numpy结构)并转化为list结构
for idx in xrange(df.size):
    item = df.ix[idx,key_list].get_values().tolist()
#提取某个取值的数据，注意：==，不是=！
df[df.businesstype==7]
```

### 数据选择

代码：

```python
#数据选取
df[col]# 根据列名，并以Series的形式返回列
df[[col1, col2]]# 以DataFrame形式返回多列
s.iloc[0]# 按位置选取数据
s.loc['index_one']# 按索引选取数据
df.iloc[0,:]# 返回第一行
df.iloc[0,0]# 返回第一列的第一个元素

DataFrame.lookup（row_labels，col_labels） # DataFrame基于标签的“花式索引”功能。 
DataFrame.pop（item） # 返回项目并从框架中删除。 类似方法del

# 多个条件通过&、|连接
student[(student['Sex']=='F') & (student['Age']>12)]
# Pandas实现where filter
df[df['sex'] == 'Female']
df[df['total_bill'] > 20]
#在where子句中常常会搭配and, or, in, not关键词，Pandas中也有对应的实现
df[(df['sex'] == 'Female') & (df['total_bill'] > 20)] # and
df[(df['sex'] == 'Female') | (df['total_bill'] > 20)] # or
# 存在性判断
df[df['total_bill'].isin([21.01, 23.68, 24.59])] # in
df[-(df['sex'] == 'Male')] # not
df[-df['total_bill'].isin([21.01, 23.68, 24.59])]
# 判断元素是否存在
a = 1 if 'NLU泛化' in stat['failure'].values else 0
# string function 使用str函数
df = df[(-df['sex'].isin(['male', 'female'])) & (-df.sex.str.contains('^m\d+$'))]
# 对where条件筛选后只有一行的dataframe取其中某一列的值，其两种实现方式如下：
total = df.loc[df['tip'] == 1.66, 'total_bill'].values[0]
total = df.get_value(df.loc[df['tip'] == 1.66].index.values[0], 'total_bill')

# 像sql一样操作, 使用bool表达式
df.query('total_bill > 20')

```

### 数据清理

代码

```python
# 数据清理
df.columns = ['a','b','c']# 重命名列名
pd.isnull()# 检查DataFrame对象中的空值，并返回一个Boolean数组
pd.notnull()# 检查DataFrame对象中的非空值，并返回一个Boolean数组
df.drop([16,17]) # 删除16，17行,得到新的dataframe, df仍然保留
df.drop(inex=['a', 'b']) # 或者这样
df.drop([16,17], inplace=True) # 删除16，17行, 原地操作
df.dropna()# 删除所有包含空值的行
df.dropna(axis=1)# 删除所有包含空值的列
df.drop(['a', 'b'], axis=1) # 删除列a,b
df.drop(columns=['a', 'b']) # 或者这样
df.dropna(axis=1,thresh=n)# 删除所有小于n个非空值的行
df.fillna(x)# 用x替换DataFrame对象中所有的空值
s.astype(float)# 将Series中的数据类型更改为float类型
s.replace(1,'one')# 用‘one’代替所有等于1的值
s.replace([1,3],['one','three'])# 用'one'代替1，用'three'代替3
#Series对象值替换
s = df.iloc[2]#获取行索引为2数据
#单值替换
s.replace('?',np.nan)#用np.nan替换？
s.replace({'?':'NA'})#用NA替换？
#多值替换
s.replace(['?',r'$'],[np.nan,'NA'])#列表值替换
s.replace({'?':np.nan,'$':'NA'})#字典映射
#同缺失值填充方法类似
s.replace(['?','$'],method='pad')#向前填充
s.replace(['?','$'],method='ffill')#向前填充
s.replace(['?','$'],method='bfill')#向后填充
#limit参数控制填充次数
s.replace(['?','$'],method='bfill',limit=1)
#DataFrame对象值替换
#单值替换
df.replace('?',np.nan)#用np.nan替换？
df.replace({'?':'NA'})#用NA替换？
#按列指定单值替换
df.replace({'EMPNO':'?'},np.nan)#用np.nan替换EMPNO列中?
df.replace({'EMPNO':'?','ENAME':'.'},np.nan)#用np.nan替换EMPNO列中?和ENAME中.
#多值替换
df.replace(['?','.','$'],[np.nan,'NA','None'])##用np.nan替换？用NA替换. 用None替换$
df.replace({'?':'NA','$':None})#用NA替换？ 用None替换$
df.replace({'?','$'},{'NA',None})#用NA替换？ 用None替换$
#正则替换
df.replace(r'\?|\.|\$',np.nan,regex=True)#用np.nan替换？或.或$原字符
df.replace([r'\?',r'\$'],np.nan,regex=True)#用np.nan替换？和$
df.replace([r'\?',r'\$'],[np.nan,'NA'],regex=True)#用np.nan替换？用NA替换$符号
df.replace(regex={r'\?':None})
#value参数显示传递
df.replace(regex=[r'\?|\.|\$'],value=np.nan)#用np.nan替换？或.或$原字符
# [2019-08-29]
d = pd.DataFrame({'BoolCol': [1, 2, 3, 3, 4],'attr': ['a.,b', 'hello', 'world', ',', '4,5']})
d.replace({'attr':','}, '->') # 完全匹配
d.replace(r',', '->',regex=True) # 正则替换
d.replace(r',', '->',regex=True, inplace=True) # 修改原值
d[(df_2.ocr.isnull) & (d.ocr.str.contains(','))] # 检测是否包含,

#原文链接：https://blog.csdn.net/kancy110/article/details/72719340
df.rename(columns=lambda x: x + 1)# 批量更改列名
df.rename(columns={'old_name': 'new_ name'})# 选择性更改列名
df.set_index('column_one')# 更改索引列
df.rename(index=lambda x: x + 1)# 批量重命名索引


# 数据处理：Filter、Sort和GroupBy
df[df[col] > 0.5]# 选择col列的值大于0.5的行
df.sort_values(col1)# 按照列col1排序数据，默认升序排列
df.sort_values(col2, ascending=False)# 按照列col1降序排列数据
df.sort_values([col1,col2], ascending=[True,False])# 先按列col1升序排列，后按col2降序排列数据
df.groupby(col)# 返回一个按列col进行分组的Groupby对象
df.groupby([col1,col2])# 返回一个按多列进行分组的Groupby对象
df.groupby(col1)[col2]# 返回按列col1进行分组后，列col2的均值
df.pivot_table(index=col1, values=[col2,col3], aggfunc=max)# 创建一个按列col1进行分组，并计算col2和col3的最大值的数据透视表
df.groupby(col1).agg(np.mean)# 返回按列col1分组的所有列的均值
data.apply(np.mean)# 对DataFrame中的每一列应用函数np.mean
data.apply(np.max,axis=1)# 对DataFrame中的每一行应用函数np.max
# -------------
tmp = lambda x:x.sort_values(ascending = False).iloc[0]
tmp.__name__ = 'func'
df['real_cost'].applymap(tmp) # 元素级别变换
df[['customer_type','real_cost']].agg({'customer_type':['sum','mean'],'real_cost':['sum',tmp]}) # 多个属性的统计信息（统计值不同,自定义聚合函数）
df.groupby(['real_cost']).transform(('sum')) # transform元素级别的变换
# -------------
# 数据过滤
import pandas as pd 
data_file = 'name.csv'
df = pd.read_csv(data_file)
# 编码转换 gbk -> utf8
df['path'] = df['path_name'].apply(lambda x:x.decode('gbk').encode('utf8'))
#print df['path_name'][3].decode('gbk').encode('utf8')
df

# 数据合并
df1.append(df2)# 将df2中的行添加到df1的尾部
df.concat([df1, df2],axis=1)# 将df2中的列添加到df1的尾部
df1.join(df2,on=col1,how='inner')# 对df1的列和df2的列执行SQL形式的join
```

### 合并

- [pandas-数据的合并与拼接](https://www.cnblogs.com/keye/p/10791705.html)
- Pandas包的merge、join、concat方法可以完成数据的合并和拼接
    - **merge**方法主要基于两个dataframe的共同列进行合并
    - **join**方法主要基于两个dataframe的索引进行合并
    - **concat**方法是对series或dataframe进行行拼接或列拼接。

- (1) pandas的merge方法是基于共同列，将两个dataframe连接起来。
- merge方法的主要参数：
    - left/right：左/右位置的dataframe。
    - how：数据合并的方式。
        - left：基于左dataframe列的数据合并；
        - right：基于右dataframe列的数据合并；
        - outer：基于列的数据外合并（取并集）；
        - inner：基于列的数据内合并（取交集）；默认为'inner'。
    - on：用来合并的列名，这个参数需要保证两个dataframe有相同的列名。
    - left_on/right_on：左/右dataframe合并的列名，也可为索引，数组和列表。
    - left_index/right_index：是否以index作为数据合并的列名，True表示是。
    - sort：根据dataframe合并的keys排序，默认是。
    - suffixes：若有相同列且该列没有作为合并的列，可通过suffixes设置该列的后缀名，一般为元组和列表类型。
- 示例：
    - 内连接：
        - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170030512-309759819.png)
    - 外链接
        - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170055862-1927816021.png)
    - index和column的内连接方法
        - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170503579-1916082061.png)



```python
# 单列的内连接
# 定义df1
import pandas as pd
import numpy as np

df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'feature1':[1,1,2,3,3,1],
            'feature2':['low','medium','medium','high','low','high']})
# 定义df2
df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],
            'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})
# print(df1)
# print(df2)
# 基于共同列alpha的内连接
df3 = pd.merge(df1,df2,how='inner',on='alpha')
# 基于共同列alpha的内连接,若两个dataframe间除了on设置的连接列外并无相同列，则该列的值置为NaN。
df4 = pd.merge(df1,df2,how='outer',on='alpha')
# 基于共同列alpha的左连接
df5 = pd.merge(df1,df2,how='left',on='alpha')
# 基于共同列alpha的右连接
df6 = pd.merge(df1,df2,how='right',on='alpha')
# 基于共同列alpha和beta的内连接
df7 = pd.merge(df1,df2,on=['alpha','beta'],how='inner')
# 基于共同列alpha和beta的右连接
df8 = pd.merge(df1,df2,on=['alpha','beta'],how='right')
# 基于df1的beta列和df2的index连接
df9 = pd.merge(df1,df2,how='inner',left_on='beta',right_index=True)
# 基于df1的alpha列和df2的index内连接(修改相同列的后缀名)
df9 = pd.merge(df1,df2,how='inner',left_on='beta',right_index=True,suffixes=('_df1','_df2'))
df3
```

- (2) join方法
    - join方法是基于index连接dataframe，merge方法是基于column连接，连接方法有内连接，外连接，左连接和右连接，与merge一致。 
    - join和merge的连接方法类似，这里就不展开join方法了，建议用merge方法。
- 示例
    - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170956399-607825585.png)

```python
caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})
other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})
print(caller)
print(other)# lsuffix和rsuffix设置连接的后缀名
# 基于index连接
caller.join(other,lsuffix='_caller', rsuffix='_other',how='inner')
# 基于key列进行连接
caller.set_index('key').join(other.set_index('key'),how='inner')
```

- (3) concat方法
    - concat方法是拼接函数，有行拼接和列拼接，默认是行拼接，拼接方法默认是外拼接（并集），拼接的对象是pandas数据类型。 
- 示例

```python
df1 = pd.Series([1.1,2.2,3.3],index=['i1','i2','i3'])
df2 = pd.Series([4.4,5.5,6.6],index=['i2','i3','i4'])
print(df1)
print(df2)

# 行拼接
pd.concat([df1,df2])
# 对行拼接分组,行拼接若有相同的索引，为了区分索引，我们在最外层定义了索引的分组情况。
pd.concat([df1,df2],keys=['fea1','fea2'])
# 列拼接,默认是并集
pd.concat([df1,df2],axis=1)
# 列拼接的内连接（交）
pd.concat([df1,df2],axis=1,join='inner')
# 列拼接的内连接（交）
pd.concat([df1,df2],axis=1,join='inner',keys=['fea1','fea2'])
# 指定索引[i1,i2,i3]的列拼接
pd.concat([df1,df2],axis=1,join_axes=[['i1','i2','i3']])

df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})
df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})
print(df1)
print(df2)

# 行拼接
pd.concat([df1,df2])
# 列拼接
pd.concat([df1,df2],axis=1)
# 判断是否有重复的列名，若有则报错
pd.concat([df1,df2],axis=1,verify_integrity = True)
```


Reference
> 《Python for data analysis》<br>
[pandas: powerful Python data analysis toolkit — pandas 0.20.1 documentation](http://pandas.pydata.org/pandas-docs/stable/?v=20170515184114)

### 遍历

【2020-12-25】遍历dataframe
- iterrows：最慢
- itertuples
- zip：最快

```python
# 总结
DataFrame.iteritems() # 迭代器结束（列名，系列）对。 
DataFrame.iterrows() # 将DataFrame行重复为（索引，系列）对。 
DataFrame.itertuples（[index，name]） # 将DataFrame行迭代为namedtuples，索引值作为元组的第一个元素。

df = pd.DataFrame({'a': range(0, 10000), 'b': range(10000, 20000)})
import time
list1 = []
start = time.time()
for i,r in df.iterrows():
    list1.append((r['a'], r['b']))
print("iterrows耗时  :",time.time()-start)

list1 = []
start = time.time()
for ir in df.itertuples():
    list1.append((ir[1], ir[2]))    
print("itertuples耗时:",time.time()-start)

list1 = []
start = time.time()
for r in zip(df['a'], df['b']):
    list1.append((r[0], r[1]))
print("zip耗时       :",time.time()-start)
```

- 结果：
    - iterrows耗时  : 0.7355637550354004
    - itertuples耗时: 0.008462905883789062
    - zip耗时       : 0.003980875015258789

### 多表合并

- 【2020-12-31】一次合并多张表

```python
import pandas as pd
from functools import reduce
 
data_dir = '/home/work/data/北链讲盘培训价值分析'
#data_file = '/home/work/data/北链讲盘过关用户业绩样例.csv'
bu = ['京北', '京东南']
group = ['未参加', '低分', '高分']
df_dict = {}
for b in bu:
    df_dict[b] = {}
    for g in group:
        data_file = '{}/{}-{}.csv'.format(data_dir, b, g)
        print('开始读数据：{}'.format(data_file))
        df_dict[b][g] = pd.read_csv(data_file, encoding='gbk')
        df_dict[b][g] = df_dict[b][g].rename(columns={'stat_date':'日期', 'avg(assign_amt)':'培训{}的经纪人日均业绩'.format(g)})
        df_final.loc[:,'alpha'].apply(lambda x:'{}-hh'.format(x))
        df_dict[b][g]['日期'] = df_dict[b][g]['日期'].apply(lambda x: '{}-{}-{}'.format(str(x)[:4],str(x)[4:6],str(x)[6:8]))
        # .dt.dayofweek
        df_dict[b][g]['星期几'] = pd.to_datetime(df_dict[b][g]['日期']).dt.dayofweek
    #df_dict[b]['合并'] = df.merge(df_dict[b]['未参加'], df_dict[b]['低分'], df_dict[b]['高分'], how='inner', on='日期')
    merge_list = [df_dict[b]['未参加'], df_dict[b]['低分'], df_dict[b]['高分']]
    df_dict[b]['合并'] = reduce(lambda left,right: pd.merge(left,right,on='日期',how='outer'), merge_list).fillna(0)
    df_dict[b]['合并'].to_excel('{}/{}_合并后.xlsx'.format(data_dir, b))
 
#df = pd.read_csv(data_file, encoding='gbk')
#!head $data_file
#df3 = pd.merge(df1,df2,how='inner',on='alpha')
df_dict['京北']['合并']
```

### 日期转换

- [pandas字符串转日期处理方式](https://blog.csdn.net/weixin_41685388/article/details/103860881)
- 代码

```python

#提取年月日时分秒：方法1
df = pd.read_csv(r"spider.csv",header=None,names=['datetime','url','name','x','y'],encoding='utf-8')
df['datetime'] = pd.to_datetime(df['datetime'],errors='coerce')   #先转化为datetime类型,默认format='%Y-%m-%d %H:%M:%S'
df['date'] = df['datetime'].dt.date   #转化提取年-月-日
df['year'] =df['datetime'].dt.year.fillna(0).astype("int")   #转化提取年 ,
#如果有NaN元素则默认转化float64型，要转换数据类型则需要先填充空值,在做数据类型转换
df['month'] = df['datetime'].dt.month.fillna(0).astype("int")  #转化提取月
df['%Y_%m'] = df['year'].map(str) + '-' + df['month'].map(str) #转化获取年-月
df['day'] = df['datetime'].dt.day.fillna(0).astype("int")      #转化提取天
df['hour'] = df['datetime'].dt.hour.fillna(0).astype("int")    #转化提取小时
df['minute'] = df['datetime'].dt.minute.fillna(0).astype("int") #转化提取分钟
df['second'] = df['datetime'].dt.second.fillna(0).astype("int") #转化提取秒
df['dayofyear'] = df['datetime'].dt.dayofyear.fillna(0).astype("int") #一年中的第n天
df['weekofyear'] = df['datetime'].dt.weekofyear.fillna(0).astype("int") #一年中的第n周
df['weekday'] = df['datetime'].dt.weekday.fillna(0).astype("int") #周几，一周里的第几天，Monday=0, Sunday=6
df['quarter'] = df['datetime'].dt.quarter.fillna(0).astype("int")  #季度
display(df.head())
```

### 排序

数据排序sort_index()和sort_values()

**sort_values**()
- 作用：既可以根据列数据，也可根据行数据排序。
- 注意：必须指定by参数，即必须指定哪几行或哪几列；无法根据index名和columns名排序（由.sort_index()执行）

DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')
- axis：{0 or ‘index’, 1 or ‘columns’}, default 0，默认按照列排序，即纵向排序；如果为1，则是横向排序。
- by：str or list of str；如果axis=0，那么by="列名"；如果axis=1，那么by="行名"。
- ascending：布尔型，True则升序，如果by=['列名1','列名2']，则该参数可以是[True, False]，即第一字段升序，第二个降序。
- inplace：布尔型，是否用排序后的数据框替换现有的数据框。
- kind：排序方法，{‘quicksort’, ‘mergesort’, ‘heapsort’}, default ‘quicksort’。似乎不用太关心。
- na_position：{‘first’, ‘last’}, default ‘last’，默认缺失值排在最后面。

**sort_index**()
- 作用：默认根据行标签对所有行排序，或根据列标签对所有列排序，或根据指定某列或某几列对行排序。
- 注意：df. sort_index()可以完成和df. sort_values()完全相同的功能，但python更推荐用只用df. sort_index()对“根据行标签”和“根据列标签”排序，其他排序方式用df.sort_values()。

sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)
- axis：0按照行名排序；1按照列名排序
- level：默认None，否则按照给定的level顺序排列---貌似并不是，文档
- ascending：默认True升序排列；False降序排列
- inplace：默认False，否则排序之后的数据直接替换原来的数据框
- kind：排序方法，{‘quicksort’, ‘mergesort’, ‘heapsort’}, default ‘quicksort’。似乎不用太关心。
- na_position：缺失值默认排在最后{"first","last"}
- by：按照某一列或几列数据进行排序，但是by参数貌似不建议使用



```python
import pandas as pd  

df = pd.DataFrame({'b':[1,2,2,3],'a':[4,3,2,1],'c':[1,3,8,2]},index=[2,0,1,3]) 

df.sort_values(by='b') #等同于df.sort_values(by='b',axis=0)
df.sort_values(by=[3,0],axis=1,ascending=[True,False])
df.sort_values(by=3,axis=1) #按第三行升序，必须指定axis=1

df.sort_index() #默认按“行标签”升序排序，或df.sort_index(axis=0, ascending=True)
df.sort_index(axis=1) #按“列标签”升序排序
#先按b列“降序”排列，因为b列中有相同值，相同值再按a列的“升序”排列
df.sort_index(by = ['b','a'],ascending = [False,True]) 

```

### 聚合统计

词频统计，类似collections里的Counter
- 聚合函数:sum,cumsum,prod,mean,max,min,idxmax,rank

```python
# 对train表里的intent列计算频次，并给出百分比（不用单独计算）
train.intent.value_counts(), train.intent.value_counts(normalize=True)
# 聚合统计
df.groupby('total_bedrooms')['population'].agg(['count', 'sum', 'mean'])[:10]
df.groupby(['real_cost']).size().loc[10] # 查询某个分组下的聚合值
df.groupby(['real_cost']).get_group((10)) # 查询某个分组下所有记录
df.groupby(['real_cost'])['queuecount'].idxmin() # 各个分组下某个取值(queuecount)最小/大的记录数下标,idxmin,idxmax
df.groupby(['real_cost']).size().apply(lambda x:2*x).head() # apply,对统计值的二次处理
df.groupby(['real_cost']).size().reset_index()# reset_index重置index

# key内部求和，按照key分组，再对value求和
gp = data.groupby(["key"])["value"].sum().reset_index() # reset_index重置index
gp = data.groupby(["key"])["value"].cumsum().reset_index() # 累计和
gp = data.groupby(["key"])["value"].prod().reset_index() # 连乘，类似的min、max、mean、idxmin、idxmax
gp = data.groupby(["key"])["value"].rank().reset_index() # 编号
gp = data.groupby(["key"])["value"].agg(['count','sum']).reset_index() # agg多组值

gp.rename(columns={"value":"sum_of_value"},inplace=True) # rename改列名
grouped1 = df['data1'].astype(float).groupby(df['key1']).mean()     #先将data1转换成浮点型，然后分组求均值

# [2021-10-22] 转成字典格式: key → value
prov_data = dict(stat['location'].groupby('省')['所有频次'].agg(['sum'])['sum'])
# pandas groupby常用功能
df.groupby(['real_cost']).size().reset_index()# reset_index重置index
df.groupby(['dt','msg']).size().reset_index().rename(columns={0:"count"})
df.rename(columns={0:"count"})
df.groupby(['real_cost']).size() # 分组,频次计算,size()计算数目
df.groupby(['real_cost']).size() # 分组,频次计算,count()不含Nan值
df.groupby(['real_cost']).size().loc[10] # 查询某个分组下的聚合值
df.groupby(['real_cost']).get_group((10)) # 查询某个分组下所有记录
df.groupby(['real_cost'])['queuecount'].idxmin() # 各个分组下某个取值(queuecount)最小/大的记录数下标,idxmin,idxmax
df.groupby(['real_cost']).size().apply(lambda x:2*x).head() # apply,对统计值的二次处理
# 用户当天第几次搜索某个brand_id
gp = data.groupby(["user_id","day","brand_id"])["hour"].rank().reset_index() 
gp.rename(columns={"hour":"rank"},inplace=True)
#agg 调用的时候要指定字段，apply 默认传入的是整个dataframe,transform 是针对输入的元素级别转换
df[['customer_type','real_cost']].agg(['sum','mean','min','max','median']) # 多个属性的统计信息
tmp = lambda x:x.sort_values(ascending = False).iloc[0]
tmp.__name__ = 'func'
df[['customer_type','real_cost']].agg({'customer_type':['sum','mean'],'real_cost':['sum',tmp]}) # 多个属性的统计信息（统计值不同,自定义聚合函数）
df.groupby(['real_cost']).transform(('sum')) # transform元素级别的变换
df['real_cost'].applymap(tmp) # 元素级别变换
```

### 采样

pandas随机采样，用于数据集划分;

```python
# 随机采样
df = pd.DataFrame([[1,'a'],[2,'b'],[3,'c'],[4,'d']], columns=['id','name'])
# DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)
#df.sample(frac=1).reset_index(drop=True)
df.sample(frac=1) # 随机打乱,100%乱序，frac是比例，axis行还是列向，replace是否放回，weights字符索引或概率数组
df.sample(n=3,random_state=1) # 抽3行，可重复数据
df.sample(frac=0.8, replace=True, random_state=1) # replace可重复
```

### 文件读写

excel文件：openpyxl、pandas、xlrd（2.0版本不再支持xlsx文件，因此我用的1.2版本）、xlwings分别读取测试性能
- openpyxl读取得到1048553行，耗时32秒pandas读取得到1048553行（包括表头行），耗时49秒
- xlrd读取得到63行，耗时15秒（将xlrd获取的数据用遍历方式读入list再转化为DataFrame的操作，耗时微秒级）
- xlwings读取得到1048553行，耗时6秒（将xlwings获取的数据用expand方法读入list可以获得正确的行数，再转化为DataFrame的操作，耗时毫秒级）


`xlrd`是python环境下对excel中的数据进行读取的一个模板，可以进行的操作有：
- 读取有效单元格的行数、列数
- 读取指定行（列）的所有单元格的值
- 读取指定单元格的值
- 读取指定单元格的数据类型

pandas文件操作

```python
# pandas读取excel数据示例
# 【2016-7-30】 参考：十分钟搞定pandas
import pandas as pd
import numpy as np
# 读取数据 D:\work\用户建模画像\家公司挖掘\code\warren.xls
# 数据格式：time
print 'start'
df = pd.read_excel('C:\Users\warren\Desktop\warren.xlsx',index='time')
#[2018-4-11] 先安装!pip install xlrd才可以
df = pd.read_excel(open('your_xls_xlsx_filename','rb'), sheetname=1) # 读取第二个sheet
df = pd.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')
# 显示excel里的sheet列表
ReadSheets=pd.ExcelFile('test.xlsx')
for i in ReadSheets.sheet_names:
    print(i)

df = pd.read_table('data/raw_tmp_new.txt',header=None,names=['a','b','c'])
data_file = 'D:/project/python_instruct/test_data1.csv'
df = pd.read_csv(data_file)#用read_csv读取的csv文件
# skiprows：排除前3行是skiprows=3 排除第3行是skiprows=[3]
df = pd.read_csv(data_file, skiprows=3)
df = pd.read_csv(data_file, encoding='utf8') # 编码
df = pd.read_table(data_file, sep=',')#用read_table读取csv文件
df = pd.read_csv("data.txt",sep="\s+") # 不规则分隔符
df = pd.read_csv(data_file, header=None)#用read_csv读取无标题行的csv文件
df = pd.read_csv(data_file, names=['a', 'b', 'c', 'd', 'message'])#用read_csv读取自定义标题行的csv文件

df =  pd.read_csv("./demo.txt",header=None,names=['a','b','c','d','e'])
df =  pd.read_csv("./demo.txt",header=None,index_col=False,names=['a','b','c','d','e'])
# 自定义某列处理方法：converters 设置指定列的处理函数，可以用"序号"也可以使用“列名”进行列的指定
def fun(x):
    return str(x)+"-haha"
df =  pd.read_csv("./test.txt",sep=' ',header=None,index_col=0,converters={3:fun})

names=['a', 'b', 'c', 'd', 'message']
df=pd.read_csv(data_file, names=names, index_col='message')#'read_csv读取时指定索引
parsed=pd.read_csv(data_file, index_col=['key1', 'key2'])#read_csv将多个列做成一个层次化索引
print(list(open(data_file)))
# read_table ≈ read_csv，区别仅在与分隔符
result=pd.read_table(data_file, sep='\s+')#read_table利用正则表达式处理文件读取
# 固定宽度文件
colspecs = [(0, 6), (8, 20), (21, 33), (34, 43)]
df = pd.read_fwf('demo.txt', colspecs=colspecs, header=None, index_col=0)
# read_msgpack 函数
#    pandas支持的一种新的可序列化的数据格式，这是一种轻量级的可移植二进制格式，类似于二进制JSON，这种数据空间利用率高，在写入（序列化）和读取（反序列化）方面都提供了良好的性能。
# read_clipboard 函数
#   读取剪贴板中的数据，可以看作read_table的剪贴板版本。在将网页转换为表格时很有用

# 直接用一个宽度列表，可以代替colspecs参数
widths = [6, 14, 13, 10]
df = pd.read_fwf('demo.txt', widths=widths, header=None)

# json
s = '{"index":[1,2,3],"columns":["a","b"],"data":[[1,3],[2,5],[6,9]]}'
df = pd.read_json(s, orient='split')
s = '[{"a":1,"b":2},{"a":3,"b":4}]'
df = pd.read_json(s,orient='records')
# html
df = pd.read_html("http://data.stcn.com/2019/0304/14899644.shtml",flavor ='lxml')

# ------- 更多用法 ---------
DataFrame.from_csv（path [，header，sep，…]） # 读取CSV文件（DISCOURAGED，请改用pandas.read_csv()）。 
DataFrame.from_dict（data [，orient，dtype]） # 从类array或dicts的dict构造DataFrame 
DataFrame.from_items（items [，columns，orient]） # 将（键，值）对转换为DataFrame。 
DataFrame.from_records（data [，index，…]） # 将结构化或记录ndarray转换为DataFrame 
DataFrame.info（[verbose，buf，max_cols，…]）# DataFrame的简明摘要。 
DataFrame.to_pickle（path）# Pickle（序列化）对象到输入文件路径。 
DataFrame.to_csv（[path_or_buf，sep，na_rep，…]） # 将DataFrame写入逗号分隔值（csv）文件 

# [2021-11-11] 注意：df.to_csv写入的字符串如果包含json串，结果会出现问题，所有"变成""，破坏json格式。
df = pd.DataFrame([{"test": 'id={"name":"test"}'}]) 
df.to_csv('t.txt', sep='\t') # 结果 id={""name"":""test""}
df.to_csv("test.txt", sep='|',index=False,header=True)
# 改进办法：
import csv
df.to_csv("test.csv", sep='|', quoting=csv.QUOTE_NONE, index=False, header=True)


DataFrame.to_hdf（path_or_buf，key, kwargs） # 使用HDFStore将包含的数据写入HDF5文件。 
DataFrame.to_sql（name，con [，flavor，…]） # 将存储在DataFrame中的记录写入SQL数据库。 
DataFrame.to_dict（[orient]） #将DataFrame转换成字典。 
DataFrame.to_excel（excel_writer [，…]） #将DataFrame写入excel表 
DataFrame.to_json（[path_or_buf，orient，…]） #将对象转换为JSON字符串。 
DataFrame.to_html（[buf，columns，col_space，…]） # 将DataFrame呈现为HTML表格。 
DataFrame.to_latex（[buf，columns，…]） # 将DataFrame呈现为表格环境表。 
DataFrame.to_stata（fname [，convert_dates，…]） # 从数组类对象中写入Stata二进制dta文件的类 
DataFrame.to_msgpack（[path_or_buf，encoding]） # msgpack（serialize）对象到输入文件路径 
DataFrame.to_gbq（destination_table，project_id）# 将DataFrame写入Google - BigQuery表格。 
DataFrame.to_records（[index，convert_datetime64]） # 将DataFrame转换为记录数组。 
DataFrame.to_sparse（[fill_value，kind]） # 转换为SparseDataFrame 
DataFrame.to_dense() # 返回NDFrame的密集表示（而不是稀疏） 
DataFrame.to_string（[buf，columns，…]） # 将DataFrame呈现为控制台友好的表格输出。 
DataFrame.to_clipboard（[excel，sep]）

```

```python
import xlrd
data = xlrd.open_workbook("01.xls")#打开当前目录下名为01.xls的文档
#此时data相当于指向该文件的指针
table = data.sheet_by_index(0)#通过索引获取，例如打开第一个sheet表格
table = data.sheet_by_name("sheet1")#通过名称获取，如读取sheet1表单
table = data.sheets()[0]#通过索引顺序获取
# 以上三个函数都会返回一个xlrd.sheet.Sheet()对象
 
names = data.sheet_names()    #返回book中所有工作表的名字
data.sheet_loaded(sheet_name or indx)   # 检查某个sheet是否导入完毕
# ---- 行操作 ------
nrows = table.nrows  #获取该sheet中的有效行数
table.row(rowx)  #返回由该行中所有的单元格对象组成的列表
table.row_slice(rowx)  #返回由该列中所有的单元格对象组成的列表
table.row_types(rowx, start_colx=0, end_colx=None)    #返回由该行中所有单元格的数据类型组成的列表
table.row_values(rowx, start_colx=0, end_colx=None)   #返回由该行中所有单元格的数据组成的列表
table.row_len(rowx) #返回该列的有效单元格长度
# ---- 列操作 ------
ncols = table.ncols#获取列表的有效列数
table.col(colx, start_rowx=0, end_rowx=None)#返回由该列中所有的单元格对象组成的列表
table.col_slice(colx, start_rowx=0, end_rowx=None)#返回由该列中所有的单元格对象组成的列表
table.col_types(colx, start_rowx=0, end_rowx=None)#返回由该列中所有单元格的数据类型组成的列表
table.col_values(colx, start_rowx=0, end_rowx=None)#返回由该列中所有单元格的数据组成的列表
# ---- 单元格操作 ------
table.cell(rowx, colx)  # 返回单元格对象
table.cell_type(rowx, colx)  # 返回单元格中的数据类型
table.cell_value(rowx,colx)   #返回单元格中的数据
```

### 可视化


绘图

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
a=pd.Series(np.random.randn(1000),index=pd.date_range('20100101',periods=1000))
b=a.cumsum()
b.plot()
df.plot.area() # 面积图
df.plot.bar() # 柱形图
df.plot.barh() # 水平柱形图
df.plot.density() # 密度图
df.plot.kde()
df.plot.hist() # 直方图
df.plot.scatter()
df.plot.pie()

```

表格级别美化（适用于jupyter notebook）, [官方style介绍](http://pandas.pydata.org/pandas-docs/stable/style.html)

```python
# -------- (1) -------
pd_list[pd_list['前两位']>0.5]
# 按照数值范围显示不同颜色
def showColor(val):
    color = 'red' if val <= 0 else 'green'
    return 'color:%s'%(color)
#正规方式,单独定义函数
pd_list.style.applymap(showColor)
#简洁方式,使用匿名函数,lambda
pd_list.style.applymap(lambda val: 'color:red' if val <= 1 else 'color:green')
# -------- (2) -------
# 调用seaborn的颜色主题
import seaborn as sns

cm = sns.light_palette("green", as_cmap=True)
s = df.style.background_gradient(cmap=cm)
#df.loc[:4].style.background_gradient(cmap='viridis')
s
# -----------------
import seaborn as sns
#!sudo pip install seaborn
cm = sns.light_palette("green", as_cmap=True)
#s = dh.style.background_gradient(cmap=cm)
col_list = [u'问题项名称',u'展现量41',u'流量占比',u'评价量41',u'参评率41',u'解决量41',u'解决率41']
#dh[dh[u'参评率41']>0.1, col_list]
out = dh[col_list][dh[u'参评率41']>0.05][dh[u'展现量41']> 50]
out.style.background_gradient(cmap=cm)
#out.style.background_gradient(cmap='viridis').highlight_null('red')#突出极值.highlight_max(axis=0)
#out.style.bar(subset=['A', 'B'], color='#d65f5f') # 柱状图显示
#out.style.bar(subset=['A', 'B'], align='mid', color=['#d65f5f', '#5fba7d']) # 正负双向柱状图
```



### pandasgui

【2021-9-24】一个 GUI 接口，可以帮助我们完成自动化探索性数据分析的过程，并节省时间和精力
- [一款数据探索性分析工具 Pandasgui](https://zhuanlan.zhihu.com/p/284391734)

安装Pandasgui

```python
pip install pandasgui
# 直接从 Github 安装最新的未发布更改：
pip install git+https://github.com/adamerose/pandasgui.git
```

功能：过滤、统计、绘图等
- ![](https://pic1.zhimg.com/80/v2-2c880b4f66a8f43fde97e6da9a860e54_720w.jpg)

示例

```python
from pandasgui.datasets import iris
#importing the show function
from pandasgui import show
show(iris)
# 自定义数据
import pandas as pd
from pandasgui import show
df = pd.DataFrame(([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])
show(df)
```

## Python技巧

- [30段极简Python代码：这些小技巧你都Get了吗](https://zhuanlan.zhihu.com/p/83998758)

Python 是机器学习最广泛采用的编程语言，它最重要的优势在于编程的易用性。如果读者对基本的 Python 语法已经有一些了解，那么这篇文章可能会给你一些启发。作者简单概览了 30 段代码，它们都是平常非常实用的技巧，我们只要花几分钟就能从头到尾浏览一遍。

### 1. 重复元素判定

以下方法可以检查给定列表是不是存在重复元素，它会使用 set() 函数来移除所有重复元素。

```python
def all_unique(lst):
    return len(lst) == len(set(lst))


x = [1,1,2,2,3,2,3,4,5,6]
y = [1,2,3,4,5]
all_unique(x) # False
all_unique(y) # True
```

### 2. 字符元素组成判定

检查两个字符串的组成元素是不是一样的。

```python
from collections import Counter

def anagram(first, second):
    return Counter(first) == Counter(second)

anagram("abcd3", "3acdb") # True
```

### 3. 内存占用

下面的代码块可以检查变量 variable 所占用的内存。

```python
import sys 

variable = 30 
print(sys.getsizeof(variable)) # 24
```

### 4. 字节占用

下面的代码块可以检查字符串占用的字节数。

```python
def byte_size(string):
    return(len(string.encode('utf-8')))

byte_size(' ') # 4
byte_size('Hello World') # 11  
```

### 5. 打印 N 次字符串

该代码块不需要循环语句就能打印 N 次字符串。

```python
n = 2; 
s ="Programming"; 

print(s * n);
# ProgrammingProgramming  
```

### 6. 大写第一个字母

以下代码块会使用 title() 方法，从而大写字符串中每一个单词的首字母。

```python
s = "programming is awesome"

print(s.title())
# Programming Is Awesome
```

### 7. 分块

给定具体的大小，定义一个函数以按照这个大小切割列表。

```python
from math import ceil

def chunk(lst, size):
    return list(
        map(lambda x: lst[x * size:x * size + size],
            list(range(0, ceil(len(lst) / size)))))

chunk([1,2,3,4,5],2)
# [[1,2],[3,4],5]
```

### 8. 压缩

这个方法可以将布尔型的值去掉，例如（False，None，0，“”），它使用 filter() 函数。

```python
def compact(lst):
    return list(filter(bool, lst))

compact([0, 1, False, 2, '', 3, 'a', 's', 34])
# [ 1, 2, 3, 'a', 's', 34 ]
```

### 9. 解包

如下代码段可以将打包好的成对列表解开成两组不同的元组。

```python
array = [['a', 'b'], ['c', 'd'], ['e', 'f']]
transposed = zip(*array)
print(transposed)
# [('a', 'c', 'e'), ('b', 'd', 'f')]
```

### 10. 链式对比

我们可以在一行代码中使用不同的运算符对比多个不同的元素。

```python
a = 3
print( 2 < a < 8) # True
print(1 == a < 2) # False
```

### 11. 逗号连接

下面的代码可以将列表连接成单个字符串，且每一个元素间的分隔方式设置为了逗号。

```python
hobbies = ["basketball", "football", "swimming"]

print("My hobbies are: " + ", ".join(hobbies))
# My hobbies are: basketball, football, swimming
```

### 12. 元音统计

以下方法将统计字符串中的元音 (‘a’,‘e’,‘i’,‘o’,‘u’) 的个数，它是通过正则表达式做的。

```python
import re

def count_vowels(str):
    return len(len(re.findall(r'[aeiou]', str, re.IGNORECASE)))

count_vowels('foobar') # 3
count_vowels('gym') # 0
```

### 13. 首字母小写

如下方法将令给定字符串的第一个字符统一为小写。

```python
def decapitalize(string):
    return str[:1].lower() + str[1:]

decapitalize('FooBar') # 'fooBar'
decapitalize('FooBar') # 'fooBar'
```

### 14. 展开列表

该方法将通过递归的方式将列表的嵌套展开为单个列表。

```python
def spread(arg):
    ret = []
    for i in arg:
        if isinstance(i, list):
            ret.extend(i)
        else:
            ret.append(i)
    return ret

def deep_flatten(lst):
    result = []
    result.extend(
        spread(list(map(lambda x: deep_flatten(x) if type(x) == list else x, lst))))
    return result

deep_flatten([1, [2], [[3], 4], 5]) # [1,2,3,4,5]
```

### 15. 列表的差

该方法将返回第一个列表的元素，其不在第二个列表内。如果同时要反馈第二个列表独有的元素，还需要加一句 set_b.difference(set_a)。

```python
def difference(a, b):
    set_a = set(a)
    set_b = set(b)
    comparison = set_a.difference(set_b)
    return list(comparison)


difference([1,2,3], [1,2,4]) # [3]
```

### 16. 通过函数取差

如下方法首先会应用一个给定的函数，然后再返回应用函数后结果有差别的列表元素。

```python
def difference_by(a, b, fn):
    b = set(map(fn, b))
    return [item for item in a if fn(item) not in b]


from math import floor
difference_by([2.1, 1.2], [2.3, 3.4],floor) # [1.2]
difference_by([{ 'x': 2 }, { 'x': 1 }], [{ 'x': 1 }], lambda v : v['x'])
# [ { x: 2 } ]
```

### 17. 链式函数调用

你可以在一行代码内调用多个函数。

```python
def add(a, b):
    return a + b

def subtract(a, b):
    return a - b

a, b = 4, 5
print((subtract if a > b else add)(a, b)) # 9 
```

### 18. 检查重复项

如下代码将检查两个列表是不是有重复项。

```python
def has_duplicates(lst):
    return len(lst) != len(set(lst))

x = [1,2,3,4,5,5]
y = [1,2,3,4,5]
has_duplicates(x) # True
has_duplicates(y) # False
```

### 19. 合并两个字典

下面的方法将用于合并两个字典。

```python
def merge_two_dicts(a, b):
    c = a.copy()   # make a copy of a 
    c.update(b)    # modify keys and values of a with the ones from b
    return c

a = { 'x': 1, 'y': 2}
b = { 'y': 3, 'z': 4}
print(merge_two_dicts(a, b))
# {'y': 3, 'x': 1, 'z': 4}
```

在 Python 3.5 或更高版本中，我们也可以用以下方式合并字典：

```python
def merge_dictionaries(a, b)
   return {**a, **b}

a = { 'x': 1, 'y': 2}
b = { 'y': 3, 'z': 4}
print(merge_dictionaries(a, b))
# {'y': 3, 'x': 1, 'z': 4}

```
### 20. 将两个列表转化为字典

如下方法将会把两个列表转化为单个字典。

```python
def to_dictionary(keys, values):
    return dict(zip(keys, values))


keys = ["a", "b", "c"]    
values = [2, 3, 4]
print(to_dictionary(keys, values))
# {'a': 2, 'c': 4, 'b': 3}
```

### 21. 使用枚举

我们常用 For 循环来遍历某个列表，同样我们也能枚举列表的索引与值。

```python
list = ["a", "b", "c", "d"]
for index, element in enumerate(list): 
    print("Value", element, "Index ", index, )

# ('Value', 'a', 'Index ', 0)
# ('Value', 'b', 'Index ', 1)
#('Value', 'c', 'Index ', 2)
# ('Value', 'd', 'Index ', 3)    
```

### 22. 执行时间

如下代码块可以用来计算执行特定代码所花费的时间。

```python
import time

start_time = time.time()

a = 1
b = 2
c = a + b
print(c) #3

end_time = time.time()
total_time = end_time - start_time
print("Time: ", total_time)

# ('Time: ', 1.1205673217773438e-05)  
```

### 23. Try else

我们在使用 try/except 语句的时候也可以加一个 else 子句，如果没有触发错误的话，这个子句就会被运行。

```python
try:
    2*3
except TypeError:
    print("An exception was raised")
else:
    print("Thank God, no exceptions were raised.")

#Thank God, no exceptions were raised.
```

### 24. 元素频率

下面的方法会根据元素频率取列表中最常见的元素。

```python
def most_frequent(list):
    return max(set(list), key = list.count)

list = [1,2,1,2,3,2,1,4,2]
most_frequent(list)  
```

### 25. 回文序列

以下方法会检查给定的字符串是不是回文序列，它首先会把所有字母转化为小写，并移除非英文字母符号。最后，它会对比字符串与反向字符串是否相等，相等则表示为回文序列。

```python
def palindrome(string):
    from re import sub
    s = sub('[\W_]', '', string.lower())
    return s == s[::-1]

palindrome('taco cat') # True
```

### 26. 不使用 if-else 的计算子

这一段代码可以不使用条件语句就实现加减乘除、求幂操作，它通过字典这一数据结构实现：

```python
import operator
action = {
    "+": operator.add,
    "-": operator.sub,
    "/": operator.truediv,
    "*": operator.mul,
    "**": pow
}
print(action['-'](50, 25)) # 25
```

### 27. Shuffle

该算法会打乱列表元素的顺序，它主要会通过 Fisher-Yates 算法对新列表进行排序：

```python
from copy import deepcopy
from random import randint

def shuffle(lst):
    temp_lst = deepcopy(lst)
    m = len(temp_lst)
    while (m):
        m -= 1
        i = randint(0, m)
        temp_lst[m], temp_lst[i] = temp_lst[i], temp_lst[m]
    return temp_lst

foo = [1,2,3]
shuffle(foo) # [2,3,1] , foo = [1,2,3]
```

### 28. 展开列表

将列表内的所有元素，包括子列表，都展开成一个列表。

```python
def spread(arg):
    ret = []
    for i in arg:
        if isinstance(i, list):
            ret.extend(i)
        else:
            ret.append(i)
    return ret

spread([1,2,3,[4,5,6],[7],8,9]) # [1,2,3,4,5,6,7,8,9]
```

### 29. 交换值

不需要额外的操作就能交换两个变量的值。

```python
def swap(a, b):
  return b, a

a, b = -1, 14
swap(a, b) # (14, -1)
spread([1,2,3,[4,5,6],[7],8,9]) # [1,2,3,4,5,6,7,8,9]
```

### 30. 字典默认值

通过 Key 取对应的 Value 值，可以通过以下方式设置默认值。如果 get() 方法没有设置默认值，那么如果遇到不存在的 Key，则会返回 None。

```python
d = {'a': 1, 'b': 2}
print(d.get('c', 3)) # 3
```

# 设计模式

[二十三种设计模式及其python实现](https://www.cnblogs.com/Liqiongyu/p/5916710.html)

本文源码寄方于[github](https://github.com/w392807287/Design_pattern_of_python)

参考文献：
- 《大话设计模式》——吴强
- 《Python设计模式》——pythontip.com
- 《23种设计模式》——http://www.cnblogs.com/beijiguangyong/

设计模式是经过总结、优化的，针对一些编程问题的**可重用**解决方案。设计模式不像**类**或**库**那样能够直接作用于代码，设计模式更为高级，是一种必须在特定情形下实现的一种**方法模板**。设计模式不会绑定具体的编程语言。
- 好的设计模式应该能够用大部分编程语言实现(如果做不到全部的话，具体取决于语言特性)。
- 设计模式也是一把双刃剑，如果用在不恰当的情形下将会造成灾难，进而带来无穷的麻烦。然而如果设计模式在正确的时间被用在正确地地方，它将是你的救星。

“模式”就是为了解决一类特定问题而特别想出来的明智之举。

虽然被称为“设计模式”，但是它们同“设计“领域并非紧密联系。设计模式同传统意义上的分析、设计与实现不同，事实上设计模式将一个完整的理念根植于程序中，所以它可能出现在分析阶段或是更高层的设计阶段。很有趣的是因为设计模式的具体体现是程序代码，因此可能会让你认为它不会在具体实现阶段之前出现(事实上在进入具体实现阶段之前你都没有意识到正在使用具体的设计模式)。

可以通过程序设计的基本概念来理解模式：增加一个抽象层。抽象一个事物就是隔离任何具体细节，这么做的目的是为了将那些不变的核心部分从其他细节中分离出来。当你发现你程序中的某些部分经常因为某些原因改动，而你不想让这些改动的部分引发其他部分的改动，这时候你就需要思考那些不会变动的设计方法了。这么做不仅会使代码可维护性更高，而且会让代码更易于理解，从而降低开发成本。

三种最基本的设计模式：
- **创建**模式，提供实例化的方法，为适合的状况提供相应的对象创建方法。
- **结构化**模式，通常用来处理实体之间的关系，使得这些实体能够更好地协同工作。
- **行为**模式，用于在不同的实体建进行通信，为实体之间的通信提供更容易，更灵活的通信方法。

## 创建型

1. Factory Method（工厂方法）
2. Abstract Factory（抽象工厂）
3. Builder（建造者）
4. Prototype（原型）
5. Singleton（单例）

### Factory Method（工厂方法）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160928141135485-1986044710.gif)

意图：
- 定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method 使一个**类的实例化延迟到其子类**。

适用性：
- 当一个类不知道它所必须创建的对象的类的时候。
- 当一个类希望由它的子类来指定它所创建的对象的时候。
- 当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪一个帮助子类是代理者这一信息局部化的时候。

```python
#!/usr/bin/python
#coding:utf8
'''
Factory Method
'''

class ChinaGetter:
    """A simple localizer a la gettext"""
    def __init__(self):
        self.trans = dict(dog=u"小狗", cat=u"小猫")
 
    def get(self, msgid):
        """We'll punt if we don't have a translation"""
        try:
            return self.trans[msgid]
        except KeyError:
            return str(msgid)

class EnglishGetter:
    """Simply echoes the msg ids"""
    def get(self, msgid):
        return str(msgid)

def get_localizer(language="English"):
    """The factory method"""
    languages = dict(English=EnglishGetter, China=ChinaGetter)
    return languages[language]()
 
# Create our localizers
e, g = get_localizer("English"), get_localizer("China")
# Localize some text
for msgid in "dog parrot cat bear".split():
    print(e.get(msgid), g.get(msgid))
```

### Abstract Factory（抽象工厂）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160928181031672-1073974804.gif)

意图：
- 提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 
适用性：
- 一个系统要独立于它的产品的创建、组合和表示时。
- 一个系统要由多个产品系列中的一个来配置时。
- 当要强调一系列相关的产品对象的设计以便进行联合使用时。
- 当提供一个产品类库，而只想显示它们的接口而不是实现时。

```python
#!/usr/bin/python
#coding:utf8
'''
Abstract Factory
'''

import random
 
class PetShop:
    """A pet shop"""
 
    def __init__(self, animal_factory=None):
        """pet_factory is our abstract factory. We can set it at will."""
 
        self.pet_factory = animal_factory
 
    def show_pet(self):
        """Creates and shows a pet using the abstract factory"""
 
        pet = self.pet_factory.get_pet()
        print("This is a lovely", str(pet))
        print("It says", pet.speak())
        print("It eats", self.pet_factory.get_food())

# Stuff that our factory makes
class Dog:
    def speak(self):
        return "woof"
 
    def __str__(self):
        return "Dog"

class Cat:
    def speak(self):
        return "meow"
 
    def __str__(self):
        return "Cat"

# Factory classes
 
class DogFactory:
    def get_pet(self):
        return Dog()
 
    def get_food(self):
        return "dog food"

class CatFactory:
    def get_pet(self):
        return Cat()
 
    def get_food(self):
        return "cat food"

# Create the proper family
def get_factory():
    """Let's be dynamic!"""
    return random.choice([DogFactory, CatFactory])()
 
# Show pets with various factories
if __name__ == "__main__":
    shop = PetShop()
    for i in range(3):
        shop.pet_factory = get_factory()
        shop.show_pet()
        print("=" * 20)
```

###  Builder（建造者）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160928195334656-2085921203.gif)

意图：
- 将一个复杂对象的**构建**与它的**表示**分离，使得同样的构建过程可以创建不同的表示。

适用性：
- 当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时。
- 当构造过程必须允许被构造的对象有不同的表示时。

```python
#!/usr/bin/python
#coding:utf8
 
"""
    Builder
"""
 
# Director
class Director(object):
    def __init__(self):
        self.builder = None
 
    def construct_building(self):
        self.builder.new_building()
        self.builder.build_floor()
        self.builder.build_size()
 
    def get_building(self):
        return self.builder.building

# Abstract Builder
class Builder(object):
    def __init__(self):
        self.building = None
 
    def new_building(self):
        self.building = Building()
 
# Concrete Builder
class BuilderHouse(Builder):
    def build_floor(self):
        self.building.floor = 'One'
 
    def build_size(self):
        self.building.size = 'Big'

class BuilderFlat(Builder):
    def build_floor(self):
        self.building.floor = 'More than One'
 
    def build_size(self):
        self.building.size = 'Small'
 
# Product
class Building(object):
    def __init__(self):
        self.floor = None
        self.size = None
 
    def __repr__(self):
        return 'Floor: %s | Size: %s' % (self.floor, self.size)
 
# Client
if __name__ == "__main__":
    director = Director()
    director.builder = BuilderHouse()
    director.construct_building()
    building = director.get_building()
    print(building)
    director.builder = BuilderFlat()
    director.construct_building()
    building = director.get_building()
    print(building)
```

### Prototype（原型）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160928194103188-1537654983.gif)

意图：
- 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。

适用性：
- 当要实例化的类是在运行时刻指定时，例如，通过动态装载；或者为了避免创建一个与产品类层次平行的工厂类层次时；或者当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。

```python
#!/usr/bin/python
#coding:utf8
'''
Prototype
'''

import copy
 
class Prototype:
    def __init__(self):
        self._objects = {}
 
    def register_object(self, name, obj):
        """Register an object"""
        self._objects[name] = obj
 
    def unregister_object(self, name):
        """Unregister an object"""
        del self._objects[name]
 
    def clone(self, name, **attr):
        """Clone a registered object and update inner attributes dictionary"""
        obj = copy.deepcopy(self._objects.get(name))
        obj.__dict__.update(attr)
        return obj

def main():
    class A:
        def __str__(self):
            return "I am A"
 
    a = A()
    prototype = Prototype()
    prototype.register_object('a', a)
    b = prototype.clone('a', a=1, b=2, c=3)
 
    print(a)
    print(b.a, b.b, b.c)
 
 
if __name__ == '__main__':
    main()
```

### Singleton（单例）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160928194345281-610274391.gif)

意图：
- 保证一个类仅有一个实例，并提供一个访问它的全局访问点。

适用性：
- 当类只能有一个实例而且客户可以从一个众所周知的访问点访问它时。
- 当这个唯一实例应该是通过子类化可扩展的，并且客户应该无需更改代码就能使用一个扩展的实例时。

```python
#!/usr/bin/python
#coding:utf8
'''
Singleton
'''
 
class Singleton(object):
    ''''' A python style singleton '''
 
    def __new__(cls, *args, **kw):
        if not hasattr(cls, '_instance'):
            org = super(Singleton, cls)
            cls._instance = org.__new__(cls, *args, **kw)
        return cls._instance
 
 
if __name__ == '__main__':
    class SingleSpam(Singleton):
        def __init__(self, s):
            self.s = s
 
        def __str__(self):
            return self.s
 
 
    s1 = SingleSpam('spam')
    print id(s1), s1
    s2 = SingleSpam('spa')
    print id(s2), s2
    print id(s1), s1
```


## 结构型

### Adapter Class/Object（适配器）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160930081507250-268482079.gif)

意图：
- 将一个类的接口转换成客户希望的另外一个接口。Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 

适用性：
- 你想使用一个已经存在的类，而它的接口不符合你的需求。
- 你想创建一个可以复用的类，该类可以与其他不相关的类或不可预见的类（即那些接口可能不一定兼容的类）协同工作。
- （仅适用于对象Adapter ）你想使用一些已经存在的子类，但是不可能对每一个都进行子类化以匹配它们的接口。对象适配器可以适配它的父类接口。

```python
#!/usr/bin/python
#coding:utf8
'''
Adapter
'''
 
import os
 
 
class Dog(object):
    def __init__(self):
        self.name = "Dog"
 
    def bark(self):
        return "woof!"
 
 
class Cat(object):
    def __init__(self):
        self.name = "Cat"
 
    def meow(self):
        return "meow!"
 
 
class Human(object):
    def __init__(self):
        self.name = "Human"
 
    def speak(self):
        return "'hello'"

class Car(object):
    def __init__(self):
        self.name = "Car"
 
    def make_noise(self, octane_level):
        return "vroom%s" % ("!" * octane_level)

class Adapter(object):
    """
    Adapts an object by replacing methods.
    Usage:
    dog = Dog
    dog = Adapter(dog, dict(make_noise=dog.bark))
    """
    def __init__(self, obj, adapted_methods):
        """We set the adapted methods in the object's dict"""
        self.obj = obj
        self.__dict__.update(adapted_methods)
 
    def __getattr__(self, attr):
        """All non-adapted calls are passed to the object"""
        return getattr(self.obj, attr)

def main():
    objects = []
    dog = Dog()
    objects.append(Adapter(dog, dict(make_noise=dog.bark)))
    cat = Cat()
    objects.append(Adapter(cat, dict(make_noise=cat.meow)))
    human = Human()
    objects.append(Adapter(human, dict(make_noise=human.speak)))
    car = Car()
    car_noise = lambda: car.make_noise(3)
    objects.append(Adapter(car, dict(make_noise=car_noise)))
 
    for obj in objects:
        print "A", obj.name, "goes", obj.make_noise()
 
 
if __name__ == "__main__":
    main()
```

### Bridge（桥接）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160930082905203-1507021924.gif)

意图：
- 将抽象部分与它的实现部分分离，使它们都可以独立地变化。

适用性：
- 你不希望在抽象和它的实现部分之间有一个固定的绑定关系。例如这种情况可能是因为，在程序运行时刻实现部分应可以被选择或者切换。
- 类的抽象以及它的实现都应该可以通过生成子类的方法加以扩充。这时Bridge 模式使你可以对不同的抽象接口和实现部分进行组合，并分别对它们进行扩充。
- 对一个抽象的实现部分的修改应对客户不产生影响，即客户的代码不必重新编译。
- （C++）你想对客户完全隐藏抽象的实现部分。在C++中，类的表示在类接口中是可见的。
- 有许多类要生成。这样一种类层次结构说明你必须将一个对象分解成两个部分。Rumbaugh 称这种类层次结构为“嵌套的普化”（nested generalizations ）。
- 你想在多个对象间共享实现（可能使用引用计数），但同时要求客户并不知道这一点。一个简单的例子便是Coplien 的String 类[ Cop92 ]，在这个类中多个对象可以共享同一个字符串表示（StringRep）。

```python
#!/usr/bin/python
#coding:utf8
'''
Bridge
'''

# ConcreteImplementor 1/2
class DrawingAPI1(object):
    def draw_circle(self, x, y, radius):
        print('API1.circle at {}:{} radius {}'.format(x, y, radius))
 
 
# ConcreteImplementor 2/2
class DrawingAPI2(object):
    def draw_circle(self, x, y, radius):
        print('API2.circle at {}:{} radius {}'.format(x, y, radius))
 
 
# Refined Abstraction
class CircleShape(object):
    def __init__(self, x, y, radius, drawing_api):
        self._x = x
        self._y = y
        self._radius = radius
        self._drawing_api = drawing_api
 
    # low-level i.e. Implementation specific
    def draw(self):
        self._drawing_api.draw_circle(self._x, self._y, self._radius)
 
    # high-level i.e. Abstraction specific
    def scale(self, pct):
        self._radius *= pct
 
 
def main():
    shapes = (
        CircleShape(1, 2, 3, DrawingAPI1()),
        CircleShape(5, 7, 11, DrawingAPI2())
    )
 
    for shape in shapes:
        shape.scale(2.5)
        shape.draw()
 
 
if __name__ == '__main__':
    main()
```


###  Composite（组合）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160930112848610-861983607.gif)

意图：
- 将对象组合成树形结构以表示“部分-整体”的层次结构。C o m p o s i t e 使得用户对单个对象和组合对象的使用具有一致性。 

适用性：
- 你想表示对象的部分-整体层次结构。
- 你希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。

```python
#!/usr/bin/python
#coding:utf8
 
"""
Composite
"""
 
class Component:
    def __init__(self,strName):
        self.m_strName = strName
    def Add(self,com):
        pass
    def Display(self,nDepth):
        pass
 
class Leaf(Component):
    def Add(self,com):
        print "leaf can't add"
    def Display(self,nDepth):
        strtemp = "-" * nDepth
        strtemp=strtemp+self.m_strName
        print strtemp
 
class Composite(Component):
    def __init__(self,strName):
        self.m_strName = strName
        self.c = []
    def Add(self,com):
        self.c.append(com)
    def Display(self,nDepth):
        strtemp = "-"*nDepth
        strtemp=strtemp+self.m_strName
        print strtemp
        for com in self.c:
            com.Display(nDepth+2)
 
if __name__ == "__main__":
    p = Composite("Wong")
    p.Add(Leaf("Lee"))
    p.Add(Leaf("Zhao"))
    p1 = Composite("Wu")
    p1.Add(Leaf("San"))
    p.Add(p1)
    p.Display(1);
```


###  Decorator（装饰）

![](https://images2015.cnblogs.com/blog/824579/201609/824579-20160930115007891-1984670176.gif)

意图： 
- 动态地给一个对象添加一些额外的职责。就增加功能来说，Decorator 模式相比生成子类更为灵活。 
适用性：
- 在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。
- 处理那些可以撤消的职责。
- 当不能采用生成子类的方法进行扩充时。一种情况是，可能有大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长。另一种情况可能是因为类定义被隐藏，或类定义不能用于生成子类。

```python
#!/usr/bin/python
#coding:utf8
'''
Decorator
'''
 
class foo(object):
    def f1(self):
        print("original f1")
 
    def f2(self):
        print("original f2")
 
 
class foo_decorator(object):
    def __init__(self, decoratee):
        self._decoratee = decoratee
 
    def f1(self):
        print("decorated f1")
        self._decoratee.f1()
 
    def __getattr__(self, name):
        return getattr(self._decoratee, name)
 
u = foo()
v = foo_decorator(u)
v.f1()
v.f2()
```

###  Facade（外观）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001085208891-1109181708.gif)

意图：
- 为子系统中的一组接口提供一个一致的界面，Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。

适用性：
- 当你要为一个复杂子系统提供一个简单接口时。子系统往往因为不断演化而变得越来越复杂。大多数模式使用时都会产生更多更小的类。这使得子系统更具可重用性，也更容易对子系统进行定制，但这也给那些不需要定制子系统的用户带来一些使用上的困难。Facade 可以提供一个简单的缺省视图，这一视图对大多数用户来说已经足够，而那些需要更多的可定制性的用户可以越过facade层。
- 客户程序与抽象类的实现部分之间存在着很大的依赖性。引入facade 将这个子系统与客户以及其他的子系统分离，可以提高子系统的独立性和可移植性。
- 当你需要构建一个层次结构的子系统时，使用facade模式定义子系统中每层的入口点。如果子系统之间是相互依赖的，你可以让它们仅通过facade进行通讯，从而简化了它们之间的依赖关系。

```python
#!/usr/bin/python
#coding:utf8
'''
Decorator
'''
import time
 
SLEEP = 0.5
 
# Complex Parts
class TC1:
    def run(self):
        print("###### In Test 1 ######")
        time.sleep(SLEEP)
        print("Setting up")
        time.sleep(SLEEP)
        print("Running test")
        time.sleep(SLEEP)
        print("Tearing down")
        time.sleep(SLEEP)
        print("Test Finished\n")
 
 
class TC2:
    def run(self):
        print("###### In Test 2 ######")
        time.sleep(SLEEP)
        print("Setting up")
        time.sleep(SLEEP)
        print("Running test")
        time.sleep(SLEEP)
        print("Tearing down")
        time.sleep(SLEEP)
        print("Test Finished\n")

class TC3:
    def run(self):
        print("###### In Test 3 ######")
        time.sleep(SLEEP)
        print("Setting up")
        time.sleep(SLEEP)
        print("Running test")
        time.sleep(SLEEP)
        print("Tearing down")
        time.sleep(SLEEP)
        print("Test Finished\n")

# Facade
class TestRunner:
    def __init__(self):
        self.tc1 = TC1()
        self.tc2 = TC2()
        self.tc3 = TC3()
        self.tests = [i for i in (self.tc1, self.tc2, self.tc3)]
 
    def runAll(self):
        [i.run() for i in self.tests]
 
# Client
if __name__ == '__main__':
    testrunner = TestRunner()
    testrunner.runAll()
```


###  Flyweight（享元）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001085622719-40480507.gif)

意图：
- 运用共享技术有效地支持大量细粒度的对象。

适用性：
- 一个应用程序使用了大量的对象。
- 完全由于使用大量的对象，造成很大的存储开销。
- 对象的大多数状态都可变为外部状态。
- 如果删除对象的外部状态，那么可以用相对较少的共享对象取代很多组对象。 
- 应用程序不依赖于对象标识。由于Flyweight 对象可以被共享，对于概念上明显有别的对象，标识测试将返回真值。

```python
#!/usr/bin/python
#coding:utf8
'''
Flyweight
'''
 
import weakref 
 
 
class Card(object):
    """The object pool. Has builtin reference counting"""
    _CardPool = weakref.WeakValueDictionary()
 
    """Flyweight implementation. If the object exists in the
    pool just return it (instead of creating a new one)"""
    def __new__(cls, value, suit):        
        obj = Card._CardPool.get(value + suit, None)        
        if not obj:            
            obj = object.__new__(cls)            
            Card._CardPool[value + suit] = obj            
            obj.value, obj.suit = value, suit         
        return obj
 
    # def __init__(self, value, suit):        
    #     self.value, self.suit = value, suit     
 
    def __repr__(self):        
        return "<Card: %s%s>" % (self.value, self.suit)     
 
 
if __name__ == '__main__':
    # comment __new__ and uncomment __init__ to see the difference
    c1 = Card('9', 'h')
    c2 = Card('9', 'h')
    print(c1, c2)
    print(c1 == c2)
    print(id(c1), id(c2))
```

###  Proxy（代理）

意图：
- 为其他对象提供一种代理以控制对这个对象的访问。
适用性：
- 在需要用比较通用和复杂的对象指针代替简单的指针的时候，使用Proxy模式。下面是一 些可以使用Proxy 模式常见情况： 
  - 1) 远程代理（Remote Proxy ）为一个对象在不同的地址空间提供局部代表。 NEXTSTEP[Add94] 使用NXProxy 类实现了这一目的。Coplien[Cop92] 称这种代理为“大使” （Ambassador ）。 
  - 2) 虚代理（Virtual Proxy ）根据需要创建开销很大的对象。在动机一节描述的ImageProxy 就是这样一种代理的例子。 
  - 3) 保护代理（Protection Proxy ）控制对原始对象的访问。保护代理用于对象应该有不同 的访问权限的时候。例如，在Choices 操作系统[ CIRM93]中KemelProxies为操作系统对象提供 了访问保护。 
  - 4) 智能指引（Smart Reference ）取代了简单的指针，它在访问对象时执行一些附加操作。 它的典型用途包括：对指向实际对象的引用计数，这样当该对象没有引用时，可以自动释放它(也称为SmartPointers[Ede92 ] )。
- 当第一次引用一个持久对象时，将它装入内存。
- 在访问一个实际对象前，检查是否已经锁定了它，以确保其他对象不能改变它。

```python
#!/usr/bin/python
#coding:utf8
'''
Proxy
'''
 
import time
 
class SalesManager:
    def work(self):
        print("Sales Manager working...")
 
    def talk(self):
        print("Sales Manager ready to talk")
 
class Proxy:
    def __init__(self):
        self.busy = 'No'
        self.sales = None
 
    def work(self):
        print("Proxy checking for Sales Manager availability")
        if self.busy == 'No':
            self.sales = SalesManager()
            time.sleep(2)
            self.sales.talk()
        else:
            time.sleep(2)
            print("Sales Manager is busy")

if __name__ == '__main__':
    p = Proxy()
    p.work()
    p.busy = 'Yes'
    p.work()
```


## 行为型

### Interpreter（解释器）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001090812703-551743707.gif)

意图：
- 给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。

适用性：
- 当有一个语言需要解释执行, 并且你可将该语言中的句子表示为一个抽象语法树时，可使用解释器模式。而当存在以下情况时该模式效果最好：
- 该文法简单对于复杂的文法, 文法的类层次变得庞大而无法管理。此时语法分析程序生成器这样的工具是更好的选择。它们无需构建抽象语法树即可解释表达式, 这样可以节省空间而且还可能节省时间。
- 效率不是一个关键问题最高效的解释器通常不是通过直接解释语法分析树实现的, 而是首先将它们转换成另一种形式。例如，正则表达式通常被转换成状态机。但即使在这种情况下, 转换器仍可用解释器模式实现, 该模式仍是有用的。

```python
#!/usr/bin/python
#coding:utf8
'''
Interpreter
'''
 
class Context:
    def __init__(self):
        self.input=""
        self.output=""
 
class AbstractExpression:
    def Interpret(self,context):
        pass
 
class Expression(AbstractExpression):
    def Interpret(self,context):
        print "terminal interpret"
 
class NonterminalExpression(AbstractExpression):
    def Interpret(self,context):
        print "Nonterminal interpret"
 
if __name__ == "__main__":
    context= ""
    c = []
    c = c + [Expression()]
    c = c + [NonterminalExpression()]
    c = c + [Expression()]
    c = c + [Expression()]
    for a in c:
        a.Interpret(context)
```

### Template Method（模板方法）

意图：
- 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。TemplateMethod 使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。

适用性：
- 一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现。
- 各子类中公共的行为应被提取出来并集中到一个公共父类中以避免代码重复。这是Opdyke 和Johnson所描述过的“重分解以一般化”的一个很好的例子[ OJ93 ]。首先识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。
- 控制子类扩展。模板方法只在特定点调用“hook ”操作（参见效果一节），这样就只允许在这些点进行扩展。

```python
#!/usr/bin/python
#coding:utf8
'''
Template Method
'''
 
ingredients = "spam eggs apple"
line = '-' * 10
 
# Skeletons
def iter_elements(getter, action):    
    """Template skeleton that iterates items"""     
    for element in getter():        
        action(element)    
        print(line) 
 
def rev_elements(getter, action):
    """Template skeleton that iterates items in reverse order"""     
    for element in getter()[::-1]:        
        action(element)    
        print(line) 
 
# Getters
def get_list():    
    return ingredients.split() 
 
def get_lists():
    return [list(x) for x in ingredients.split()] 
 
# Actions
def print_item(item):    
    print(item) 
 
def reverse_item(item):
    print(item[::-1]) 
 
# Makes templates
def make_template(skeleton, getter, action):    
    """Instantiate a template method with getter and action"""    
    def template():        
        skeleton(getter, action)    
    return template 
 
# Create our template functions
templates = [make_template(s, g, a)             
             for g in (get_list, get_lists)             
             for a in (print_item, reverse_item)             
             for s in (iter_elements, rev_elements)] 
 
# Execute them
for template in templates:    
    template()
```

### Chain of Responsibility（责任链）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001092311094-692760233.gif)

意图：
- 使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。

适用性：
- 有多个的对象可以处理一个请求，哪个对象处理该请求运行时刻自动确定。
- 你想在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。
- 可处理一个请求的对象集合应被动态指定。

```python
#!/usr/bin/python
#coding:utf8
 
"""
Chain
"""
class Handler:
    def successor(self, successor):
        self.successor = successor
 
class ConcreteHandler1(Handler):
    def handle(self, request):
        if request > 0 and request <= 10:
            print("in handler1")
        else:
            self.successor.handle(request)
 
class ConcreteHandler2(Handler):
    def handle(self, request):
        if request > 10 and request <= 20:
            print("in handler2")
        else:
            self.successor.handle(request)
 
class ConcreteHandler3(Handler):
    def handle(self, request):
        if request > 20 and request <= 30:
            print("in handler3")
        else:
            print('end of chain, no handler for {}'.format(request))
 
class Client:
    def __init__(self):
        h1 = ConcreteHandler1()
        h2 = ConcreteHandler2()
        h3 = ConcreteHandler3()
 
        h1.successor(h2)
        h2.successor(h3)
 
        requests = [2, 5, 14, 22, 18, 3, 35, 27, 20]
        for request in requests:
            h1.handle(request)
 
if __name__ == "__main__":
    client = Client()
```


### Command（命令）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001093244063-1060485648.gif)

意图：
- 将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可撤消的操作。

适用性：
- 抽象出待执行的动作以参数化某对象，你可用过程语言中的回调（call back）函数表达这种参数化机制。所谓回调函数是指函数先在某处注册，而它将在稍后某个需要的时候被调用。Command 模式是回调机制的一个面向对象的替代品。
- 在不同的时刻指定、排列和执行请求。一个Command对象可以有一个与初始请求无关的生存期。如果一个请求的接收者可用一种与地址空间无关的方式表达，那么就可将负责该请求的命令对象传送给另一个不同的进程并在那儿实现该请求。
- 支持取消操作。Command的Excute 操作可在实施操作前将状态存储起来，在取消操作时这个状态用来消除该操作的影响。Command 接口必须添加一个Unexecute操作，该操作取消上一次Execute调用的效果。执行的命令被存储在一个历史列表中。可通过向后和向前遍历这一列表并分别调用Unexecute和Execute来实现重数不限的“取消”和“重做”。
- 支持修改日志，这样当系统崩溃时，这些修改可以被重做一遍。在Command接口中添加装载操作和存储操作，可以用来保持变动的一个一致的修改日志。从崩溃中恢复的过程包括从磁盘中重新读入记录下来的命令并用Execute操作重新执行它们。
- 用构建在原语操作上的高层操作构造一个系统。这样一种结构在支持事务( transaction)的信息系统中很常见。一个事务封装了对数据的一组变动。Command模式提供了对事务进行建模的方法。Command有一个公共的接口，使得你可以用同一种方式调用所有的事务。同时使用该模式也易于添加新事务以扩展系统。

```python
#!/usr/bin/python
#coding:utf8
 
"""
Command
"""
import os
 
class MoveFileCommand(object):
    def __init__(self, src, dest):
        self.src = src
        self.dest = dest
 
    def execute(self):
        self()
 
    def __call__(self):
        print('renaming {} to {}'.format(self.src, self.dest))
        os.rename(self.src, self.dest)
 
    def undo(self):
        print('renaming {} to {}'.format(self.dest, self.src))
        os.rename(self.dest, self.src)
 
 
if __name__ == "__main__":
    command_stack = []
 
    # commands are just pushed into the command stack
    command_stack.append(MoveFileCommand('foo.txt', 'bar.txt'))
    command_stack.append(MoveFileCommand('bar.txt', 'baz.txt'))
 
    # they can be executed later on
    for cmd in command_stack:
        cmd.execute()
 
    # and can also be undone at will
    for cmd in reversed(command_stack):
        cmd.undo()
```

### Iterator（迭代器）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001094329172-309095903.gif)

意图：
- 提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。

适用性：
- 访问一个聚合对象的内容而无需暴露它的内部表示。
- 支持对聚合对象的多种遍历。
- 为遍历不同的聚合结构提供一个统一的接口(即, 支持多态迭代)。

```python
#!/usr/bin/python
#coding:utf8
'''
Interator
'''
def count_to(count):
    """Counts by word numbers, up to a maximum of five"""
    numbers = ["one", "two", "three", "four", "five"]
    # enumerate() returns a tuple containing a count (from start which
    # defaults to 0) and the values obtained from iterating over sequence
    for pos, number in zip(range(count), numbers):
        yield number
 
# Test the generator
count_to_two = lambda: count_to(2)
count_to_five = lambda: count_to(5)
 
print('Counting to two...')
for number in count_to_two():
    print number
 
print " "
 
print('Counting to five...')
for number in count_to_five():
    print number
 
print " "
```

### Mediator（中介者）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001094749000-380429958.gif)

意图：
- 用一个中介对象来封装一系列的对象交互。中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。

适用性：
- 一组对象以定义良好但是复杂的方式进行通信。产生的相互依赖关系结构混乱且难以理解。
- 一个对象引用其他很多对象并且直接与这些对象通信,导致难以复用该对象。
- 想定制一个分布在多个类中的行为，而又不想生成太多的子类。

```python
#!/usr/bin/python
#coding:utf8
'''
Mediator
'''
"""http://dpip.testingperspective.com/?p=28"""
 
import time
 
class TC:
    def __init__(self):
        self._tm = tm
        self._bProblem = 0
 
    def setup(self):
        print("Setting up the Test")
        time.sleep(1)
        self._tm.prepareReporting()
 
    def execute(self):
        if not self._bProblem:
            print("Executing the test")
            time.sleep(1)
        else:
            print("Problem in setup. Test not executed.")
 
    def tearDown(self):
        if not self._bProblem:
            print("Tearing down")
            time.sleep(1)
            self._tm.publishReport()
        else:
            print("Test not executed. No tear down required.")
 
    def setTM(self, TM):
        self._tm = tm
 
    def setProblem(self, value):
        self._bProblem = value
 
class Reporter:
    def __init__(self):
        self._tm = None
 
    def prepare(self):
        print("Reporter Class is preparing to report the results")
        time.sleep(1)
 
    def report(self):
        print("Reporting the results of Test")
        time.sleep(1)
 
    def setTM(self, TM):
        self._tm = tm
 
class DB:
    def __init__(self):
        self._tm = None
 
    def insert(self):
        print("Inserting the execution begin status in the Database")
        time.sleep(1)
        #Following code is to simulate a communication from DB to TC
        import random
        if random.randrange(1, 4) == 3:
            return -1
 
    def update(self):
        print("Updating the test results in Database")
        time.sleep(1)
 
    def setTM(self, TM):
        self._tm = tm
 
class TestManager:
    def __init__(self):
        self._reporter = None
        self._db = None
        self._tc = None
 
    def prepareReporting(self):
        rvalue = self._db.insert()
        if rvalue == -1:
            self._tc.setProblem(1)
            self._reporter.prepare()
 
    def setReporter(self, reporter):
        self._reporter = reporter
 
    def setDB(self, db):
        self._db = db
 
    def publishReport(self):
        self._db.update()
        rvalue = self._reporter.report()
 
    def setTC(self, tc):
        self._tc = tc
 
 
if __name__ == '__main__':
    reporter = Reporter()
    db = DB()
    tm = TestManager()
    tm.setReporter(reporter)
    tm.setDB(db)
    reporter.setTM(tm)
    db.setTM(tm)
    # For simplification we are looping on the same test.
    # Practically, it could be about various unique test classes and their
    # objects
    while (True):
        tc = TC()
        tc.setTM(tm)
        tm.setTC(tc)
        tc.setup()
        tc.execute()
        tc.tearDown()
```

### Memento（备忘录）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001095443000-87266383.gif)

意图：
- 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。

适用性：
- 必须保存一个对象在某一个时刻的(部分)状态, 这样以后需要时它才能恢复到先前的状态。
- 如果一个用接口来让其它对象直接得到这些状态，将会暴露对象的实现细节并破坏对象的封装性。

```python
#!/usr/bin/python
#coding:utf8
'''
Memento
'''
 
import copy
 
def Memento(obj, deep=False):
    state = (copy.copy, copy.deepcopy)[bool(deep)](obj.__dict__)
 
    def Restore():
        obj.__dict__.clear()
        obj.__dict__.update(state)
    return Restore
 
class Transaction:
    """A transaction guard. This is really just
      syntactic suggar arount a memento closure.
      """
    deep = False
 
    def __init__(self, *targets):
        self.targets = targets
        self.Commit()
 
    def Commit(self):
        self.states = [Memento(target, self.deep) for target in self.targets]
 
    def Rollback(self):
        for st in self.states:
            st()
 
class transactional(object):
    """Adds transactional semantics to methods. Methods decorated  with
    @transactional will rollback to entry state upon exceptions.
    """
    def __init__(self, method):
        self.method = method
 
    def __get__(self, obj, T):
        def transaction(*args, **kwargs):
            state = Memento(obj)
            try:
                return self.method(obj, *args, **kwargs)
            except:
                state()
                raise
        return transaction
 
class NumObj(object):
    def __init__(self, value):
        self.value = value
 
    def __repr__(self):
        return '<%s: %r>' % (self.__class__.__name__, self.value)
 
    def Increment(self):
        self.value += 1
 
    @transactional
    def DoStuff(self):
        self.value = '1111'  # <- invalid value
        self.Increment()     # <- will fail and rollback
 
if __name__ == '__main__':
    n = NumObj(-1)
    print(n)
    t = Transaction(n)
    try:
        for i in range(3):
            n.Increment()
            print(n)
        t.Commit()
        print('-- commited')
        for i in range(3):
            n.Increment()
            print(n)
        n.value += 'x'  # will fail
        print(n)
    except:
        t.Rollback()
        print('-- rolled back')
    print(n)
    print('-- now doing stuff ...')
    try:
        n.DoStuff()
    except:
        print('-> doing stuff failed!')
        import traceback
        traceback.print_exc(0)
        pass
    print(n)
```

### Observer（观察者）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001095725391-893775521.gif)

意图：
- 定义对象间的一种一对多的依赖关系,当一个对象的状态发生改变时, 所有依赖于它的对象都得到通知并被自动更新。

适用性：
- 当一个抽象模型有两个方面, 其中一个方面依赖于另一方面。将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。
- 当对一个对象的改变需要同时改变其它对象, 而不知道具体有多少对象有待改变。
- 当一个对象必须通知其它对象，而它又不能假定其它对象是谁。换言之, 你不希望这些对象是紧密耦合的。

```python
#!/usr/bin/python
#coding:utf8
'''
Observer
'''
 
 
class Subject(object):
    def __init__(self):
        self._observers = []
 
    def attach(self, observer):
        if not observer in self._observers:
            self._observers.append(observer)
 
    def detach(self, observer):
        try:
            self._observers.remove(observer)
        except ValueError:
            pass
 
    def notify(self, modifier=None):
        for observer in self._observers:
            if modifier != observer:
                observer.update(self)
 
# Example usage
class Data(Subject):
    def __init__(self, name=''):
        Subject.__init__(self)
        self.name = name
        self._data = 0
 
    @property
    def data(self):
        return self._data
 
    @data.setter
    def data(self, value):
        self._data = value
        self.notify()
 
class HexViewer:
    def update(self, subject):
        print('HexViewer: Subject %s has data 0x%x' %
              (subject.name, subject.data))
 
class DecimalViewer:
    def update(self, subject):
        print('DecimalViewer: Subject %s has data %d' %
              (subject.name, subject.data))
 
# Example usage...
def main():
    data1 = Data('Data 1')
    data2 = Data('Data 2')
    view1 = DecimalViewer()
    view2 = HexViewer()
    data1.attach(view1)
    data1.attach(view2)
    data2.attach(view2)
    data2.attach(view1)
 
    print("Setting Data 1 = 10")
    data1.data = 10
    print("Setting Data 2 = 15")
    data2.data = 15
    print("Setting Data 1 = 3")
    data1.data = 3
    print("Setting Data 2 = 5")
    data2.data = 5
    print("Detach HexViewer from data1 and data2.")
    data1.detach(view2)
    data2.detach(view2)
    print("Setting Data 1 = 10")
    data1.data = 10
    print("Setting Data 2 = 15")
    data2.data = 15
 
if __name__ == '__main__':
    main()
```

### State（状态）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001100150906-852963744.gif)

意图：
- 允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它的类。

适用性：
- 一个对象的行为取决于它的状态, 并且它必须在运行时刻根据状态改变它的行为。
- 一个操作中含有庞大的多分支的条件语句，且这些分支依赖于该对象的状态。这个状态通常用一个或多个枚举常量表示。通常, 有多个操作包含这一相同的条件结构。State模式将每一个条件分支放入一个独立的类中。这使得你可以根据对象自身的情况将对象的状态作为一个对象，这一对象可以不依赖于其他对象而独立变化。

```python
#!/usr/bin/python
#coding:utf8
'''
State
'''
 
class State(object):
    """Base state. This is to share functionality"""
 
    def scan(self):
        """Scan the dial to the next station"""
        self.pos += 1
        if self.pos == len(self.stations):
            self.pos = 0
        print("Scanning... Station is", self.stations[self.pos], self.name)
 
 
class AmState(State):
    def __init__(self, radio):
        self.radio = radio
        self.stations = ["1250", "1380", "1510"]
        self.pos = 0
        self.name = "AM"
 
    def toggle_amfm(self):
        print("Switching to FM")
        self.radio.state = self.radio.fmstate
 
class FmState(State):
    def __init__(self, radio):
        self.radio = radio
        self.stations = ["81.3", "89.1", "103.9"]
        self.pos = 0
        self.name = "FM"
 
    def toggle_amfm(self):
        print("Switching to AM")
        self.radio.state = self.radio.amstate
 
class Radio(object):
    """A radio.     It has a scan button, and an AM/FM toggle switch."""
    def __init__(self):
        """We have an AM state and an FM state"""
        self.amstate = AmState(self)
        self.fmstate = FmState(self)
        self.state = self.amstate
 
    def toggle_amfm(self):
        self.state.toggle_amfm()
 
    def scan(self):
        self.state.scan()
 
# Test our radio out
if __name__ == '__main__':
    radio = Radio()
    actions = [radio.scan] * 2 + [radio.toggle_amfm] + [radio.scan] * 2
    actions = actions * 2
 
    for action in actions:
        action()
```


### Strategy（策略）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001100423828-707061510.gif)

意图：
- 定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。

适用性：
- 许多相关的类仅仅是行为有异。“策略”提供了一种用多个行为中的一个行为来配置一个类的方法。
- 需要使用一个算法的不同变体。例如，你可能会定义一些反映不同的空间/时间权衡的算法。当这些变体实现为一个算法的类层次时[H087] ,可以使用策略模式。
- 算法使用客户不应该知道的数据。可使用策略模式以避免暴露复杂的、与算法相关的数据结构。
- 一个类定义了多种行为, 并且这些行为在这个类的操作中以多个条件语句的形式出现。将相关的条件分支移入它们各自的Strategy类中以代替这些条件语句。

```python
#!/usr/bin/python
#coding:utf8
"""
Strategy
In most of other languages Strategy pattern is implemented via creating some base strategy interface/abstract class and
subclassing it with a number of concrete strategies (as we can see at http://en.wikipedia.org/wiki/Strategy_pattern),
however Python supports higher-order functions and allows us to have only one class and inject functions into it's
instances, as shown in this example.
"""
import types
 
 
class StrategyExample:
    def __init__(self, func=None):
        self.name = 'Strategy Example 0'        
        if func is not None:
            self.execute = types.MethodType(func, self)     
 
    def execute(self):        
        print(self.name)  
 
def execute_replacement1(self):
    print(self.name + ' from execute 1')  
 
def execute_replacement2(self):
    print(self.name + ' from execute 2') 
 
if __name__ == '__main__':
    strat0 = StrategyExample()    
 
    strat1 = StrategyExample(execute_replacement1)
    strat1.name = 'Strategy Example 1'    
 
    strat2 = StrategyExample(execute_replacement2)
    strat2.name = 'Strategy Example 2'
 
    strat0.execute()
    strat1.execute()    
    strat2.execute()
```


### Visitor（访问者）

![](https://images2015.cnblogs.com/blog/824579/201610/824579-20161001100727844-1430710049.gif)

意图：
- 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。TemplateMethod 使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。

适用性：
- 一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现。
- 各子类中公共的行为应被提取出来并集中到一个公共父类中以避免代码重复。这是Opdyke和Johnson所描述过的“重分解以一般化”的一个很好的例子[OJ93]。首先识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。
- 控制子类扩展。模板方法只在特定点调用“hook ”操作（参见效果一节），这样就只允许在这些点进行扩展。

```python
#!/usr/bin/python
#coding:utf8
'''
Visitor
'''
class Node(object):
    pass
 
class A(Node):
    pass
 
class B(Node):
    pass
 
class C(A, B):
    pass
 
class Visitor(object):
    def visit(self, node, *args, **kwargs):
        meth = None
        for cls in node.__class__.__mro__:
            meth_name = 'visit_'+cls.__name__
            meth = getattr(self, meth_name, None)
            if meth:
                break
 
        if not meth:
            meth = self.generic_visit
        return meth(node, *args, **kwargs)
 
    def generic_visit(self, node, *args, **kwargs):
        print('generic_visit '+node.__class__.__name__)
 
    def visit_B(self, node, *args, **kwargs):
        print('visit_B '+node.__class__.__name__)
 
a = A()
b = B()
c = C()
visitor = Visitor()
visitor.visit(a)
visitor.visit(b)
visitor.visit(c)
```

## 单例模式

【2021-7-14】[单例设计模式的python实现](https://www.jianshu.com/p/6a1690f0dd00)

单例模式就是确保**一个类只有一个实例**.当你希望整个系统中,某个类只有一个实例时,单例模式就派上了用场.
- 比如,某个服务器的配置信息存在在一个文件中,客户端通过AppConfig类来读取配置文件的信息.如果程序的运行的过程中,很多地方都会用到配置文件信息,则就需要创建很多的AppConfig实例,这样就导致内存中有很多AppConfig对象的实例,造成资源的浪费.其实这个时候AppConfig我们希望它只有一份,就可以使用单例模式.

### 模块实现

python的模块就是天然的单例模式,因为模块在第一次导入的时候,会生成.pyc文件,当第二次导入的时候,就会直接加载.pyc文件,而不是再次执行模块代码.如果我们把相关的函数和数据定义在一个模块中,就可以获得一个单例对象了

新建一个python模块叫singleton, 文件名 mysingleton.py

```python
class Singleton(object):
    def foo(self):
        pass
singleton = Singleton()

```
调用时：

```python
from singleton.mysingleton import singleton
```


### 装饰器实现

装饰器里面的外层变量定义一个字典,里面存放这个类的实例.当第一次创建的收,就将这个实例保存到这个字典中.
然后以后每次创建对象的时候,都去这个字典中判断一下,如果已经被实例化,就直接取这个实例对象.如果不存在就保存到字典中.

```python
# encoding:utf-8
__author__ = 'Fioman'
__time__ = '2019/3/6 10:22'

def singleton(cls):
    # 单下划线的作用是这个变量只能在当前模块里访问,仅仅是一种提示作用
    # 创建一个字典用来保存类的实例对象
    _instance = {}

    def _singleton(*args, **kwargs):
        # 先判断这个类有没有对象
        if cls not in _instance:
            _instance[cls] = cls(*args, **kwargs)  # 创建一个对象,并保存到字典当中
        # 将实例对象返回
        return _instance[cls]

    return _singleton

@singleton
class A(object):
    a = 1

    def __init__(self, x=0):
        self.x = x
        print('这是A的类的初始化方法')

a1 = A(2)
a2 = A(3)
print(id(a1), id(a2))
```


### 类实现

调用类的instance方法,这样有一个弊端就是在使用类创建的时候,并不是单例了.也就是说在创建类的时候一定要用类里面规定的方法创建

注意：
- 这样的单例模式在单线程下是安全的,但是如果遇到多线程,就会出现问题.如果遇到多个线程同时创建这个类的实例的时候就会出现问题.

```python
# encoding:utf-8
__author__ = 'Fioman'
__time__ = '2019/3/6 11:06'

class Singleton(object):
    def __init__(self,*args,**kwargs):
        pass

    @classmethod
    def get_instance(cls, *args, **kwargs):
        # 利用反射,看看这个类有没有_instance属性
        if not hasattr(Singleton, '_instance'):
            Singleton._instance = Singleton(*args, **kwargs)

        return Singleton._instance

s1 = Singleton()  # 使用这种方式创建实例的时候,并不能保证单例
s2 = Singleton.get_instance()  # 只有使用这种方式创建的时候才可以实现单例
s3 = Singleton()
s4 = Singleton.get_instance()

print(id(s1), id(s2), id(s3), id(s4))
```

多线程安全版本

```python
# encoding:utf-8
__author__ = 'Fioman'
__time__ = '2019/3/6 11:26'
import threading


class Singleton(object):
    def __init__(self, *args, **kwargs):
        time.sleep(1) # init时加阻塞，以便暴露问题
        pass

    @classmethod
    def get_instance(cls, *args, **kwargs):
        if not hasattr(Singleton, '_instance'):
            Singleton._instance = Singleton(*args, **kwargs)

        return Singleton._instance

def task(arg):
    obj = Singleton.get_instance(arg)
    print(obj)

for i in range(10):
    t = threading.Thread(target=task, args=[i, ])
    t.start()

```

结果创建了10个不同的实例对象，因为在一个对象创建的过程中,另外一个对象也创建了.当它判断的时候,会先去获取_instance属性,因为这个时候还没有,它就会调用init()方法.结果就是调用了10次,然后就创建了10个对象.

```python
# encoding:utf-8
__author__ = 'Fioman'
__time__ = '2019/3/6 11:38'

import time
import threading

class Singleton(object):
    _instance_lock = threading.Lock()

    def __init__(self,*args,**kwargs):
        time.sleep(1)

    @classmethod
    def get_instance(cls,*args,**kwargs):
        if not hasattr(Singleton,'_instance'):
            with Singleton._instance_lock:
                if not hasattr(Singleton,'_instance'):
                    Singleton._instance = Singleton(*args,**kwargs)

        return Singleton._instance

def task(arg):
    obj = Singleton.get_instance(arg)
    print(obj)

for i in range(10):
    t = threading.Thread(target=task,args=[i,])
    t.start()

obj = Singleton.get_instance()
print(obj)
```

这种方式创建的单例,必须使用Singleton_get_instance()方法,如果使用Singleton()的话,得到的并不是单例.所以我们推荐使用__new__()方法来创建单例,这样创建的单例可以使用类名()的方法进行实例化对象

### 基于__new__方法实现的单例模式(推荐使用,方便)

知识点:
- 一个对象的实例化过程是先执行类的__new__方法,如果没有写,默认会调用object的__new__方法,返回一个实例化对象,然后再调用__init__方法,对这个对象进行初始化,我们可以根据这个实现单例.
- 在一个类的__new__方法中先判断是不是存在实例,如果存在实例,就直接返回,如果不存在实例就创建.

```python
# encoding:utf-8
__author__ = 'Fioman'
__time__ = '2019/3/6 13:36'
import threading


class Singleton(object):
    _instance_lock = threading.Lock()

    def __init__(self, *args, **kwargs):
        pass

    def __new__(cls, *args, **kwargs):
        if not hasattr(cls, '_instance'):
            with Singleton._instance_lock:
                if not hasattr(cls, '_instance'):
                    Singleton._instance = super().__new__(cls)

            return Singleton._instance

obj1 = Singleton()
obj2 = Singleton()
print(obj1, obj2)

def task(arg):
    obj = Singleton()
    print(obj)

for i in range(10):
    t = threading.Thread(target=task, args=[i, ])
    t.start()
```

# Python GUI

常见GUI工具包:
- PyQt 的介绍 : http://en.wikipedia.org/wiki/PyQt
- Tkinter 的介绍 : http://en.wikipedia.org/wiki/Tkinter
- wxPython 的介绍 : http://en.wikipedia.org/wiki/WxPython
- PyGTK 的介绍 : http://en.wikipedia.org/wiki/PyGTK
- PySide 的介绍 : http://en.wikipedia.org/wiki/PySide

- [推荐8款常用的Python GUI图形界面开发框架](https://www.jb51.net/article/181133.htm)

## 总结

[Python下各种GUI简介、使用优缺点对比](https://blog.csdn.net/wanglj2012/article/details/83012148) 

| GUI编程对比 | 简介特点 | 优缺点 |
|---|---|---|
| PyQt | Python 对跨平台的 GUI 工具集 Qt 的包装实现了 440 个类以及 6000 个函数或者方法 ，PyQt 是作为 Python 的插件实现的。  | 比较流行的一个 Tkinter 的替代品，功能 非常强大，可以用Qt开发多美漂亮的界面，也就可以用PyQt开发多么漂亮的界面。 跨平台的支持很好，不过在商业授权上似乎存在一些问题。|
| Tkinter| 绑定了 Python 的 Tk GUI 工具集 ，就是Python 包装的Tcl代码，通过内嵌在 Python 解释器内部的 Tcl 解释器实现， Tkinter的调用转换成 Tcl 命令，然后交给 Tcl 解释器进行解释，实现 Python 的 GUI 界面。| 对比Tk和其它语言的绑定，比如 PerlTk ，是直接由 Tk 中的 C 库实现的。|历史最悠久， Python 事实上的标准 GUI ， Python 中使用 Tk GUI 工具集的标准接口，已经包括在标准的 Python Windows 安装中，著名的 IDLE 就是使用 Tkinter 实现 GUI 的创建的 GUI 简单，学起来和用起来也简单。|
| wxPython | Python 对跨平台的 GUI 工具集 wxWidgets （ C++ 编写）的包装，作为 Python 的一个 扩展模块实现。|比较流行的一个 Tkinter 的替代品，在 各种平台下都表现挺好。|
| PyGTK| 一系列的 Python 对 GTK+ GUI 库的包装。| 比较流行的一个 Tkinter 的替代品，许多 Gnome 下的著名应用程序的 GUI 都是使用 PyGTK 实现的，比如 BitTorrent ， GIMP和 Gedit 都有可选的实现，在 Windows 平台 似乎表现不太好，这点也无可厚非，毕竟使用的是GTK 的 GUI 库。|
| PySide| 另一个 Python 对跨平台的 GUI 工具集 Qt 的包装，捆绑在 Python 当中，最初由 BoostC++ 库实现，后来迁移到 Shiboken。| 比较流行的一个 Tkinter 的替代品，和上 面类似，至于两者的区别，这里 有一个介绍。|

## 基本概念

概念：窗口和控件、事件驱动处理、布局管理器。
- 窗体控件: 窗体、标签、按钮、列表框、滚动条等。
- 事件驱动：按下按钮及释放、鼠标移动、按回车键等。
- 布局管理：Tk有3种布局管理器：Placer、Packer、Grid


## Tkinter

Tkinter（也叫Tk接口）是Tk图形用户界面工具包标准的Python接口。Tk是一个轻量级的跨平台图形用户界面（GUI）开发工具。Tk和Tkinter可以运行在大多数的Unix平台、Windows、和Macintosh系统。

Tkinter 由一定数量的模块组成。Tkinter位于一个名为_tkinter（较早的版本名为tkinter）的二进制模块中 。Tkinter包含了对Tk的低 级接口模块，低级接口并不会被应用级程序员直接使用，通常是一个共享库（或DLL），但是在一些情况下它也被Python解释器静态链接。

tkinter提供各种控件，如按钮、标签和文本框等，在一个GUI应用程序中使用。这些控件有时也被称为部件。目前有19种tkinter的控件。
- ![](https://img-blog.csdnimg.cn/20200329125958615.png)

### 语法

```python
from tkinter import *

win = Tk() # 生成根窗体
win.title("Python GUI") # 标题

def _quit():
    win.quit()
    win.destroy()
    exit()
    
# 创建菜单栏功能
menuBar = Menu(win) 
win.config(menu = menuBar)

font = ("黑体", 10, "bold")

fileMenu = Menu(menuBar, tearoff=0, font=font, bg="white", fg="black")
menuBar.add_cascade(label="File", menu=fileMenu)
fileMenu.add_command(labe="New File") 
fileMenu.add_separator()
fileMenu.add_command(labe="Exit",command=_quit) 

helpMenu = Menu(menuBar, tearoff=0, font=font, bg="white", fg="black")
menuBar.add_cascade(label="Help", menu=helpMenu)
helpMenu.add_command(labe="About") 

check_music = IntVar()
check_video = IntVar()

# ---- 准备各类组件 -----
label = Label(win, text = "hello tkinter") # 文字
button = Button(win ,text="第一个按钮") # 按钮
#   Checkbutton控件
check_m = Checkbutton(win,text="Music", variable = check_music, onvalue =1, offvalue =0)
check_v = Checkbutton(win,text="Video", variable = check_video, onvalue =1, offvalue =0)
#   文本控件
text = Text(win,height=5, width=30, font=font, bg="white", fg="black")
text.insert(INSERT,"Hello GUI,")
text.insert(END, "Bye!")

# ---- 组件添加到窗体中 -----
label.pack()
button.pack()
check_m.pack()
check_v.pack()
text.pack()

win .mainloop() # 根窗体（活跃状态？）
```

### 案例

制作TCP通信的Server 和 Client
- 服务端
  - ![](https://img-blog.csdnimg.cn/2020032913034498.png)
- 客户端
  - ![](https://img-blog.csdnimg.cn/20200329130405677.png)

```python
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 26 15:34:10 2020

@author: sinlearn
"""
import tkinter as tk
import tkinter.ttk as ttk
import socket
import threading
import time

class TCP_Server():
    # 服务端
    def __init__(self):
        winserver = tk.Tk()
        winserver.title("TCP Server")
        winserver.geometry("500x500")
        winserver.resizable(width=False, height=False)
        font = ("宋体", 10)

        self.rbtn = tk.Radiobutton(winserver, text="未连接", fg="red")
        self.label_port = tk.Label(winserver, text=" 端口:", font=font)
        self.label_send = tk.Label(winserver, text=" 发送区:", font=font)
        self.label_recv = tk.Label(winserver, text=" 接收区:", font=font)
        self.label_clist = tk.Label(winserver, text=" 客户端列表:", font=font)
        self.spinbox_port = tk.Spinbox(winserver, from_=1024, to=10000)
        self.btn_start = tk.Button(winserver, text="启动", bg="white", command=self.do_start)
        self.btn_stop = tk.Button(winserver, text="停止", bg="white", command=self.do_stop)
        self.btn_send = tk.Button(winserver, text="发送", bg="white", command=self.send_to_client)
        self.en_send = tk.Entry(winserver, text="Test", bd=2)
        self.text_recv = tk.Text(winserver, height=5, width=43, font=font, bg="white", fg="black")
        self.client_list = ttk.Treeview(winserver, height=10, show="headings",
                                        columns=('col1', 'col2', 'col3'))  # show = "headings" 隐藏默认的col0列
        self.client_list.column('col1', width=50, anchor='center')
        self.client_list.column('col2', width=200, anchor='center')
        self.client_list.column('col3', width=100, anchor='center')
        self.client_list.heading('col1', text='序号')
        self.client_list.heading('col2', text='IP地址')
        self.client_list.heading('col3', text='端口号')

        self.rbtn.place(x=10, y=10)
        self.label_port.place(x=100, y=15)
        self.label_send.place(x=100, y=50)
        self.label_recv.place(x=100, y=140)
        self.spinbox_port.place(x=150, y=15)
        self.btn_start.place(x=400, y=10)
        self.btn_stop.place(x=440, y=10)
        self.btn_send.place(x=440, y=70)
        self.en_send.place(x=120, y=70, width=300, height=60)
        self.text_recv.place(x=120, y=160)
        self.label_clist.place(x=100, y=240)
        self.client_list.place(x=120, y=260)

        for i in range(10):
            self.client_list.insert("", i, values=(i, "192.168.2.3" + str(i), "9999"))  # 插入数据
            self.client_list.bind("<Double-1>", self.onDBClick)
        winserver.mainloop()

    def onDBClick(self, event):
        item = self.client_list.selection()[0]
        print("you clicked on ", self.client_list.item(item, "values"))

    def do_start(self):
        self.rbtn["fg"] = "green"
        self.rbtn["text"] = "已连接"
           

    def do_stop(self):
        print("正在断开连接....")
        self.rbtn["fg"] = "red"
        self.rbtn["text"] = "未连接"
      

    def send_to_client(self):
        if self.rbtn["text"] == "已连接":
            print("正在发送数据....")
        else:
            print("连接未建立，不能发送数据....")

    def tcp_link(self, sock, addr):
        print(f" {addr} 正在请求连接........")
        sock.send("欢迎您连接到服务器........".encode('utf-8'))
        while True:
            data = sock.recv(1024)
            time.sleep(1)
            if data and data.decode('utf-8') != "exit":
                print(data.decode('utf-8'))
                self.text_recv["text"] = data.decode('utf-8')
                sock.send("服务器正在接收数据,请稍等........".encode('utf-8'))
            else:
                break


class TCP_Client():
    def __init__(self):
        self.client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        winclient = tk.Tk()
        winclient.title("TCP Client")
        winclient.geometry("600x250")
        winclient.resizable(width=False, height=False)
        font = ("宋体", 10)

        self.rbtn = tk.Radiobutton(winclient, text="未连接", fg="red")
        self.label_ip = tk.Label(winclient, text=" IP地址:", font=font)
        self.label_port = tk.Label(winclient, text=" 端口:", font=font)
        self.label_send = tk.Label(winclient, text=" 发送区:", font=font)
        self.label_recv = tk.Label(winclient, text=" 接收区:", font=font)
        self.spinbox_port = tk.Spinbox(winclient, from_=1024, to=10000)
        self.btn_start = tk.Button(winclient, text="连接", bg="white", command=self.do_connect)
        self.btn_stop = tk.Button(winclient, text="断开", bg="white", command=self.do_stopconnect)
        self.btn_send = tk.Button(winclient, text="发送", bg="white", command=self.send_to_server)
        self.en_ip = tk.Entry(winclient, text="IP地址", bd=2)
        self.en_send = tk.Entry(winclient, text="Test", bd=2)
        self.text_recv = tk.Text(winclient, height=5, width=43, font=font, bg="white", fg="black")

        self.label_ip.place(x=100, y=15)
        self.label_port.place(x=360, y=15)
        self.label_send.place(x=100, y=50)
        self.label_recv.place(x=100, y=150)
        self.rbtn.place(x=10, y=10)
        self.btn_start.place(x=480, y=10)
        self.btn_stop.place(x=520, y=10)
        self.btn_send.place(x=480, y=70)
        self.en_ip.place(x=160, y=15, width=200, height=20)
        self.spinbox_port.place(x=410, y=15, width=50, height=20)
        self.en_send.place(x=120, y=70, width=300, height=60)
        self.text_recv.place(x=120, y=170)
        winclient.mainloop()

    def do_connect(self):
        print("正在连接服务器....")
        self.rbtn["fg"] = "green"
        self.rbtn["text"] = "已连接"
       
    def do_stopconnect(self):
        self.rbtn["fg"] = "red"
        self.rbtn["text"] = "未连接"
       

    def send_to_server(self):
        print("正在往服务器发送数据.....")
        
if __name__ == "__main__":
    TCP_Server()
    TCP_Client()
```

## PyQT

pyqt5是一套Python绑定Digia QT5应用的框架。它可用于Python 2和3。Qt库是最**强大**的GUI库之一。
- [PyQT中文教程](http://code.py40.com/pyqt5/)

![](https://img.jbzj.com/file_images/article/202002/2020223152502329.jpg)

pyqt5的类别分为几个模块，包括以下：
- QtCore: 包含了核心的非GUI功能。此模块用于处理时间、文件和目录、各种数据类型、流、URL、MIME类型、线程或进程。
- QtGui: 包含类窗口系统集成、事件处理、二维图形、基本成像、字体和文本。
- qtwidgets: 包含创造经典桌面风格的用户界面提供了一套UI元素的类。
- QtMultimedia: 包含的类来处理多媒体内容和API来访问相机和收音机的功能。
- Qtbluetooth: 包含类的扫描设备和连接并与他们互动。描述模块包含了网络编程的类。
- Qtpositioning: 包含类的利用各种可能的来源，确定位置，包括卫星、Wi-Fi、或一个文本文件。
- Enginio: 实现了客户端库访问Qt云服务托管的应用程序运行时。
- Qtwebsockets: 包含实现WebSocket协议类。
- QtWebKit: 包含一个基于Webkit2图书馆Web浏览器实现类。
- Qtwebkitwidgets: 的类的基础webkit1一用于qtwidgets应用Web浏览器的实现。
- QtXml: 包含与XML文件的类。这个模块为SAX和DOM API提供了实现。
- QtSvg: 提供了显示SVG文件内容的类。可伸缩矢量图形（SVG）是一种描述二维图形和图形应用的语言。
- QtSql: 提供操作数据库的类。
- QtTest: 包含的功能，使pyqt5应用程序的单元测试

代码

```python
#!/usr/bin/python3
# -*- coding: utf-8 -*-

"""
Py40 PyQt5 tutorial 

This example shows a tooltip on 
a window and a button.

author: Jan Bodnar
website: py40.com 
last edited: January 2015
"""

import sys
from PyQt5.QtWidgets import (QWidget, QToolTip, 
    QPushButton, QApplication)
from PyQt5.QtGui import QFont    


class Example(QWidget):
    
    def __init__(self):
        super().__init__()
        
        self.initUI()
        
        
    def initUI(self):
        #这种静态的方法设置一个用于显示工具提示的字体。我们使用10px滑体字体。
        QToolTip.setFont(QFont('SansSerif', 10))
        
        #创建一个提示，我们称之为settooltip()方法。我们可以使用丰富的文本格式
        self.setToolTip('This is a <b>QWidget</b> widget')
        
        #创建一个PushButton并为他设置一个tooltip
        btn = QPushButton('Button', self)
        btn.setToolTip('This is a <b>QPushButton</b> widget')
        
        #btn.sizeHint()显示默认尺寸
        btn.resize(btn.sizeHint())
        
        #移动窗口的位置
        btn.move(50, 50)       
        
        self.setGeometry(300, 300, 300, 200)
        self.setWindowTitle('Tooltips')    
        self.show()
        
        
if __name__ == '__main__':
    
    app = QApplication(sys.argv)
    ex = Example()
    sys.exit(app.exec_())
```


## wxPython

wxPython 是 Python 语言的一套优秀的 GUI 图形库，允许 Python 程序员很方便的创建完整的、功能键全的  GUI 用户界面。 wxPython 是作为优秀的跨平台 GUI 库 wxWidgets 的 Python 封装和 Python 模块的方式提供给用户的。

就如同Python和wxWidgets一样，wxPython也是一款开源软件，并且具有非常优秀的跨平台能力，能够运行在32位windows、绝大多数的Unix或类Unix系统、Macintosh OS X上。

![](https://img.jbzj.com/file_images/article/202002/2020223152506774.jpg)


##  PyGTK

PyGTK让你用Python轻松创建具有图形用户界面的程序.底层的GTK+提供了各式的可视元素和功能,如果需要,你能开发在GNOME桌面系统运行的功能完整的软件.

PyGTK真正具有跨平台性,它能不加修改地,稳定运行各种操作系统之上,如Linux,Windows,MacOS等.除了简单易用和快速的原型开发能力外,PyGTK还有一流的处理本地化语言的独特功能.


# 结束
















